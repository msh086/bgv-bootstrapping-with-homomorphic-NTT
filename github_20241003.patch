diff --git a/include/helib/Context.h b/include/helib/Context.h
index 1723b43..c3927ac 100644
--- a/include/helib/Context.h
+++ b/include/helib/Context.h
@@ -133,10 +133,51 @@ private:
   std::shared_ptr<const EncryptedArray> ea;
 
   // These parameters are currently set by buildPrimeChain
-  long hwt_param = 0; // Hamming weight of all keys associated with context
-                      // 0 means "dense"
-  long e_param = 0;   // parameters specific to bootstrapping
+  long hwt_param = 0;      // Hamming weight of all keys associated with context
+                           // 0 means "dense"
+  long encapHwt_param = 0; // Hamming weight of the encapsulated bts key
+                           // 0 means set to default value
+  long e_param = 0;        // parameters specific to bootstrapping
   long ePrime_param = 0;
+  // newly added
+  long eNew_param = 0; // the new digit extraction is performed modulo p^e
+  // t < 0: use non-power-of-p aux
+  // t = 0: use power-of-p aux, deduce t automatically
+  // t > 0: use aux = p^t, assert on too small aux
+  long t_param = 0;   // for type-A bts, the aux modulus is aux = p^t
+  long aux_param = 0; // for type-B bts (gcd(aux, p) = 1), set t_param = 0 and
+                      // stores the aux modulus
+                      // note that this need not be a prime
+                      // so that we cannot store it in the moduli chain
+  long numExtract_param =
+      0; // number of digits to extract (used only by the new bootstrap
+         // procedure) this should be either 1 or 2
+  // long qks_param = 0;  // the ks modulus before bootstrap
+  // long R_param = 0;    // the special modulus used in the ks before bootstrap
+  long index_qks = -1;  // the index of qks in the moduli vector
+  long index_R = -1;    // the index of R in the moduli vector
+  IndexSet modUpPrimes; // the extra primes used in mod-up operation
+
+  bool newBtsFlag = false; // whether to use the new bootstrap procedure
+  bool newKSFlag = false;
+  bool ch18Flag = false;
+  bool s2cFirstFlag = false; // whether perform s2c first in general bootstrapping
+
+  long debug_ee;
+  long debug_rr;
+  // for benchmarking only
+  // the min capacity for a ctxt to bootstrap
+  double minCapacity;
+
+  // precomputed polynomials for bootstrap...?
+  // XXX: we use a hack to do this by precomputing the poly in sage and reading
+  // them in
+  NTL::ZZX liftPoly;
+  NTL::Vec<NTL::ZZX> extractPolys;
+
+  bool forceRadix2;
+  std::vector<long> FFT_partition;
+  bool dummy; // for a rough comparison with GV23
 
   std::shared_ptr<const PowerfulDCRT> pwfl_converter;
 
@@ -148,7 +189,8 @@ private:
   // The `sqrt(variance)` of the LWE error (default=3.2).
   NTL::xdouble stdev;
 
-  double scale; // default = 10
+  double scale;         // default = 10
+  double btsScale = 10; // default = 10, recommended = 8
 
   // The "ciphertext primes" are the "normal" primes that are used to
   // represent the public encryption key and ciphertexts. These are all
@@ -181,6 +223,10 @@ private:
   // See section 3.1.6 in the design document (key-switching).
   // Digits of ctxt/columns of key-switching matrix
   std::vector<IndexSet> digits;
+  long btsDigits = 0; // number of digits for KS before bootstrap (NOTE that we
+                      // don't use CRT decomposition for this KS)
+  long btsBaseKS = 0; // the base for the KS before bootstrap, i.e., each digit
+                      // is modulo btsBaseKS
 
   // Bootstrapping-related data in the context includes both thin and thick
   ThinRecryptData rcData;
@@ -218,7 +264,8 @@ private:
   // Methods for adding primes.
   void addSpecialPrimes(long nDgts,
                         bool willBeBootstrappable,
-                        long bitsInSpecialPrimes);
+                        long bitsInSpecialPrimes,
+                        long nDgtsBTS = 0);
 
   void addCtxtPrimes(long nBits, long targetSize);
 
@@ -283,6 +330,12 @@ public:
    **/
   double getScale() const { return scale; }
 
+  /**
+   * @brief Getter method for the btsScale.
+   * @return the btsScale as a `double`.
+   **/
+  double getBtsScale() const { return btsScale; }
+
   /**
    * @brief Getter method for the standard deviation used..
    * @return the standard deviation as an `NTL::xdouble`.
@@ -365,6 +418,10 @@ public:
    **/
   const IndexSet& getDigit(long i) const { return digits[i]; }
 
+  long getBtsDigits() const { return btsDigits; }
+
+  long getBtsBaseKS() const { return btsBaseKS; }
+
   /**
    * @brief Getter method for a recryption data object.
    * @return A `const` reference to the recryption data object.
@@ -385,6 +442,13 @@ public:
    **/
   long getHwt() const { return hwt_param; }
 
+  /**
+   * @brief Getter method for the Hamming weight value (of the encapsulated
+   *key).
+   * @return The Hamming weight value.
+   **/
+  long getEncapHwt() const { return encapHwt_param; }
+
   /**
    * @brief Getter method for the e parameter.
    * @return The e parameter.
@@ -397,6 +461,56 @@ public:
    **/
   long getEPrime() const { return ePrime_param; }
 
+  /**
+   * @brief Getter method for the new e parameter.
+   * @return The new e parameter.
+   **/
+  long getENew() const { return eNew_param; }
+
+  /**
+   * @brief Getter method for the t parameter.
+   * @return The t parameter.
+   **/
+  long getT() const { return t_param; }
+
+  /**
+   * @brief Getter method for the aux parameter.
+   * @return The aux parameter.
+   **/
+  long getAux() const { return aux_param; }
+
+  long getNumExtract() const { return numExtract_param; }
+
+  long getIndexQks() const { return index_qks; }
+
+  long getIndexR() const { return index_R; }
+
+  IndexSet getModUpPrimes() const { return modUpPrimes; }
+
+  bool getNewBTSFlag() const { return newBtsFlag; }
+
+  bool getNewKSFlag() const { return newKSFlag; }
+
+  bool getCH18Flag() const { return ch18Flag; }
+
+  bool getS2CFirstFlag() const { return s2cFirstFlag; }
+
+  long getDebugEE() const { return debug_ee; }
+
+  long getDebugRR() const { return debug_rr; }
+
+  double getMinCap() const { return minCapacity; }
+
+  const NTL::ZZX& getLiftPoly() const { return liftPoly; }
+
+  const NTL::vec_ZZX& getExtractPolys() const { return extractPolys; }
+
+  bool getForceRadix2() const { return forceRadix2; }
+
+  const std::vector<long>& getFFTPartition() const { return FFT_partition; }
+
+  bool getDummy() const { return dummy; }
+
   /**
    * @brief Get the underlying `zMStar` object.
    * @return A `zMStar` object.
@@ -615,7 +729,7 @@ public:
    **/
   double stdDevForRecryption() const
   {
-    long skHwt = hwt_param;
+    long skHwt = encapHwt_param; // NOTE: change to the hwt of encapsulated key
 
     // number of prime factors of m
     long k = zMStar.getNFactors();
@@ -634,7 +748,8 @@ public:
    **/
   double boundForRecryption() const
   {
-    return 0.5 + scale * stdDevForRecryption();
+    return 0.5 +
+           btsScale * stdDevForRecryption(); // NOTE: bts scale is used here
   }
 
   /**
@@ -682,6 +797,8 @@ public:
    **/
   Context& operator=(Context&& other) = delete;
 
+  void buildBtsPolys();
+
   /**
    * @brief Initialises the recryption data.
    * @param mvec A `std::vector` of unique prime factors of `m`.
@@ -694,11 +811,12 @@ public:
                            bool build_cache = false,
                            bool alsoThick = true)
   {
-    assertTrue(e_param > 0,
+    assertTrue(e_param > 0 || eNew_param > 0, // add the case of new bootstrap
                "enableBootStrapping invoked but willBeBootstrappable "
                "not set in buildModChain");
 
     rcData.init(*this, mvec, alsoThick, build_cache);
+    buildBtsPolys();
   }
 
   /**
@@ -1001,6 +1119,8 @@ public:
     hwt_param = 0;
     e_param = 0;
     ePrime_param = 0;
+    // I don't want to change this... do we need to run parameter generation
+    // programs?
   }
 
   /**
@@ -1015,13 +1135,20 @@ public:
    * is 3.
    * @param bitsInSpecialPrimes The bit size of the special primes in the
    *modulus chain. Default is 0.
+   * @param newBts Flag for using the new bootstrap procedure.
+   * @note We have to include the newBts flag a one of the params, because e and
+   *ePrime are set in this function
    **/
   void buildModChain(long nBits,
                      long nDgts = 3,
                      bool willBeBootstrappable = false,
                      long skHwt = 0,
                      long resolution = 3,
-                     long bitsInSpecialPrimes = 0);
+                     long bitsInSpecialPrimes = 0,
+                     long encapSkHwt = 0,
+                     bool newBts = false,
+                     bool newKS = false,
+                     long t = -1);
 
   // should be called if after you build the mod chain in some way
   // *other* than calling buildModChain.
@@ -1069,22 +1196,37 @@ private:
   long r_ = default_values::r; // BGV: Hensel lifting = 1,
                                // CKKS: Precision = 20
   long c_ = 3;
+  long btsC_ = 3; // number of digits in key switching before BTS
 
   // Modulus chain params
   long bits_ = 300;
   long skHwt_ = 0;
+  long encapSkHwt_ = 0; // hwt of encapsulated bootstrap sk
   long resolution_ = 3;
   long bitsInSpecialPrimes_ = 0;
   bool buildModChainFlag_ = true; // Default build the modchain.
+  long t_ = 0; // the auxiliary modulus = p^t. -1 for non-power-of-p aux; 0 for
+               // automatic choice we choose to set it manually because
+               // different choices of t provides tradeoff between running time
+               // / bit consumption
 
   double stdev_ = 3.2;
   double scale_ = 10;
+  double btsScale_ = 10; // this parameter is used only for estimating the bound
+                         // of the overflow parts in bootstrapping
 
   // Boostrap params (BGV only)
   NTL::Vec<long> mvec_;
   bool buildCacheFlag_ = false;
   bool thickFlag_ = false;
   bool bootstrappableFlag_ = false; // Default not boostrappable.
+  bool newBtsFlag_ = false; // set to true to use the new bootstrap procedure
+  bool newKSFlag_ = false;  // whether to use the new KS
+  bool s2cFirstFlag_ = false; // whether to execute SlotToCoeff first in general bootstrapping
+
+  bool forceRadix2_ = false;
+  std::vector<long> FFT_partition_;
+  bool dummy_ = false;
 
 public:
   /**
@@ -1157,6 +1299,17 @@ public:
     return *this;
   }
 
+  /**
+   * @brief Sets `btsScale` the scale parameter.
+   * @param scale The bit scale parameter used in bootstrapping.
+   * @return Reference to the `ContextBuilder` object.
+   **/
+  ContextBuilder& btsScale(double btsScale)
+  {
+    btsScale_ = btsScale;
+    return *this;
+  }
+
   /**
    * @brief Sets `stdev` the standard deviation parameter.
    * @param stdev The standard deviation parameter.
@@ -1180,6 +1333,18 @@ public:
     return *this;
   }
 
+  /**
+   * @brief Sets `btsC` the number of columns (a.k.a. digits) in the key
+   *switching before BTS matrices.
+   * @param c The number of columns in the key switching matrix before BTS.
+   * @return Reference to the `ContextBuilder` object.
+   **/
+  ContextBuilder& btsC(long btsC)
+  {
+    btsC_ = btsC;
+    return *this;
+  }
+
   /**
    * @brief Sets `gens` the generators of the `ZMStar` group.
    * @param gens A `std::vector` containing the generators.
@@ -1230,6 +1395,16 @@ public:
     return *this;
   }
 
+  /**
+   * @brief Sets the encapsulated secret key Hamming weight
+   * @param skHwt The encapsulated secret key Hamming weight
+   */
+  ContextBuilder& encapSkHwt(long encapSkHwt)
+  {
+    encapSkHwt_ = encapSkHwt;
+    return *this;
+  }
+
   /**
    * @brief Sets the resolution for the modulus chain.
    * @param bits How many bit size of resolution.
@@ -1265,6 +1440,12 @@ public:
     return *this;
   }
 
+  ContextBuilder& t(long t)
+  {
+    t_ = t;
+    return *this;
+  }
+
   /**
    * @brief Sets `mvec` the unique primes which are factors of `m`.
    * @param mvec An `NTL::Vec` of primes factors.
@@ -1319,6 +1500,19 @@ public:
     return *this;
   }
 
+  /**
+   * @brief Sets the thich flag, a union of thickboot and thinboot.
+   * @return Reference to the `ContextBuilder` object.
+   * @note Only exists when the `SCHEME` is `BGV`.
+   **/
+  template <typename S = SCHEME,
+            std::enable_if_t<std::is_same<S, BGV>::value>* = nullptr>
+  ContextBuilder& setThick(bool isThick)
+  {
+    thickFlag_ = isThick;
+    return *this;
+  }
+
   /**
    * @brief Sets flag to choose that the cache for boostrapping will be
    * built.
@@ -1350,6 +1544,73 @@ public:
     return *this;
   }
 
+  /**
+   * @brief Sets a flag determining if the new bootstrap procedure will used.
+   * @param yesno A `bool` to determine whether the new bootstrap procedure will
+   *be used.
+   * @return Reference to this `ContextBuilder` object.
+   * @note Only exists when the `SCHEME` is `BGV`.
+   **/
+  template <typename S = SCHEME,
+            std::enable_if_t<std::is_same<S, BGV>::value>* = nullptr>
+  ContextBuilder& newBts(bool yesno = true)
+  {
+    newBtsFlag_ = yesno;
+    if (newBtsFlag_ && !newKSFlag_)
+      newKSFlag_ = true;
+    return *this;
+  }
+
+  /**
+   * @brief Sets a flag determining if the new bootstrap procedure will used.
+   * @param yesno A `bool` to determine whether the new bootstrap procedure will
+   *be used.
+   * @return Reference to this `ContextBuilder` object.
+   * @note Only exists when the `SCHEME` is `BGV`.
+   **/
+  template <typename S = SCHEME,
+            std::enable_if_t<std::is_same<S, BGV>::value>* = nullptr>
+  ContextBuilder& newKS(bool yesno = true)
+  {
+    if (newBtsFlag_ && !yesno)
+      std::cerr << "cannot disable newKS for new bootstrap procedure\n";
+    else
+      newKSFlag_ = yesno;
+    return *this;
+  }
+
+  template <typename S = SCHEME,
+          std::enable_if_t<std::is_same<S, BGV>::value>* = nullptr>
+  ContextBuilder& s2cFirst(bool yesno = true)
+  {
+    s2cFirstFlag_ = yesno;
+    return *this;
+  }
+
+  template <typename S = SCHEME,
+            std::enable_if_t<std::is_same<S, BGV>::value>* = nullptr>
+  ContextBuilder& forceRadix2(bool yesno = true)
+  {
+    forceRadix2_ = yesno;
+    return *this;
+  }
+
+  template <typename S = SCHEME,
+            std::enable_if_t<std::is_same<S, BGV>::value>* = nullptr>
+  ContextBuilder& FFT_partition(const std::vector<long> &partition)
+  {
+    FFT_partition_ = partition;
+    return *this;
+  }
+
+  template <typename S = SCHEME,
+            std::enable_if_t<std::is_same<S, BGV>::value>* = nullptr>
+  ContextBuilder& dummy(bool yesno)
+  {
+    dummy_ = yesno;
+    return *this;
+  }
+
   /**
    * @brief Builds a `Context` object from the arguments stored in the
    * `ContextBuilder` object.
@@ -1364,8 +1625,8 @@ public:
    **/
   Context* buildPtr() const;
 
-  friend std::ostream& operator<<<SCHEME>(std::ostream& os,
-                                          const ContextBuilder& cb);
+  friend std::ostream& operator<< <SCHEME>(std::ostream& os,
+                                           const ContextBuilder& cb);
 }; // End of class ContextBuilder
 
 // Default BGV values
diff --git a/include/helib/Ctxt.h b/include/helib/Ctxt.h
index da4be81..309ef86 100644
--- a/include/helib/Ctxt.h
+++ b/include/helib/Ctxt.h
@@ -281,7 +281,8 @@ public:
            const IndexSet& s,
            const SKHandle& otherHandle) :
       DoubleCRT(_context, s), skHandle(otherHandle)
-  {}
+  {
+  }
 
   // Copy constructors from the base class
   explicit CtxtPart(const DoubleCRT& other) : DoubleCRT(other)
@@ -291,7 +292,8 @@ public:
 
   CtxtPart(const DoubleCRT& other, const SKHandle& otherHandle) :
       DoubleCRT(other), skHandle(otherHandle)
-  {}
+  {
+  }
 
   /**
    * @brief Write out the `CtxtPart` object in binary format.
@@ -476,10 +478,14 @@ class Ctxt
   // Takes as arguments a ciphertext-part p relative to s' and a key-switching
   // matrix W = W[s'->s], use W to switch p relative to (1,s), and add the
   // result to *this.
-  void keySwitchPart(const CtxtPart& p, const KeySwitch& W);
+  void keySwitchPart(const CtxtPart& p,
+                     const KeySwitch& W,
+                     bool toNewBootKey = false);
 
   // internal procedure used in key-switching
-  void keySwitchDigits(const KeySwitch& W, std::vector<DoubleCRT>& digits);
+  void keySwitchDigits(const KeySwitch& W,
+                       std::vector<DoubleCRT>& digits,
+                       bool toNewBootKey = false);
 
   long getPartIndexByHandle(const SKHandle& handle) const
   {
@@ -1251,7 +1257,7 @@ public:
   // CKKS adjustment to protect precision
   void relin_CKKS_adjust();
 
-  void reLinearize(long keyIdx = 0);
+  void reLinearize(long keyIdx = 0, bool toNewBootKey = false);
   // key-switch to (1,s_i), s_i is the base key with index keyIdx
 
   Ctxt& cleanUp();
@@ -1334,6 +1340,8 @@ public:
   //! additive mod switching noise)
   double rawModSwitch(std::vector<NTL::ZZX>& zzParts, long toModulus) const;
 
+  double rawModSwitchNew(std::vector<NTL::ZZX>& zzParts, long toModulus) const;
+
   //! @brief compute the power X,X^2,...,X^n
   //  void computePowers(std::vector<Ctxt>& v, long nPowers) const;
 
@@ -1605,6 +1613,19 @@ void extendExtractDigits(std::vector<Ctxt>& digits,
                          long e);
 // implemented in extractDigits.cpp
 
+void newExtractDigits(std::vector<Ctxt>& digits, const Ctxt& c);
+
+// move some of the static functions in extractDigits.cpp to here
+// so that we can precompute the polynomials
+void buildDigitPolynomial(NTL::ZZX& result, long p, long e);
+void compute_magic_poly(NTL::ZZX& poly1, long p, long e);
+void compute_null_poly(NTL::ZZX& poly,
+                       long p,
+                       long e,
+                       long t,
+                       long B,
+                       bool isFirstRow);
+void compute_prime_aux_poly(NTL::ZZX& poly, long p, long r, long B, long aux);
 } // namespace helib
 
 #endif // ifndef HELIB_CTXT_H
diff --git a/include/helib/DoubleCRT.h b/include/helib/DoubleCRT.h
index 0e825a0..398e141 100644
--- a/include/helib/DoubleCRT.h
+++ b/include/helib/DoubleCRT.h
@@ -258,6 +258,11 @@ public:
   //! Returns the sum of the canonical embedding of the digits
   NTL::xdouble breakIntoDigits(std::vector<DoubleCRT>& dgts) const;
 
+  //! @brief Break into n digits using non-RNSS decomposition
+  //! Used only in new bootstrap procedure
+  //! Returns the sum of the canonical embedding of the digits
+  NTL::xdouble breakIntoDigitsNonRNS(std::vector<DoubleCRT>& dgts) const;
+
   //! @brief Expand the index set by s1.
   //! It is assumed that s1 is disjoint from the current index set.
   //! If poly_p != 0, then *poly_p will first be set to the result of applying
diff --git a/include/helib/EncryptedArray.h b/include/helib/EncryptedArray.h
index d34b09a..d42cd59 100644
--- a/include/helib/EncryptedArray.h
+++ b/include/helib/EncryptedArray.h
@@ -416,12 +416,19 @@ private:
   //
   MappingData<type> mappingData; // MappingData is defined in PAlgebra.h
 
+  // NOTE: not sure what this is for
   NTL::Lazy<NTL::Mat<RE>> linPolyMatrix;
 
+  // NOTE: v_N^T * M_first = v_P^T
+  //  M_second = Inv(M_first)
   NTL::Lazy<NTL::Pair<NTL::Mat<R>, NTL::Mat<R>>> normalBasisMatrices;
   // a is the matrix, b is its inverse
 
 public:
+  // XXX: debug
+  const mat_R &getMat(long i) const {
+    return mappingData.getMat(i);
+  }
   explicit EncryptedArrayDerived(const Context& _context,
                                  const RX& _G,
                                  const PAlgebraMod& _tab);
diff --git a/include/helib/EvalMap.h b/include/helib/EvalMap.h
index 74593ac..405232b 100644
--- a/include/helib/EvalMap.h
+++ b/include/helib/EvalMap.h
@@ -103,6 +103,74 @@ public:
   void apply(Ctxt& ctxt) const;
 };
 
+/**
+ * Several kinds of linear transforms used in Po2 BTS
+ * 1. ThickBTS, p=1 mod 4: BlockMatMul1D + MatMul1D (may be augmented)
+ * 2. ThickBTS, p=3 mod 4: BlockMatMul1D + MatMul1D
+ * 3. ThinBTS, p=1 mod 4: MatMul1D (may be augmented)
+ * 4. ThickBTS, p=3 mod 4: BlockMatMul1D (sparse frob) + MatMul1D
+ * 
+ * Augments MatMul1D should be implemented in a seperate class
+ * 
+ * Order of implementation:
+ * ThickBTS, p=3 mod 4
+ * ThickBTS, p=1 mod 4
+ * ThinBTS, p=1 mod 4
+ * ThinBTS, p=3 mod 4
+*/
+
+// FFT-style slotToCoeff / coeffToSlot for bts in power of 2 cyclotomics
+class Po2IFFT
+{
+private:
+  const EncryptedArray& ea;
+  bool invert;   // apply transformation in inverse order. set to true for FFT
+  // one block matrix for (1) p=1 mod 4, or (2) Bruun FFT when p = 3 mod 4
+  // multiple block matrices for radix-2 FFT when p = 3 mod 4
+  NTL::Vec<std::unique_ptr<BlockMatMul1DExec>> mat1vec;
+  // regular matrices, evaluated in order when invert = false
+  NTL::Vec<std::unique_ptr<MatMul1DExec>> matvec;
+
+public:
+  Po2IFFT(const EncryptedArray& _ea,
+          bool _invert,
+          // _partition is a vector of positive integers, whose sum =
+          //   the number of basic matrices (intra/inter-slot, radix-2 FFT)
+          // the i-th IFFT matrix is the product of _partition[i] basic matrices
+          const std::vector<long>& _partition,
+          bool forceRadix2,
+          bool build_cache);
+
+  void upgrade();
+  void apply(Ctxt& ctxt) const;
+};
+
+
+//
+class ThinPo2IFFT
+{
+  private:
+    const EncryptedArray& ea;
+    bool invert;
+    // only those coefficients with the lowest `cnt_clear_bits` = 0 are kept
+    // others are set to 0
+    long cnt_clear_bits;
+    NTL::Vec<std::unique_ptr<BlockMatMul1DExec>> mat1vec;
+    NTL::Vec<std::unique_ptr<MatMul1DExec>> matvec;
+
+public:
+  ThinPo2IFFT(const EncryptedArray& _ea,
+          bool _invert,
+          const std::vector<long>& _partition,
+          bool forceRadix2,
+          bool build_cache,
+          bool dummy = false);
+
+  void upgrade();
+  void apply(Ctxt& ctxt) const;
+};
+
+
 } // namespace helib
 
 #endif // ifndef HELIB_EVALMAP_H
diff --git a/include/helib/NumbTh.h b/include/helib/NumbTh.h
index 4159870..01792f8 100644
--- a/include/helib/NumbTh.h
+++ b/include/helib/NumbTh.h
@@ -197,8 +197,8 @@ inline void ppInvert(NTL::mat_GF2E& X,
   NTL::inv(X, A);
 }
 
-void buildLinPolyMatrix(NTL::mat_zz_pE& M, long p);
-void buildLinPolyMatrix(NTL::mat_GF2E& M, long p);
+void buildLinPolyMatrix(NTL::mat_zz_pE& M, long p, bool subfield=false);
+void buildLinPolyMatrix(NTL::mat_GF2E& M, long p, bool subfield=false);
 
 //! @brief Combination of buildLinPolyMatrix and ppsolve.
 //!
diff --git a/include/helib/PAlgebra.h b/include/helib/PAlgebra.h
index 5652afc..61633cc 100644
--- a/include/helib/PAlgebra.h
+++ b/include/helib/PAlgebra.h
@@ -63,6 +63,8 @@ struct quarter_FFT
  * where the ei's range over 0,1,...,ord(gi)-1 and the ej's range over
  * 0,1,...ord(hj)-1 (these last orders are in (Z/mZ)^* /(p,g1,g2,...)).
  *
+ * NOTE: is this consistent with the description in HS20?
+ *
  * Phi_m(X) is factored as Phi_m(X)= prod_{t in T} F_t(X) mod p,
  * where the F_t's are irreducible modulo p. An arbitrary factor
  * is chosen as F_1, then for each t in T we associate with the index t the
@@ -92,10 +94,14 @@ class PAlgebra
 
   //  native[i] is true iff gens[i] has the same order in the quotient
   //  group as its order in Zm*.
+  // NOTE: native[i] = 1 iff gens[i] induces a good dimension
   NTL::Vec<bool> native;
 
   // frob_perturb[i] = j if gens[i] raised to its order equals p^j,
   // otherwise -1
+  // NOTE: frob_perturb[i] = log_p(gens[i]^ords[i])
+  //  which is 1 iff gens[i] induces a good dimension
+  //  it seems frob_perturb[i] cannot be -1
   NTL::Vec<long> frob_perturb;
 
   CubeSignature cube; // the hypercube structure of Zm* /(p)
@@ -121,14 +127,22 @@ class PAlgebra
   // for the method RecryptData::setAE in recryption.cpp. Also see
   // Appendix A of https://ia.cr/2014/873 (updated version from 2019)
 
-  std::vector<long> T;    // The representatives for the quotient group Zm* /(p)
-  std::vector<long> Tidx; // i=Tidx[t] is the index i s.t. T[i]=t.
-                          // Tidx[t]==-1 if t notin T
+  std::vector<long> T; // The representatives for the quotient group Zm* /(p)
+                       // NOTE: T[0] = (0,...,0) as (e0, ..., en)
+                       //       T[1] = (0,...,1) as (e0, ..., en), where ei is
+                       //       the exponent of gens[i]
+  std::vector<long>
+      Tidx; // i=Tidx[t] is the index i s.t. T[i]=t.
+            // Tidx[t]==-1 if t notin T
+            // NOTE: an array of length m, the inverse map of T (value to index)
 
   std::vector<long> zmsIdx; // if t is the i'th element in Zm* then zmsIdx[t]=i
                             // zmsIdx[t]==-1 if t notin Zm*
+                            // NOTE: an array of length m, inverse of zmsRep
 
   std::vector<long> zmsRep; // inverse of zmsIdx
+                            // NOTE: an array of length phi(m), stores all Zm*
+                            // elements in ascending order
 
   std::shared_ptr<PGFFT> fftInfo; // info for computing m-point complex FFT's
                                   // shard_ptr allows delayed initialization
@@ -520,11 +534,21 @@ private:
 
   /* the remaining fields are visible only to PAlgebraModDerived */
 
+  // NOTE: isomorphism: X \in R[X]/G -> maps[i] \in R[X]/Fi
   std::vector<RX> maps;
+  // NOTE: isomorphism: v^T w.r.t. X-basis in R[X]/G
+  //  -> v^T * matrix_maps[i] is the X-basis coeff vector in R[X]/Fi
   std::vector<mat_R> matrix_maps;
+  // NOTE: let X \in R[X]/G, rmaps[i] = Y - X^{1/ti} \in (R[X]/G)[Y]
+  //  not sure what it is. used in PAlgebraModDerived<type>::decodePlaintext
   std::vector<REX> rmaps;
 
 public:
+// XXX: debug
+  const mat_R &getMat(long i) const {
+    return matrix_maps[i];
+  }
+
   const RX& getG() const { return G; }
   long getDegG() const { return degG; }
   void restoreContextForG() const { contextForG.restore(); }
@@ -544,7 +568,8 @@ public:
         std::shared_ptr<TNode<T>> _right,
         const T& _data) :
       left(_left), right(_right), data(_data)
-  {}
+  {
+  }
 };
 
 template <typename T>
@@ -579,9 +604,19 @@ private:
 
   vec_RX factors;
   std::vector<NTL::ZZX> factorsOverZZ;
+  // NOTE: len(factors) size array, crtCoeffs[i] = \prod_{j\ne i} Fj^{-1} mod Fi
   vec_RX crtCoeffs;
+  // NOTE: the first dimension has length (number of gens)
+  //       maskTable[i] has length (order of gens[i])
+  //       maskTable[i][ord_i] has all slots as 0
+  //       maskTable[i][j] has slots indexed [j, ord_i-1] as 1 on dimension i,
+  //       with other slots 0
   std::vector<std::vector<RX>> maskTable;
+  // NOTE: len(factors) size array, crtTable[i] = 1 mod Fi, = 0 mod Fj (j \neq
+  // i)
   std::vector<RX> crtTable;
+  // NOTE:a binary tree storing the products of Fi's
+  //  i.e., the root stores the product of all Fi's, the i-th leaf stores Fi
   std::shared_ptr<TNode<RX>> crtTree;
 
   void genMaskTable();
@@ -825,7 +860,8 @@ public:
 
   explicit PAlgebraMod(const PAlgebra& zMStar, long r) :
       rep(buildPAlgebraMod(zMStar, r))
-  {}
+  {
+  }
   // constructor
 
   //! Downcast operator
diff --git a/include/helib/keys.h b/include/helib/keys.h
index c02eda4..fb480e5 100644
--- a/include/helib/keys.h
+++ b/include/helib/keys.h
@@ -41,6 +41,48 @@ namespace helib {
 #define HELIB_KSS_MIN (3)
 // minimal strategy (for g_i, and for g_i^{-ord_i} for bad dims)
 
+struct BootBench
+{
+  double time_linear_1 = 0;
+  double time_linear_2 = 0;
+  double time_extract = 0;
+  double time_total = 0;
+
+  double bits_down_linear_1 = 0;
+  double bits_down_linear_2 = 0;
+  double bits_down_extract = 0;
+  double bits_final = 0;
+  double bits_after_inner_prod = 0;
+
+  BootBench& operator+=(const BootBench& another)
+  {
+    time_linear_1 += another.time_linear_1;
+    time_linear_2 += another.time_linear_2;
+    time_extract += another.time_extract;
+    time_total += another.time_total;
+
+    bits_down_linear_1 += another.bits_down_linear_1;
+    bits_down_linear_2 += another.bits_down_linear_2;
+    bits_down_extract += another.bits_down_extract;
+    bits_final += another.bits_final;
+    bits_after_inner_prod += another.bits_after_inner_prod;
+    return *this;
+  }
+
+  void Mult(double x) {
+    time_linear_1 *= x;
+    time_linear_2 *= x;
+    time_extract *= x;
+    time_total *= x;
+
+    bits_down_linear_1 *= x;
+    bits_down_linear_2 *= x;
+    bits_down_extract *= x;
+    bits_final *= x;
+    bits_after_inner_prod *= x;
+  }
+};
+
 /**
  * @class PubKey
  * @brief The public key
@@ -232,9 +274,16 @@ public:
   // NOTE: Is taking the alMod from the context the right thing to do?
 
   bool isBootstrappable() const;
-  void reCrypt(Ctxt& ctxt) const;     // bootstrap a ciphertext to reduce noise
-  void thinReCrypt(Ctxt& ctxt) const; // bootstrap a "thin" ciphertext, where
+  BootBench reCrypt(Ctxt& ctxt) const; // bootstrap a ciphertext to reduce noise
+  // general bootstrapping... 
+  //  1. without extracting the overflow part
+  //  2. (optional) with SlotToCoeff before decryption formula simplification
+  BootBench reCryptRefine(Ctxt& ctxt) const; // bootstrap a ciphertext to reduce noise
+  BootBench thinReCrypt(
+      Ctxt& ctxt) const; // bootstrap a "thin" ciphertext, where
   // slots are assumed to contain constants
+  // thin bootstrap without extracting the overflow part
+  BootBench thinReCryptRefine(Ctxt &ctxt) const;
 
   friend class SecKey;
   friend std::ostream& operator<<(std::ostream& str, const PubKey& pk);
@@ -365,7 +414,8 @@ public:
                       long fromXPower,
                       long fromKeyIdx = 0,
                       long toKeyIdx = 0,
-                      long ptxtSpace = 0);
+                      long ptxtSpace = 0,
+                      bool toNewBootKey = false);
 
   // Decryption
   void Decrypt(NTL::ZZX& plaintxt, const Ctxt& ciphertxt) const;
diff --git a/include/helib/matmul.h b/include/helib/matmul.h
index d048f20..e717d80 100644
--- a/include/helib/matmul.h
+++ b/include/helib/matmul.h
@@ -86,6 +86,8 @@ public:
 template <typename type>
 class MatMul1D_partial : public MatMul1D
 {
+  // NOTE: an ugly hack...
+  const std::vector<long> _vec = {};
 public:
   PA_INJECT(type)
 
@@ -95,6 +97,18 @@ public:
   virtual void processDiagonal(RX& poly,
                                long i,
                                const EncryptedArrayDerived<type>& ea) const = 0;
+
+  // NOTE: get the indices of the nonzero diagonals.
+  //   the default implementation returns an empty set,
+  //   meaning all diagonals are nonzero
+  virtual const std::vector<long>& nonzeroDiagnoals() const;
+  // NOTE: 0 for non-multi-dim
+  // -1 for row manipulation (FFT)
+  // 1 for column manipulation (IFFT)
+  virtual int multiDimInfo() const;
+  virtual const NTL::Mat<RX>& getPo2MultiDimMat() const;
+private:
+  const NTL::Mat<RX> _mat;
 };
 
 // Concrete derived class that defines the matrix entries.
@@ -152,11 +166,13 @@ private:
 public:
   MatMul_CKKS(const EncryptedArray& _ea, get_fun_type _get_fun) :
       ea(_ea), get_fun(_get_fun)
-  {}
+  {
+  }
 
   MatMul_CKKS(const Context& context, get_fun_type _get_fun) :
       ea(context.getEA()), get_fun(_get_fun)
-  {}
+  {
+  }
 
   virtual const EncryptedArray& getEA() const override { return ea; }
 
@@ -181,11 +197,13 @@ private:
 public:
   MatMul_CKKS_Complex(const EncryptedArray& _ea, get_fun_type _get_fun) :
       ea(_ea), get_fun(_get_fun)
-  {}
+  {
+  }
 
   MatMul_CKKS_Complex(const Context& context, get_fun_type _get_fun) :
       ea(context.getEA()), get_fun(_get_fun)
-  {}
+  {
+  }
 
   virtual const EncryptedArray& getEA() const override { return ea; }
 
@@ -213,6 +231,7 @@ public:
 template <typename type>
 class BlockMatMul1D_partial : public BlockMatMul1D
 {
+  const std::vector<long> _vec = {};
 public:
   PA_INJECT(type)
 
@@ -223,6 +242,13 @@ public:
   virtual bool processDiagonal(std::vector<RX>& poly,
                                long i,
                                const EncryptedArrayDerived<type>& ea) const = 0;
+
+  // NOTE: get the indices of the nonzero diagonals
+  //   the default implementation returns an empty set, meaning all diagonals
+  //   are nonzero
+  virtual const std::vector<long>& nonzeroDiagnoals() const;
+  // NOTE: if the map is on a degree-2 subfield of the slot algebra
+  virtual bool isSubField() const;
 };
 
 // Concrete derived class that defines the matrix entries.
@@ -298,11 +324,28 @@ public:
   long D;
   bool native;
   bool minimal;
+  bool dummy;
   long g;
 
+  // NOTE: for fast computation on sparse matrices with special structures
+  // NOTE: the vectors should always be non-empty!!!
+  std::vector<long> diag_indices;
+  std::vector<long> giant_step_indices;
+  std::vector<long> baby_indices;
+  // in some situations, the role of baby & giant steps can be swapped
+  //  for faster computation
+  bool swap_baby_giant; 
+
   ConstMultiplierCache cache;
   ConstMultiplierCache cache1; // only for non-native dimension
 
+  // NOTE: for two MatMul1D (a very special case of MatMulFull)
+  //  for Po2 bts, this happens in the last IFFT matrix
+  //  we don't use MatMulFull to obtain better performance by reusing some variables
+  bool multiDim;
+  ConstMultiplierCache cacheX;
+  ConstMultiplierCache cacheX1;
+
   // The constructor encodes all the constants for a given
   // matrix in zzX format.
   // The mat argument defines the entries of the matrix.
@@ -313,7 +356,7 @@ public:
   // addMinimal{1D,Frb}Matrices routines declared in helib.h.
   // If the minimal flag is false, it is best to use the
   // addSome{1D,Frb}Matrices routines declared in helib.h.
-  explicit MatMul1DExec(const MatMul1D& mat, bool minimal = false);
+  explicit MatMul1DExec(const MatMul1D& mat, bool minimal = false, bool dummy = false);
 
   // VJS-FIXME: it seems that the minimal flag is currently
   // redundant, as the decision is essentially based on
@@ -328,6 +371,8 @@ public:
   {
     cache.upgrade(ea.getContext());
     cache1.upgrade(ea.getContext());
+    cacheX.upgrade(ea.getContext());
+    cacheX1.upgrade(ea.getContext());
   }
 
   const EncryptedArray& getEA() const override { return ea; }
@@ -357,6 +402,17 @@ public:
   bool native;
   long strategy;
 
+  // NOTE: for fast computation on sparse matrices with special structures
+  //  these information should be obtained from BlockMatMul1D
+  // NOTE: `diag_indices` should be sorted in the ascending order
+  //  these vectors should always be non-empty
+  std::vector<long> diag_indices;
+  std::vector<long> giant_step_indices;
+  std::vector<long> baby_step_indices;
+  // bool giant_step_divides_gap;
+  std::vector<long> frob_indices;
+  // NOTE: cache.multiplier[i*d1+j] stores k'(i,j), cache1.multiplier[i*d1+j]
+  // stores k''(i,j)
   ConstMultiplierCache cache;
   ConstMultiplierCache cache1; // only for non-native dimension
 
diff --git a/include/helib/polyEval.h b/include/helib/polyEval.h
index 6e32547..5299488 100644
--- a/include/helib/polyEval.h
+++ b/include/helib/polyEval.h
@@ -30,6 +30,11 @@ namespace helib {
 void polyEval(Ctxt& ret, NTL::ZZX poly, const Ctxt& x, long k = 0);
 // Note: poly is passed by value, so caller keeps the original
 
+// evaluate multiple polynomials on the same ctxt
+// the polynomials should be odd
+// k is the size of the baby step
+void polyEvalNew(std::vector<Ctxt*>& ret, NTL::vec_ZZX poly, const Ctxt& x, long k = 0);
+
 //! @brief Evaluate an encrypted polynomial on an encrypted input
 //! @param[out] res  to hold the return value
 //! @param[in]  poly the degree-d polynomial to evaluate
diff --git a/include/helib/recryption.h b/include/helib/recryption.h
index 2880968..719e22b 100644
--- a/include/helib/recryption.h
+++ b/include/helib/recryption.h
@@ -27,6 +27,8 @@ class PAlgebraMod;
 class EncryptedArray;
 class EvalMap;
 class ThinEvalMap;
+class Po2IFFT;
+class ThinPo2IFFT;
 class PowerfulDCRT;
 class Context;
 class PubKey;
@@ -42,7 +44,10 @@ public:
   //! skey encrypted wrt space p^{e-e'+r}
   long e, ePrime;
 
+  long eNew, t;
+
   //! Hamming weight of recryption secret key
+  // NOTE: this is equal to encapSkHwt in Context
   long skHwt;
 
   //! for plaintext space p^{e-e'+r}
@@ -55,9 +60,15 @@ public:
 
   bool alsoThick;
 
+  bool newBtsFlag;
+
+  bool isPo2;
+
   //! linear maps
   std::shared_ptr<const EvalMap> firstMap = nullptr, secondMap = nullptr;
 
+  std::shared_ptr<const Po2IFFT> firstPo2Map = nullptr, secondPo2Map = nullptr;
+
   //! conversion between ZZX and Powerful
   std::shared_ptr<const PowerfulDCRT> p2dConv = nullptr;
 
@@ -70,6 +81,8 @@ public:
     e = ePrime = 0;
     build_cache = false;
     alsoThick = false;
+    eNew = t = 0;
+    newBtsFlag = false;
   }
 
   //! Initialize the recryption data in the context
@@ -86,10 +99,29 @@ public:
   }
 
   //! Helper function for computing the recryption parameters
-  static void setAE(long& e, long& ePrime, const Context& context);
+  static double setAE(long& e, long& ePrime, const Context& context);
   // VJS-FIXME: this needs to be documented.
   // It is based on the most recent version of our bootstrapping
   // paper (see Section 6.2)
+
+  // Helper function for computing the recryption parameters,
+  //  but using the encapsulated bootstrapping key
+  static double setEncapAE(long& e,
+                           long& ePrime,
+                           long& qks,
+                           long& R,
+                           long nDgtsBTS,
+                           const Context& context);
+
+  // Helper function for computing the new recryption parameters
+  static double setNewBootAE(long& eNew,
+                             long& t,
+                             long& aux,
+                             long& qks,
+                             long& R,
+                             long& numExtract,
+                             long nDgtsBTS,
+                             const Context& context);
 };
 
 //! @class ThinRecryptData
@@ -101,6 +133,9 @@ public:
   //! linear maps
   std::shared_ptr<const ThinEvalMap> coeffToSlot, slotToCoeff;
 
+  // Po2 linear maps
+  std::shared_ptr<const ThinPo2IFFT> coeffToSlotPo2, slotToCoeffPo2;
+
   //! Initialize the recryption data in the context
   void init(const Context& context,
             const NTL::Vec<long>& mvec_,
diff --git a/misc/params1a.cpp b/misc/params1a.cpp
index 295d9ad..2957841 100644
--- a/misc/params1a.cpp
+++ b/misc/params1a.cpp
@@ -99,6 +99,11 @@ int main(int argc, char *argv[])
    long m_arg = 0;
    amap.arg("m", m_arg, "use only the specified m value", nullptr);
 
+   long nfacs_arg = 4;
+   amap.arg("nfac", nfacs_arg, "the maximum number of primes factors of m");
+
+   long ngens_arg = 4;
+   amap.arg("ngen", ngens_arg, "the maximum number of generators");
 
    amap.parse(argc, argv);
 
@@ -128,13 +133,16 @@ int main(int argc, char *argv[])
 
       if (k == 1) continue;
 
+      if (k > nfacs_arg)
+         continue;
+
       bool sqrfree = true;
       for (long i = 0; i < k; i++) {
         if (fac[i].b > 1) sqrfree = false;
       }
       //if (!sqrfree) continue;
 
-
+      // prime power factors
       Vec<long> fac1;
       fac1.SetLength(k);
 
@@ -158,12 +166,14 @@ int main(int argc, char *argv[])
       long best_cost = NTL_MAX_LONG;
       long best_depth = NTL_MAX_LONG;
 
-      for (long i = 0; i < k; i++) {
+      for (long i = 0; i < k; i++) { // choose m_0
          long m1 = fac1[i];
          long phim1 = phivec[i];
+         // we want d1 = d
          if (multOrd(p, m1) != d) continue;
 
          PAlgebra pal1(m1, p);
+         // we want a cyclic group
          if (pal1.numOfGens() > 1) continue;
 
          bool good = (pal1.numOfGens() == 0 ||
@@ -229,10 +239,11 @@ int main(int argc, char *argv[])
       Vec<long> fac2;
 
       fac2 = fac1;
-
+      // move the gen prime factor to the front
       for (long i = gen_index-1; i >= 0; i--)
         swap(fac2[i], fac2[i+1]);
 
+      // this is never triggered
       if (gen_index2 != -1) {
          for (long i = gen_index2; i < k-1; i++)
             swap(fac2[i], fac2[i+1]);
@@ -281,6 +292,10 @@ int main(int argc, char *argv[])
 
 
       if (info_flag) {
+         if (trunc(rev(global_gen)).length() > ngens_arg)
+            continue;
+
+
          cout << setw(6) << phim << "  ";
          cout << setw(4) << d << "  ";
          cout << setw(6) << m << "  ";
diff --git a/src/Context.cpp b/src/Context.cpp
index f698110..4f782cb 100644
--- a/src/Context.cpp
+++ b/src/Context.cpp
@@ -83,6 +83,11 @@ struct Context::ModChainParams
   long bitsInSpecialPrimes;
   double stdev;
   double scale;
+  // newly added
+  long encapSkHwt; // hwt of the encapsulated sk (used only in bts)
+  double btsScale; // scale parameter used to bound the overflow parts
+  long btsC;       // number of ks digits before bootstrap
+  long t;          // the hensel lifting param for the aux modulus
 };
 
 struct Context::BootStrapParams
@@ -90,6 +95,12 @@ struct Context::BootStrapParams
   NTL::Vec<long> mvec;
   bool buildCacheFlag;
   bool thickFlag;
+  bool newBtsFlag;
+  bool newKSFlag;
+  bool forceRadix2;
+  std::vector<long> FFT_partition;
+  bool dummy;
+  bool s2cFirstFlag;
 };
 
 struct Context::SerializableContent
@@ -658,15 +669,25 @@ Context::Context(long m,
   if (mparams) {
     this->stdev = mparams->stdev;
     this->scale = mparams->scale;
+    this->btsScale = mparams->btsScale;
+    this->btsDigits = mparams->btsC;
 
     this->buildModChain(mparams->bits,
                         mparams->c,
                         mparams->bootstrappableFlag,
                         mparams->skHwt,
                         mparams->resolution,
-                        mparams->bitsInSpecialPrimes);
+                        mparams->bitsInSpecialPrimes,
+                        mparams->encapSkHwt,
+                        bparams->newBtsFlag,
+                        bparams->newKSFlag,
+                        mparams->t);
 
     if (mparams->bootstrappableFlag && bparams) {
+      this->forceRadix2 = bparams->forceRadix2;
+      this->FFT_partition = bparams->FFT_partition;
+      this->dummy = bparams->dummy;
+      this->s2cFirstFlag = bparams->s2cFirstFlag;
       this->enableBootStrapping(bparams->mvec,
                                 bparams->buildCacheFlag,
                                 bparams->thickFlag);
@@ -873,7 +894,8 @@ void Context::addCtxtPrimes(long nBits, long targetSize)
 
 void Context::addSpecialPrimes(long nDgts,
                                bool willBeBootstrappable,
-                               long bitsInSpecialPrimes)
+                               long bitsInSpecialPrimes,
+                               long nDgtsBTS)
 {
   const PAlgebra& palg = getZMStar();
   long p = std::abs(palg.getP()); // for CKKS, palg.getP() == -1
@@ -883,14 +905,98 @@ void Context::addSpecialPrimes(long nDgts,
 
   long p2e = p2r;
   if (willBeBootstrappable && !isCKKS()) {
-    // bigger p^e for bootstrapping
-    long e, ePrime;
-    RecryptData::setAE(e, ePrime, *this);
-    p2e *= NTL::power_long(p, e - ePrime);
-
-    // initialize e and ePrime parameters in the context
-    this->e_param = e;
-    this->ePrime_param = ePrime;
+    if (newBtsFlag) {
+      assertTrue(newKSFlag, "new KS flag should always be true for the new BTS");
+      // since we use the new bootstrap, parameters need to be set in a
+      // different way t_param is already set, now we just to check its validity
+      // and set eNew and aux
+      long t = getT();
+      long eNew, aux, qks, R, numExtract;
+      minCapacity = RecryptData::setNewBootAE(eNew, t, aux, qks, R, numExtract, nDgtsBTS, *this);
+      if (t > 0)
+        p2e *= NTL::power_long(p, t);
+      this->t_param = t; // t is updated
+      this->eNew_param = eNew;
+      this->aux_param = aux;
+      this->numExtract_param = numExtract;
+
+      // add qks and R to the moduli vector
+      assertFalse(inChain(qks),
+                  "KS prime q for bootstrap is already in the prime chain");
+      assertFalse(inChain(R),
+                  "KS aux prime R for bootstrap is already in the prime chain");
+      index_qks = moduli.size();
+      moduli.push_back(Cmodulus(zMStar, qks, 0));
+      this->btsBaseKS =
+          ceil(pow(qks, 1.0 / btsDigits)); // base-btsBaseKS decomposition, no
+                                           // longer mixed-radix
+      while(true) {
+        long dgtHi = (this->btsBaseKS-1)>>1;
+        long tmp = 1;
+        // make sure (1+baseKS+...+baseKS^(ndgts-1))*dgtHi can represent up to qks / 2
+        for(long i = 1; i < btsDigits; i++)
+          tmp = this->btsBaseKS * tmp + 1;
+        tmp *= dgtHi;
+        if (tmp >= qks / 2)
+          break;
+        this->btsBaseKS++;
+      }
+
+      index_R = moduli.size();
+      moduli.push_back(Cmodulus(zMStar, R, 0));
+      // finally add some mod-up primes
+      // two 50-bits primes will do
+      PrimeGenerator modUpGen(50, m);
+      int genCount = 0;
+      while(genCount < 2) {
+        long genPrime = modUpGen.next();
+        if(!inChain(genPrime)) {
+          modUpPrimes.insert(moduli.size());
+          moduli.push_back(Cmodulus(zMStar, genPrime, 0));
+          genCount += 1;
+        }
+      }
+    } else if (newKSFlag) { // native BTS with new KS
+      long e, ePrime, qks, R;
+      minCapacity = RecryptData::setEncapAE(e, ePrime, qks, R, nDgtsBTS, *this);
+      p2e *= NTL::power_long(p, e - ePrime);
+
+      this->e_param = e;
+      this->ePrime_param = ePrime;
+      
+      assertFalse(inChain(qks),
+                  "KS prime q for bootstrap is already in the prime chain");
+      assertFalse(inChain(R),
+                  "KS aux prime R for bootstrap is already in the prime chain");
+      index_qks = moduli.size();
+      moduli.push_back(Cmodulus(zMStar, qks, 0));
+      this->btsBaseKS =
+          ceil(pow(qks, 1.0 / btsDigits)); // base-btsBaseKS decomposition, no
+                                           // longer mixed-radix
+      while(true) {
+        long dgtHi = (this->btsBaseKS-1)>>1;
+        long tmp = 1;
+        // make sure (1+baseKS+...+baseKS^(ndgts-1))*dgtHi can represent up to qks / 2
+        for(long i = 1; i < btsDigits; i++)
+          tmp = this->btsBaseKS * tmp + 1;
+        tmp *= dgtHi;
+        if (tmp >= qks / 2)
+          break;
+        this->btsBaseKS++;
+      }
+
+      index_R = moduli.size();
+      moduli.push_back(Cmodulus(zMStar, R, 0));
+    } else { // native BTS
+      // bigger p^e for bootstrapping
+      long e, ePrime;
+      minCapacity = RecryptData::setAE(e, ePrime, *this);
+      p2e *= NTL::power_long(p, e - ePrime);
+
+      // initialize e and ePrime parameters in the context
+      this->e_param = e;
+      this->ePrime_param = ePrime;
+    }
   }
 
   long nCtxtPrimes = getCtxtPrimes().card();
@@ -1027,6 +1133,11 @@ void Context::addSpecialPrimes(long nDgts,
     nPrimes--;
   }
 
+  // print the security level early here
+  std::cout << "INFO: total bits = " << logOfProduct(getCtxtPrimes() | getSpecialPrimes()) / log(2.0)
+     << ", security level = " << securityLevel() << std::endl;
+  std::flush(std::cout);
+
   // std::cerr << "*** specialPrimes excess: " <<
   // (logOfProduct(specialPrimes)/std::log(2.0) - nBits) <<
   // "\n";
@@ -1039,13 +1150,18 @@ void Context::buildModChain(long nBits,
                             bool willBeBootstrappable,
                             long skHwt,
                             long resolution,
-                            long bitsInSpecialPrimes)
+                            long bitsInSpecialPrimes,
+                            long encapSkHwt,
+                            bool newBts,
+                            bool newKS,
+                            long t)
 {
   // Cannot build modulus chain with nBits < 0
   assertTrue<InvalidArgument>(nBits > 0,
                               "Cannot initialise modulus chain with nBits < 1");
 
   assertTrue(skHwt >= 0, "invalid skHwt parameter");
+  assertTrue(encapSkHwt >= 0, "invalid encapSkHwt parameter");
 
   // ignore for CKKS
   if (isCKKS())
@@ -1057,13 +1173,21 @@ void Context::buildModChain(long nBits,
       skHwt = BOOT_DFLT_SK_HWT;
   }
 
+  if (encapSkHwt == 0 && willBeBootstrappable)
+    encapSkHwt =
+        skHwt; // if not specified, fall back to the default hwt in helib
+
   // initialize hwt param in context
   hwt_param = skHwt;
+  encapHwt_param = encapSkHwt;
+  newBtsFlag = newBts;
+  newKSFlag = newKS;
+  t_param = t; // t_param can be set manually (be setting t > 0)
 
   long pSize = ctxtPrimeSize(nBits);
   addSmallPrimes(resolution, pSize);
   addCtxtPrimes(nBits, pSize);
-  addSpecialPrimes(nDgts, willBeBootstrappable, bitsInSpecialPrimes);
+  addSpecialPrimes(nDgts, willBeBootstrappable, bitsInSpecialPrimes, btsDigits);
 
   CheckPrimes(*this, smallPrimes, "smallPrimes");
   CheckPrimes(*this, ctxtPrimes, "ctxtPrimes");
@@ -1106,13 +1230,19 @@ ContextBuilder<SCHEME>::makeParamsArgs() const
                                                          resolution_,
                                                          bitsInSpecialPrimes_,
                                                          stdev_,
-                                                         scale_})
+                                                         scale_,
+                                                         encapSkHwt_,
+                                                         btsScale_,
+                                                         btsC_,
+                                                         t_})
           : std::nullopt;
 
-  const auto bparams = bootstrappableFlag_
-                           ? std::make_optional<Context::BootStrapParams>(
-                                 {mvec_, buildCacheFlag_, thickFlag_})
-                           : std::nullopt;
+  const auto bparams =
+      bootstrappableFlag_
+          ? std::make_optional<Context::BootStrapParams>(
+                {mvec_, buildCacheFlag_, thickFlag_, newBtsFlag_, newKSFlag_, 
+                  forceRadix2_, FFT_partition_, dummy_, s2cFirstFlag_})
+          : std::nullopt;
 
   return {mparams, bparams};
 }
@@ -1133,7 +1263,7 @@ Context* ContextBuilder<SCHEME>::buildPtr() const
 
 // Essentially serialization of params.
 template <>
-std::ostream& operator<<<BGV>(std::ostream& os, const ContextBuilder<BGV>& cb)
+std::ostream& operator<< <BGV>(std::ostream& os, const ContextBuilder<BGV>& cb)
 {
   const json j = {{"scheme", "bgv"},
                   {"m", cb.m_},
@@ -1156,7 +1286,8 @@ std::ostream& operator<<<BGV>(std::ostream& os, const ContextBuilder<BGV>& cb)
 }
 
 template <>
-std::ostream& operator<<<CKKS>(std::ostream& os, const ContextBuilder<CKKS>& cb)
+std::ostream& operator<< <CKKS>(std::ostream& os,
+                                const ContextBuilder<CKKS>& cb)
 {
   const json j = {{"scheme", "ckks"},
                   {"m", cb.m_},
diff --git a/src/Ctxt.cpp b/src/Ctxt.cpp
index b346fcd..4f321ad 100644
--- a/src/Ctxt.cpp
+++ b/src/Ctxt.cpp
@@ -174,6 +174,8 @@ void Ctxt::DummyEncrypt(const NTL::ZZX& ptxt, double size)
 
 // Sanity-check: Check that prime-set is "valid", i.e. that it
 // contains either all the special primes or none of them
+// for the bringToSet in new bts, since s is intersected with the CtxtPrimes,
+// qKS will not be a problem
 bool Ctxt::verifyPrimeSet() const
 {
   IndexSet s =
@@ -188,12 +190,24 @@ bool Ctxt::verifyPrimeSet() const
 // Multiply vector of digits by key-switching matrix and add to *this.
 // It is assumed that W has at least as many b[i]'s as there are digits.
 // The vector of digits is modified in place.
-void Ctxt::keySwitchDigits(const KeySwitch& W, std::vector<DoubleCRT>& digits)
+void Ctxt::keySwitchDigits(const KeySwitch& W,
+                           std::vector<DoubleCRT>& digits,
+                           bool toNewBootKey)
 { // An object to hold the pseudorandom ai's, note that it must be defined
   // with the maximum number of levels, else the PRG will go out of sync.
   // FIXME: This is a bug waiting to happen.
 
-  DoubleCRT ai(context, context.getCtxtPrimes() | context.getSpecialPrimes());
+  IndexSet newPrimeSet;
+  if (toNewBootKey) {
+    newPrimeSet.insert(context.getIndexQks());
+    newPrimeSet.insert(context.getIndexR());
+    // sanity check
+    for (auto& dgt : digits)
+      assertTrue(dgt.getIndexSet() == newPrimeSet,
+                 "digit is not modulo qKS * R");
+  } else
+    newPrimeSet = context.getCtxtPrimes() | context.getSpecialPrimes();
+  DoubleCRT ai(context, newPrimeSet);
 
   // Subsequent ai's use the evolving RNG state
   RandomState state; // backup the NTL PRG seed
@@ -717,7 +731,7 @@ void Ctxt::relin_CKKS_adjust()
 
 // key-switch to (1,s_i), s_i is the base key with index keyID. If
 // keyID<0 then re-linearize to any key for which a switching matrix exists
-void Ctxt::reLinearize(long keyID)
+void Ctxt::reLinearize(long keyID, bool toNewBootKey)
 {
   HELIB_TIMER_START;
   // Special case: if *this is empty or already re-linearized then do nothing
@@ -729,8 +743,13 @@ void Ctxt::reLinearize(long keyID)
   // HERE
   std::cerr << "*** reLinearlize: " << primeSet;
 #endif
-
-  dropSmallAndSpecialPrimes();
+  // new sanity check
+  assertFalse(toNewBootKey && (primeSet != IndexSet(context.getIndexQks())),
+              "only qKS is expected");
+  // when switching to the boot key in the new bts,
+  // ctxt has a modulus of qks, which will be dropped by this
+  if (!toNewBootKey)
+    dropSmallAndSpecialPrimes();
 
 #if 0
   // HERE
@@ -746,14 +765,19 @@ void Ctxt::reLinearize(long keyID)
   relin_CKKS_adjust();
 
   long g = ptxtSpace;
-  double logProd = context.logOfProduct(context.getSpecialPrimes());
+  IndexSet newSpecialPrimeSet;
+  if (toNewBootKey)
+    newSpecialPrimeSet.insert(context.getIndexR());
+  else
+    newSpecialPrimeSet = context.getSpecialPrimes();
+  double logProd = context.logOfProduct(newSpecialPrimeSet);
 
   Ctxt tmp(pubKey, ptxtSpace); // an empty ciphertext, same plaintext space
   tmp.intFactor = intFactor;   // same intFactor, too
   tmp.ptxtMag = ptxtMag;       // same CKKS plaintext size
   tmp.noiseBound = noiseBound * NTL::xexp(logProd); // The noise after mod-up
 
-  tmp.primeSet = primeSet | context.getSpecialPrimes();
+  tmp.primeSet = primeSet | newSpecialPrimeSet;
   // VJS-NOTE: added this to make addPart work
 
   tmp.ratFactor = ratFactor * NTL::xexp(logProd); // CKKS factor after mod-up
@@ -762,7 +786,7 @@ void Ctxt::reLinearize(long keyID)
   for (CtxtPart& part : parts) {
     // For a part relative to 1 or base,  only scale and add
     if (part.skHandle.isOne() || part.skHandle.isBase(keyID)) {
-      part.addPrimesAndScale(context.getSpecialPrimes());
+      part.addPrimesAndScale(newSpecialPrimeSet);
       tmp.addPart(part, /*matchPrimeSet=*/true);
       continue;
     }
@@ -779,7 +803,10 @@ void Ctxt::reLinearize(long keyID)
       g = tmp.ptxtSpace;
       // VJS-NOTE: fixes a bug where intFactor was not corrected
     }
-    tmp.keySwitchPart(part, W); // switch this part & update noiseBound
+    // XXX: this has to be changed
+    tmp.keySwitchPart(part,
+                      W,
+                      toNewBootKey); // switch this part & update noiseBound
   }
   *this = tmp;
   // std::cerr << "====== " << ratFactor << "\n";
@@ -802,19 +829,35 @@ Ctxt& Ctxt::cleanUp()
 // It is assumed that the part p does not include any of the special
 // primes, and that if *this is not an empty ciphertext then its
 // primeSet is p.getIndexSet() \union context.specialPrimes
-void Ctxt::keySwitchPart(const CtxtPart& p, const KeySwitch& W)
+void Ctxt::keySwitchPart(const CtxtPart& p,
+                         const KeySwitch& W,
+                         bool toNewBootKey)
 {
   HELIB_TIMER_START;
 
+  if (toNewBootKey) { // new sanity check
+    IndexSet expectedSet;
+    expectedSet.insert(context.getIndexQks());
+    expectedSet.insert(context.getIndexR());
+    assertFalse(p.getIndexSet() != IndexSet(context.getIndexQks()) ||
+                    primeSet != expectedSet,
+                "new boot ks expects qKS+R");
+  }
+
+  IndexSet newSpecialPrimes;
+  if (toNewBootKey)
+    newSpecialPrimes.insert(context.getIndexR());
+  else
+    newSpecialPrimes = context.getSpecialPrimes();
   // no special primes in the input part
   assertTrue(
-      context.getSpecialPrimes().disjointFrom(p.getIndexSet()),
+      newSpecialPrimes.disjointFrom(p.getIndexSet()),
       "Special primes and CtxtPart's index set have non-empty intersection");
 
   // For parts p that point to 1 or s, only scale and add
   if (p.skHandle.isOne() || p.skHandle.isBase(W.toKeyID)) {
     CtxtPart pp = p;
-    pp.addPrimesAndScale(context.getSpecialPrimes());
+    pp.addPrimesAndScale(newSpecialPrimes);
     addPart(pp, /*matchPrimeSet=*/true);
     return;
   }
@@ -824,11 +867,17 @@ void Ctxt::keySwitchPart(const CtxtPart& p, const KeySwitch& W)
   assertEq(W.fromKey, p.skHandle, "Secret key handles do not match");
 
   std::vector<DoubleCRT> polyDigits;
-  NTL::xdouble addedNoise = p.breakIntoDigits(polyDigits);
+  // NOTE: use non-RNS decomposition
+  // TODO: check against the estimated noise bound?
+  NTL::xdouble addedNoise;
+  if (toNewBootKey)
+    addedNoise = p.breakIntoDigitsNonRNS(polyDigits);
+  else
+    addedNoise = p.breakIntoDigits(polyDigits);
   addedNoise *= W.noiseBound;
 
   // Finally we multiply the vector of digits by the key-switching matrix
-  keySwitchDigits(W, polyDigits);
+  keySwitchDigits(W, polyDigits, toNewBootKey);
 
   double ratio = NTL::conv<double>(addedNoise / noiseBound);
 
@@ -836,6 +885,7 @@ void Ctxt::keySwitchPart(const CtxtPart& p, const KeySwitch& W)
 
   if (ratio > 1) {
     Warning("KS-noise-ratio=" + std::to_string(ratio));
+    std::cerr << "WARNING: KS-noise-ratio = " << ratio << " > 1\n";
   }
 
   noiseBound += addedNoise; // update the noise estimate
@@ -3048,6 +3098,104 @@ double Ctxt::rawModSwitch(std::vector<NTL::ZZX>& zzParts, long q) const
   // this is returned so that caller in recryption.cpp can check bounds
 }
 
+// Special-purpose modulus-switching for bootstrapping.
+// Requires q to divide the current ctxt modulus.
+// Returns an estimate for the scaled noise (not including the
+// additive mod switching noise)
+double Ctxt::rawModSwitchNew(std::vector<NTL::ZZX>& zzParts, long q) const
+{
+  // Ensure that new modulus is co-prime with plaintext space
+  const long p2r = getPtxtSpace();
+  assertTrue<InvalidArgument>(q > 1, "q must be greater than 1");
+  assertTrue(p2r > 1,
+             "Plaintext space must be greater than 1 for mod switching");
+  assertEq(NTL::GCD(q, p2r),
+           1l,
+           "New modulus and current plaintext space must be co-prime");
+
+  // Compute also the ratio modulo ptxtSpace
+  {
+    IndexSet expSet;
+    expSet.insert(context.getIndexQks());
+    expSet.insert(context.getIndexR());
+    assertTrue(primeSet == expSet, "input ctxt modulus should be qKS*R");
+    assertTrue(q == context.ithPrime(context.getIndexQks()),
+               "q should be equal to qKS");
+  }
+
+  // mod switch from qKS*R to R (in the pwfl basis)
+  NTL::ZZ qKS(context.ithPrime(context.getIndexQks()));
+  NTL::ZZ R(context.ithPrime(context.getIndexR()));
+
+  // Compute the ratio between the current modulus and the new one.
+  // essentially 1/R
+  NTL::xdouble ratio = NTL::xdouble(1.0) / NTL::xdouble(NTL::to_long(R));
+
+  // Scale and round all the integers in all the parts
+  zzParts.resize(parts.size());
+  const PowerfulDCRT& p2d_conv = *context.getRcData().p2dConv;
+  for (long i : range(parts.size())) {
+#if 0 // XXX: I don't why this is not working, am I mistaking something???
+    // following the RNS-style BGV modulus switching
+    NTL::Vec<NTL::ZZ> pwrfl_qKS, pwrfl_R;
+    DoubleCRT mod_qKS = parts[i], mod_R = parts[i];
+    mod_qKS.setPrimes(IndexSet(context.getIndexQks()));
+    mod_R.setPrimes(IndexSet(context.getIndexR()));
+    p2d_conv.dcrtToPowerful(pwrfl_qKS, mod_qKS);
+    p2d_conv.dcrtToPowerful(pwrfl_R, mod_R);
+
+    // vecRed(pwrfl, pwrfl, Q, false);
+    // reduce to interval [-Q/2,+Q/2]
+    // FIXME: it looks like the coefficients should already be reduced
+
+    // add -[a]_R*P*[P^-1]_R = -P*[a*P^-1]_R to the element modulo qKS
+    // the mult it by [R^-1]_qKS
+    NTL::ZZ pInvR = NTL::InvMod(NTL::ZZ(p2r), R);
+    NTL::ZZ RInvQks = NTL::InvMod(R, qKS);
+    NTL::ZZ tmp;
+    for(long j = 0; j < pwrfl_qKS.length(); j++) {
+      // TODO: use NTL's precon to accelerate?
+      tmp = NTL::MulMod(pwrfl_R[j], pInvR, R);
+      // if (tmp > R / 2)
+      //   tmp -= R;
+      tmp = NTL::MulMod(tmp, p2r, qKS);
+      pwrfl_qKS[j] = NTL::SubMod(pwrfl_qKS[j], tmp, qKS);
+      pwrfl_qKS[j] = NTL::MulMod(pwrfl_qKS[j], RInvQks, qKS);
+    }
+    helib::vecRed(pwrfl_qKS, pwrfl_qKS, qKS, false);
+    p2d_conv.powerfulToZZX(zzParts[i], pwrfl_qKS); // convert to ZZX
+#else
+    NTL::ZZ pInvR = NTL::InvMod(NTL::ZZ(p2r) % R, R);
+    NTL::vec_ZZ pwrfl;
+    p2d_conv.dcrtToPowerful(pwrfl, parts[i]);
+    for (long j = 0; j < pwrfl.length(); j++) {
+      NTL::ZZ tmp;
+      NTL::rem(tmp, pwrfl[j], R);
+      tmp = NTL::MulMod(tmp, pInvR, R);
+      if (tmp > R / 2)
+        tmp -= R;
+      pwrfl[j] -= p2r * tmp;
+#ifdef HELIB_DEBG
+      // XXX: debug
+      NTL::ZZ dbg_ZZ;
+      NTL::rem(dbg_ZZ, pwrfl[j], R);
+      assertEq(dbg_ZZ, NTL::ZZ(0), "why???");
+      // XXX: end debug
+#endif
+      pwrfl[j] /= R;
+    }
+    vecRed(pwrfl, pwrfl, qKS, false);
+    p2d_conv.powerfulToZZX(zzParts[i], pwrfl);
+#endif
+  }
+
+  // Return an estimate for the noise
+  double scaledNoise = NTL::conv<double>(noiseBound * ratio);
+
+  return scaledNoise;
+  // this is returned so that caller in recryption.cpp can check bounds
+}
+
 void Ctxt::addedNoiseForCKKSDecryption(const SecKey& sk,
                                        double eps,
                                        NTL::ZZX& noise) const
diff --git a/src/DoubleCRT.cpp b/src/DoubleCRT.cpp
index e356d6d..dad9248 100644
--- a/src/DoubleCRT.cpp
+++ b/src/DoubleCRT.cpp
@@ -560,6 +560,64 @@ NTL::xdouble DoubleCRT::breakIntoDigits(std::vector<DoubleCRT>& digits) const
   return noise;
 }
 
+NTL::xdouble DoubleCRT::breakIntoDigitsNonRNS(
+    std::vector<DoubleCRT>& dgts) const
+{
+  // sanity check
+  assertTrue(getIndexSet() == IndexSet(context.getIndexQks()), "only qKS is expected");
+  long nDgts = context.getBtsDigits();
+  long baseKS = context.getBtsBaseKS();
+  long baseKSHalf = (baseKS + 1) >> 1;
+  long phim = context.getPhiM();
+
+  IndexSet dgtSet;
+  dgtSet.insert(context.getIndexQks());
+  dgtSet.insert(context.getIndexR());
+  dgts.resize(nDgts, DoubleCRT(context, dgtSet));
+  NTL::xdouble noise(0.0);
+
+  NTL::ZZX poly, tmp;
+  toPoly(poly, false); // iFFT here
+  tmp.SetLength(phim);
+#ifdef HELIB_DEBUG
+  NTL::ZZX dbg, dbg_poly;
+  std::vector<NTL::ZZX> dbg_digits;
+  dbg_poly = poly;
+#endif
+  // decompose poly into `nDgts` parts, each of base `baseKS`
+  for(long i = 0; i < nDgts; i++){
+    for(long j = 0; j < phim; j++){
+      tmp[j] = NTL::DivRem(poly[j], poly[j], baseKS);
+      if(tmp[j] >= baseKSHalf){ // balanced mod
+        tmp[j] -= baseKS;
+        poly[j] += 1;
+      }
+    }
+    dgts[i] = tmp;
+    double norm_bnd =
+        context.noiseBoundForUniform(baseKS / 2.0, phim);
+    NTL::xdouble norm_val = embeddingLargestCoeff(tmp, context.getZMStar());
+    if(norm_val > norm_bnd)
+      std::cerr << "WARNING: in non-RNS ks, actual norm bnd / expected norm bnd is " << norm_val / norm_bnd << "\n";
+    noise += norm_val;
+#ifdef HELIB_DEBUG
+    dbg_digits.push_back(tmp);
+#endif
+  }
+#ifdef HELIB_DEBUG
+  for(long i = 0; i < nDgts; i++) {
+    dbg += dbg_digits[i] * NTL::power_long(baseKS, i);
+  }
+  if(dbg != dbg_poly) {
+    for(long j = 0; j < phim; j++) {
+      if(dbg[j] != dbg_poly[j])
+        std::cerr << "decomposition error at position " << j << "\n";
+    }
+  }
+#endif
+  return noise;
+}
+
 // expand index set by s1.
 // it is assumed that s1 is disjoint from the current index set.
 void DoubleCRT::addPrimes(const IndexSet& s1, NTL::ZZX* poly_p)
diff --git a/src/EncryptedArray.cpp b/src/EncryptedArray.cpp
index 1d551a9..09e5561 100644
--- a/src/EncryptedArray.cpp
+++ b/src/EncryptedArray.cpp
@@ -515,9 +515,21 @@ void EncryptedArrayDerived<type>::initNormalBasisMatrix() const
     bool got_it = false;
 
     H = power(NTL::conv<RE>(RX(1, 1)), p);
-
+    // NOTE: find a normal element randomly
+    //  by checking the non-singularity of the normal basis matrix
+    // NOTE: CB, the first element in the returned pair, 
+    //  has CB[i] = theta^i, where theta is the normal element
+    //  theta is represented in the X-basis
+    //  given v^T represented w.r.t. the normal basis
+    //  v^T * CB is its representation w.r.t. the X-basis
+    //  CBI = Inv(CB)
     do {
       NTL::random(normal_element);
+      // NOTE: if d = 1, use 1 as the normal element
+      //  this is also beneficial for bootstrapping
+      //  because it saves some capacity in unpacking
+      if (d == 1)
+        normal_element = 1;
 
       RE pow;
       pow = normal_element;
@@ -547,6 +559,32 @@ void EncryptedArrayDerived<type>::initNormalBasisMatrix() const
     ptr.make(CB, CBi);
     builder.move(ptr);
   } while (0);
+
+  // XXX: debug // XXX: not finished
+  // std::cout << "start sparsity testing...\n";
+  // NTL::Vec<RE> basis_vec;
+  // basis_vec.SetLength(d);
+  // {
+  //   NTL::zz_pBak bak1;
+  //   bak1.save();
+  //   NTL::zz_p::init(p);
+  //   NTL::Mat<NTL::zz_p> basis_mat;
+  //   basis_mat.SetDims(d, d);
+  //   while (true) {
+  //     bool found = false;
+  //     for(long i = 0; i < d && !found; i++) {
+  //       for(long j = 0; j < d; j++) {
+  //         if(basis_mat[i][j] < p - 1){
+  //           basis_mat[i][j] += 1;
+  //           found = true;
+  //           break;
+  //         }
+  //         basis_mat[i][j] = 0;
+  //       }
+  //     }
+  //     // basis is found
+  //   }
+  // }
 }
 
 // PtxtArray member functions
diff --git a/src/EvalMap.cpp b/src/EvalMap.cpp
index ff2399c..f0b6f09 100644
--- a/src/EvalMap.cpp
+++ b/src/EvalMap.cpp
@@ -209,6 +209,196 @@ static void init_representatives(NTL::Vec<long>& representatives,
     representatives[i] = NTL::PowerMod(g, i, m);
 }
 
+// sparse matrix manipulation (especially for BlockMatMul1D)
+template<typename T>
+void MulCol(NTL::Mat<T> &mat, long colID, const T& val,
+    const std::set<long> &diag_set) {
+  long n = mat.NumCols();
+  // colID - rowId = diag mod n
+  long rowID;
+  for(long diag : diag_set) {
+    rowID = mcMod(colID - diag, n);
+    if(!NTL::IsZero(mat[rowID][colID]))
+      mat[rowID][colID] *= val;
+  }
+
+}
+// sparse matrix manipulation (especially for BlockMatMul1D)
+template<typename T>
+void MulRow(NTL::Mat<T> &mat, long rowID, const T& val,
+    const std::set<long> &diag_set) {
+  long n = mat.NumCols();
+  // colID - rowId = diag mod n
+  long colID;
+  for(long diag : diag_set) {
+    colID = mcMod(rowID + diag, n);
+    if(!NTL::IsZero(mat[rowID][colID]))
+      mat[rowID][colID] = val * mat[rowID][colID];
+  }
+}
+
+template<typename T>
+void MulAddCol(NTL::Mat<T> &mat, const NTL::Mat<T> &fromMat, long fromColID, long toColID,
+    const T& val, std::set<long> &diag_set) {
+  long n = mat.NumCols();
+  long rowID;
+  std::set<long> new_diags;
+  for(long diag : diag_set) {
+    rowID = mcMod(fromColID - diag, n);
+    if(NTL::IsZero(fromMat[rowID][fromColID]))
+      continue;
+    new_diags.insert(mcMod(toColID - rowID, n));
+    if(NTL::IsZero(mat[rowID][toColID])) // NOTE: mul order matters
+      mat[rowID][toColID] = fromMat[rowID][fromColID] * val;
+    else
+      mat[rowID][toColID] += fromMat[rowID][fromColID] * val;
+  }
+  diag_set.merge(new_diags);
+}
+
+// avoid adding a 0x0 matrix
+template<typename T>
+T safe_add(const T& a, const T&b) {
+  if(NTL::IsZero(a))
+    return b;
+  if(NTL::IsZero(b))
+    return a;
+  return a+b;
+}
+
+// compute sum(ai*bi), skipping zeros
+template<typename V, typename T, typename U>
+V safe_lin(const std::vector<T> &a, const std::vector<U> &b) {
+  V res;
+  long n = a.size(), i = 0;
+  for(; i < n; i++) {
+    if(!NTL::IsZero(a[i]) && !NTL::IsZero(b[i])) {
+      res = a[i] * b[i];
+      i++;
+      break;
+    }
+  }
+  for(; i < n; i++) {
+    if(!NTL::IsZero(a[i]) && !NTL::IsZero(b[i])) 
+      res += a[i] * b[i];
+  }
+  return res;
+}
+
+/**
+ * Linear combination of two columns
+*/
+template<typename T, typename U>
+void DoubleLinComb(NTL::Mat<T> &mat, long i, long j, const NTL::Mat<U> &lins, 
+    const std::set<long> &diag_set, std::set<long> &new_diags){
+  assertTrue(lins.NumCols() == 2 && lins.NumRows() == 2, "not 2-linear");
+  assertTrue(i < j, "expecting i < j");
+  long n = mat.NumCols();
+  long diag_i, diag_j;
+  for(long row = 0; row < n; row++) { // TODO: iterate diagonals...?
+    diag_i = mcMod(i - row, n);
+    diag_j = mcMod(j - row, n);
+    if(diag_set.count(diag_i) || diag_set.count(diag_j)) {
+      std::vector<T> cur_row{mat[row][i], mat[row][j]};
+      std::vector<U> lin0{lins[0][0], lins[1][0]}, 
+                     lin1{lins[0][1], lins[1][1]};
+      mat[row][i] = safe_lin<T>(cur_row, lin0);
+      mat[row][j] = safe_lin<T>(cur_row, lin1);
+      if(!NTL::IsZero(mat[row][i]))
+        new_diags.insert(diag_i);
+      if(!NTL::IsZero(mat[row][j]))
+        new_diags.insert(diag_j);
+    }
+  }
+}
+
+/**
+ * Linear combination of four columns
+ * indexed by i, i+delta, i+2*delta, i+3*delta
+*/
+template<typename T, typename U>
+void QuadLinComb(NTL::Mat<T> &mat, long i, long delta, const NTL::Mat<U> &lins,
+    const std::set<long> &diag_set, std::set<long> &new_diags){
+  assertTrue(lins.NumCols() == 4 && lins.NumRows() == 4, "not 4=linear");
+  long n = mat.NumCols();
+  long cur_diags[4];
+  for(long row = 0; row < n; row++) {
+    bool empty_row = true;
+    for(long k = 0; k < 4; k++) {
+      cur_diags[k] = mcMod(i + delta * k - row, n);
+      if(empty_row && diag_set.count(cur_diags[k]))
+        empty_row = false;
+    }
+    if(empty_row)
+      continue;
+    std::vector<T> cur_row{mat[row][i], mat[row][i+delta], 
+      mat[row][i+2*delta], mat[row][i+3*delta]};
+    for(long k = 0; k < 4; k++) {
+      std::vector<U> lin_k{lins[0][k], lins[1][k], lins[2][k], lins[3][k]};
+      mat[row][i+k*delta] = safe_lin<T>(cur_row, lin_k);
+      if(!NTL::IsZero(mat[row][i+k*delta]))
+        new_diags.insert(cur_diags[k]);
+    }
+  }
+}
+
+/**
+ * Linear combination of two rows
+*/
+template<typename T, typename U>
+void DoubleLinCombRows(NTL::Mat<T> &mat, long i, long j, const NTL::Mat<U> &lins, 
+    const std::set<long> &diag_set, std::set<long> &new_diags){
+  assertTrue(lins.NumCols() == 2 && lins.NumRows() == 2, "not 2-linear");
+  assertTrue(i < j, "expecting i < j");
+  long n = mat.NumCols();
+  long diag_i, diag_j;
+  for(long col = 0; col < n; col++) { // TODO: iterate diagonals...?
+    diag_i = mcMod(col - i, n);
+    diag_j = mcMod(col - j, n);
+    if(diag_set.count(diag_i) || diag_set.count(diag_j)) {
+      std::vector<T> cur_col{mat[i][col], mat[j][col]};
+      std::vector<U> lin0{lins[0][0], lins[0][1]}, 
+                     lin1{lins[1][0], lins[1][1]};
+      mat[i][col] = safe_lin<T>(lin0, cur_col);
+      mat[j][col] = safe_lin<T>(lin1, cur_col);
+      if(!NTL::IsZero(mat[i][col]))
+        new_diags.insert(diag_i);
+      if(!NTL::IsZero(mat[j][col]))
+        new_diags.insert(diag_j);
+    }
+  }
+}
+
+/**
+ * Linear combination of four rows
+ * indexed by i, i+delta, i+2*delta, i+3*delta
+*/
+template<typename T, typename U>
+void QuadLinCombRows(NTL::Mat<T> &mat, long i, long delta, const NTL::Mat<U> &lins,
+    const std::set<long> &diag_set, std::set<long> &new_diags){
+  assertTrue(lins.NumCols() == 4 && lins.NumRows() == 4, "not 4=linear");
+  long n = mat.NumCols();
+  long cur_diags[4];
+  for(long col = 0; col < n; col++) {
+    bool empty_col = true;
+    for(long k = 0; k < 4; k++) {
+      cur_diags[k] = mcMod(col - (i + delta * k), n);
+      if(empty_col && diag_set.count(cur_diags[k]))
+        empty_col = false;
+    }
+    if(empty_col)
+      continue;
+    std::vector<T> cur_col{mat[i][col], mat[i+delta][col], 
+      mat[i+2*delta][col], mat[i+3*delta][col]};
+    for(long k = 0; k < 4; k++) {
+      std::vector<U> lin_k{lins[k][0], lins[k][1], lins[k][2], lins[k][3]};
+      mat[i+k*delta][col] = safe_lin<T>(lin_k, cur_col);
+      if(!NTL::IsZero(mat[i+k*delta][col]))
+        new_diags.insert(cur_diags[k]);
+    }
+  }
+}
+
 // The callback interface for the matrix-multiplication routines.
 
 //! \cond FALSE (make doxygen ignore these classes)
@@ -301,6 +491,1173 @@ static MatMul1D* buildStep2Matrix(const EncryptedArray& ea,
   }
 }
 
+/**
+ * A random matrix in for a 2 x D sized hypercube in Po2 cyclotomics
+ * note that it is not purely random
+*/
+class Po2RandBtsMatrix : public MatMul1D_derived<PA_zz_p>
+{
+  PA_INJECT(PA_zz_p)
+
+  const EncryptedArray& base_ea;
+  bool multiple_blocks;
+  NTL::Mat<RX> multiDimMat;
+public:
+  Po2RandBtsMatrix(const EncryptedArray& _ea) : base_ea(_ea) {
+    multiple_blocks = base_ea.dimension() > 1;
+    assertTrue(multiple_blocks, "GV23 requires multi-dimension hypercube");
+    multiDimMat.SetDims(2, 2);
+    RBak rbak;
+    rbak.save();
+    base_ea.restoreContext();
+    NTL::random(multiDimMat[0][0], base_ea.getDegree());
+    NTL::random(multiDimMat[0][1], base_ea.getDegree());
+    NTL::random(multiDimMat[1][0], base_ea.getDegree());
+    NTL::random(multiDimMat[1][1], base_ea.getDegree());
+  }
+
+  const EncryptedArray& getEA() const override {
+    return base_ea;
+  }
+
+  long getDim() const override {
+    return base_ea.dimension() - 1;
+  }
+
+  void processDiagonal(RX& poly, UNUSED long i, const EncryptedArrayDerived<PA_zz_p>& ea) const override {
+    RBak rbak;
+    rbak.save();
+    base_ea.restoreContext();
+    NTL::random(poly, ea.getTab().getZMStar().getPhiM());
+  }
+
+  int multiDimInfo() const {
+    return 1;
+  }
+
+  const NTL::Mat<RX>& getPo2MultiDimMat() const override {
+    return multiDimMat;
+  }
+
+  bool multipleTransforms() const override {
+    return true;
+  }
+
+  bool get(UNUSED RX& out, UNUSED long i, UNUSED long j, UNUSED long k) const override {
+    return true;
+  }
+
+};
+
+
+// XXX: I'm not sure if we should implement this using dense matrices...
+//  or maybe spending more time/memory on preprocessing is ok...?
+
+/*
+  the hypercube may contain one or two hypercolumns (stored in A0, A1)
+  we assume the final inter-slot computation is not included
+*/
+class Po2IFFTStep1Matrix : public BlockMatMul1D_derived<PA_zz_p>
+{
+  PA_INJECT(PA_zz_p)
+
+  const EncryptedArray& base_ea;
+  bool multiple_blocks;
+  bool inverse;
+  bool subfield;
+  NTL::Mat<mat_R> As[2];
+  std::vector<long> diag_indices;
+
+public:
+  // constructor
+  Po2IFFTStep1Matrix(
+      const EncryptedArray& _ea,
+      bool _inverse,
+      bool forceRadix2,
+      bool isThick,
+      long start_mat,
+      long end_mat) : /* [start, end) = the indices of intra-slot/FFT maps */
+      base_ea(_ea), inverse(_inverse)
+  {
+    const auto& alMod = base_ea.getAlMod().getDerived(PA_zz_p());
+    const auto& zmStar = alMod.getZMStar();
+    const auto& palg = base_ea.getPAlgebra();
+    // the larger dimension should always be the second one!!!
+    long D = base_ea.sizeOfDimension(base_ea.dimension() - 1);
+    long d = palg.getOrdP();
+    // long M = palg.getM();
+    long p = zmStar.getP();
+    long r = alMod.getR();
+
+    multiple_blocks = base_ea.dimension() > 1;
+    subfield = !isThick && (p % 4 == 3);
+    long nmats = NTL::NumTwos(NTL::ZZ(palg.getNSlots())) + 1;
+    // bool GtoFi = start_mat == 0;
+    assertTrue(d > 1, "Po2IFFTStep1Matrix: not a BlockMatMul1D");
+    if(p % 4 == 1)
+      forceRadix2 = false;
+    if(!forceRadix2)
+      assertTrue(start_mat == 0, "except for forceRadix2, start_mat should be 0");
+    assertTrue(start_mat < end_mat, 
+      "expecting start_mat < end_mat");
+    assertTrue(palg.getNSlots() == D * (1 + multiple_blocks), "what happened ???");
+
+    RBak bak;
+    bak.save();
+    alMod.restoreContext();
+    REBak rebak;
+    rebak.save();
+    base_ea.restoreContextForG();
+    // tmp variables
+    RXModulus tmp_mod;
+
+    long cnt_A = 1 + multiple_blocks;
+    for (long Aidx = 0; Aidx < cnt_A; Aidx++)
+      As[Aidx].SetDims(D, D);
+    // TODO: consider thin bts
+    /**
+     * for thin bts:
+     * 1. p % 4 == 1
+     *  encoding maps in both IFFT and FFT are identity map
+     *  all layers are MatMul1D
+     * 2. p % 4 == 3, not forceRadix2
+     *  encoding maps in both IFFT and FFT are on degree-2 subfield
+     *  the first IFFT layer is BlockMatMul1D on degree-2 subfield
+     *  all other layers are MatMul1D
+     * 3. p % 4 == 3, forceRadix2
+     *  encoding maps in both IFFT and FFT are on degree-2 subfield
+     *  all layers are BlockMatMul1D on degree-2 subfield
+     *  an extra projection is needed at the end of IFFT
+    */
+    
+    // the encoding map
+    if(start_mat == 0){
+      for (long Aidx = 0; Aidx < cnt_A; Aidx++) {
+        for (long i = 0; i < D; i++) {
+          // move the coeffs in R[X]/G into R[X]/Fi
+          // i.e., the inverse map of evaluating X=(X\in R[X]/G)^{1/ti}
+          // which is evaluating X=(X\in R[X]/Fi)^ti
+          As[Aidx][i][i].SetDims(d, d);
+          RX pow;
+          pow = 1;
+          RX X2ti;
+          NTL::SetCoeff(X2ti, palg.ith_rep(i + Aidx * D), 1); // X2ti = X^ti
+          const RX& Fi = alMod.getFactors()[i + Aidx * D];
+          NTL::rem(X2ti, X2ti, Fi);
+          for (long j = 0; j < d; j++) {
+            NTL::VectorCopy(As[Aidx][i][i][j], pow, d);
+            NTL::MulMod(pow, pow, X2ti, Fi);
+          }
+          // XXX: debug
+          // check the correctness of this step
+          assertEq(As[Aidx][i][i], _ea.getDerived(PA_zz_p()).getMat(i+Aidx*D), 
+            "not eq?");
+          // end debug
+          // compose the two maps
+          // NTL::mul(As[Aidx][i][i], n2p_mat, As[Aidx][i][i]);
+          if(inverse) { // for r > 1, ppInvert is not inplace-safe
+            mat_R Afrom = As[Aidx][i][i];
+            ppInvert(As[Aidx][i][i], Afrom, p, r);
+          }
+        }
+      }
+      start_mat++;
+    } else {
+      for (long Aidx = 0; Aidx < cnt_A; Aidx++) {
+        for (long i = 0; i < D; i++)
+          NTL::ident(As[Aidx][i][i], d);
+      }
+    }
+    std::set<long> diag_set, new_diags;
+    diag_set.insert(0);
+    /**
+     * ### Bruun FFT ###
+     * f = a*X^{3k}+b*X^{2k}+c*X^{k}+d, where a,b,c,d are k-length vectors
+     * reducing f modulo X^{2k}\pm s*X^{k}+t, we have
+     * f mod X^{2k}+s*X^{k}+t = 
+     *  [c+a(s^2-t)-bs]*X^{k} + [d+ast-bt] = H*X^{k} + L
+     * f mod X^{2k}-s*X^{k}+t =
+     *  [c+a(s^2-t)+bs]*X^{k} + [d-ast-bt] = H'*X^{k} + L'
+     * inverting the process, we have
+     * a = (L-L')/(2st)
+     * b = (H-H')/(-2s)
+     * c = (H+H')/2+(L-L')(t-s^2)/(2st)
+     * d = (L+L')/2+(H'-H)t/(2s)
+     * there are two strategies to perform the Bruun FFT
+     * #1. first layer BlockMatMul1D, other layers MatMul1D
+     *    first layer 2-diagonals, other layers 6~7-diagonals
+     * for the first layer:
+     *                                     | x x |   x |
+     *                                     |_x_x_|_x_ _|
+     * | d  c | b  a | = | L H | L' H' | * | x x |   x |
+     *                                     | x x | x   |
+     *                            
+     * and inverse is
+     *                                     | x   | x   |
+     *                                     |_ _x_|_ _x_|
+     * | L H | L' H' | = | d  c | b  a | * | x x | x x |
+     *                                     | x x | x x |
+     *                         
+     * for other layers:
+     *                    ------        | x   x x |
+     *   00 10 01 11      |    |        | x   x x |
+     * | d  b  c  a | = | L L' H H' | * | x x x   |
+     *                      |    |      | x x x   |
+     *                      ------
+     * and inverse is
+     *   ------                         | x x     |   
+     *   |    |          00 10 01 11    | x x x x |   
+     * | L L' H H' | = | d  b  c  a | * |     x x |
+     *     |    |                       | x x x x |   
+     *     ------                                                           
+     * since the first layer outputs d,c,b,a (the ordinary order)
+     * the coefficients are grouped in block sizes of d
+     * after IFFT, the i-th slot contains the BitRev(i)-th coeff block
+     * i.e., coeffs in [BitRev(i)*d, BitRev(i)*d+d-1]
+     * 
+     * #2. all layers BlockMatMul1D
+     *    first layer 2-diagonals, other layers 3-diagonals
+     * the major difference from the previous case is that
+     * the first layer also has bit-reversed output, i.e.,
+     *                     -------         | x   | x x |
+     *   00 10  01 11      |     |         |_x_x_|_x_ _|
+     * | d  b | c  a | = | L H | L' H' | * | x   | x x |
+     *                       |      |      | x x | x   |
+     *                       --------
+     * and the inverse is
+     *   -------                           | x   | x   |
+     *   |     |           00 10  01 11    |_x_x_|_x_x_|
+     * | L H | L' H' | = | d  b | c  a | * |   x |   x |
+     *     |      |                        | x x | x x |
+     *     --------
+     * now d & b (or c & a) serve as L0 & H0 (or L1 & H1) in the next layer
+     * the other layers have identical structures as the first layer:
+     *                     -------         | x   | x x |
+     *   00 10  01 11      |     |         |_x_x_|_x_ _|
+     * | d  b | c  a | = | L H | L' H' | * | x   | x x |
+     *                       |      |      | x x | x   |
+     *                       --------
+    */
+    if(p % 4 == 3) { // we only have one dimension, use A0 only
+      NTL::Mat<mat_R> &A0 = As[0];
+      assertFalse(multiple_blocks, "p = 3 mod 4 should have only one block");
+      std::unique_ptr<std::vector<R>> middle_coeff_vec_ptr = std::make_unique<std::vector<R>>();
+      std::unique_ptr<std::vector<R>> bak_vec_ptr = std::make_unique<std::vector<R>>();
+      {
+        std::vector<R> &middle_coeffs = *middle_coeff_vec_ptr;
+        middle_coeffs.resize(D);
+        // NOTE: we can obtain the middle_coeffs in a top-down manner
+        //  with Dickson polynomials... but that is unnecessary
+        for(long i = 0; i < D; i++)
+          middle_coeffs[i] = NTL::coeff(alMod.getFactors()[i], d/2);
+      }
+      R const_coeff = NTL::coeff(alMod.getFactors()[0], 0);
+      assertTrue(const_coeff == 1 || const_coeff == -1, "const coeff not \\pm 1");
+      R s, t;
+      if (!forceRadix2) {  // first layer of Bruun FFT is special
+        // because it cannot be represented as a MatMul1D transform
+        if (start_mat == 1 && start_mat < end_mat) {
+          std::vector<R> &middle_coeffs = *middle_coeff_vec_ptr;
+          NTL::Mat<mat_R> lin2x2;
+          lin2x2.SetDims(2, 2);
+          lin2x2[0][0].SetDims(d, d);
+          lin2x2[0][1].SetDims(d, d);
+          lin2x2[1][0].SetDims(d, d);
+          lin2x2[1][1].SetDims(d, d);
+          for(long i = 0; i < D/2; i++) {
+            s = middle_coeffs[i];
+            t = const_coeff;
+            // assertTrue(bool(s + middle_coeffs[i + D/2] == 0), "middle coeff err?");
+            if(!inverse) { // IFFT
+              for(long j = 0; j < d/2; j++) {
+                // d
+                lin2x2[0][0][j][j] = R(1) / R(2);    // L
+                lin2x2[0][0][j+d/2][j] = -t / (2*s); // H
+                lin2x2[1][0][j][j] = R(1) / R(2);    // L'
+                lin2x2[1][0][j+d/2][j] = t / (2*s);  // H'
+                // c
+                lin2x2[0][0][j][j+d/2] = (t-s*s) / (2*s*t);  // L
+                lin2x2[0][0][j+d/2][j+d/2] = R(1) / R(2);    // H
+                lin2x2[1][0][j][j+d/2] = -(t-s*s) / (2*s*t); // L'
+                lin2x2[1][0][j+d/2][j+d/2] = R(1) / R(2);    // H'
+                // b
+                lin2x2[0][1][j+d/2][j] = -R(1) / (2*s);    // H
+                lin2x2[1][1][j+d/2][j] = R(1) / (2*s);     // H'
+                // a
+                lin2x2[0][1][j][j+d/2] = R(1) / (2*s*t);  // L
+                lin2x2[1][1][j][j+d/2] = -R(1) / (2*s*t); // L'
+              }
+              // perform col operation on A0
+              DoubleLinComb(A0, i, i+D/2, lin2x2, diag_set, new_diags);
+            } else { // FFT
+              for(long j = 0; j < d/2; j++) {
+                // L
+                lin2x2[0][0][j][j] = R(1);    // d
+                lin2x2[1][0][j][j] = -t;      // b
+                lin2x2[1][0][j+d/2][j] = s*t; // a
+                // H
+                lin2x2[0][0][j+d/2][j+d/2] = R(1);  // c
+                lin2x2[1][0][j][j+d/2] = -s;        // b
+                lin2x2[1][0][j+d/2][j+d/2] = s*s-t; // a
+                // L'
+                lin2x2[0][1][j][j] = R(1);     // d
+                lin2x2[1][1][j][j] = -t;       // b
+                lin2x2[1][1][j+d/2][j] = -s*t; // a
+                // H'
+                lin2x2[0][1][j+d/2][j+d/2] = R(1);  // c
+                lin2x2[1][1][j][j+d/2] = s;         // b
+                lin2x2[1][1][j+d/2][j+d/2] = s*s-t; // a
+              }
+              DoubleLinCombRows(A0, i, i+D/2, lin2x2, diag_set, new_diags);
+            }
+          }
+          diag_set.merge(new_diags);
+          new_diags.clear();
+          start_mat++;
+        }
+      }
+      // prepare the middle coeffs
+      long cnt_factors = D;
+      for(long k = 1; k < start_mat; k++) {
+        std::vector<R> &cur = *middle_coeff_vec_ptr;
+        std::vector<R> &next = *bak_vec_ptr;
+        cnt_factors /= 2;
+        next.resize(cnt_factors);
+        for(long i = 0; i < cnt_factors; i++)
+          next[i] = 2*const_coeff-cur[i]*cur[i];
+        cur.clear();
+        std::swap(middle_coeff_vec_ptr, bak_vec_ptr);
+        const_coeff *= const_coeff; // const_coeff = 1
+      }
+      /** 
+       * for the k-th layer, there are D/2^{k-1} factors
+       * the coeff group of the i-th factor occupies the slots indexed by
+       * i + j * D/2^{k-1} in a bit-reversed order
+       * the i-th coeff group can be combined with the i+D/2^k-th group
+       * in an interleaved way (i.e., combine L0, H0, L0', H0')
+       * L0   H0   L1 ...
+       *   L1'   H1'  L1' ...
+       * 
+       * start_mat = 2 for Bruun FFT
+       * start_mat >= 1 for radix-2 FFT
+       * */
+      for (long k = start_mat; k < end_mat; k++) {
+        std::vector<R> &middle_coeffs = *middle_coeff_vec_ptr;
+        assertEq(cnt_factors, (long)middle_coeffs.size(), "cnt_factors mismatch");
+        assertEq(cnt_factors, D >> (k-1), "cnt factors wrong");
+        long group_size = 1L << (k-1);
+        if (!forceRadix2){
+          NTL::Mat<R> lin4x4; // matrix of R instead of mat_R here
+          lin4x4.SetDims(4, 4);
+          for(long i = 0; i < cnt_factors / 2; i++) {
+            s = middle_coeffs[i];
+            t = const_coeff;
+            // the same lin4x4 is used for all the quad-pairs in the coeff group
+            if(!inverse){ // IFFT
+              // d
+              lin4x4[0][0] = R(1) / R(2);   // L
+              lin4x4[1][0] = R(1) / R(2);   // L'
+              lin4x4[2][0] = -t / (2*s);    // H
+              lin4x4[3][0] = t / (2*s);     // H'
+              // b
+              lin4x4[2][1] = -R(1) / (2*s);  // H
+              lin4x4[3][1] = R(1) / (2*s);   // H'
+              // c
+              lin4x4[0][2] = (t-s*s) / (2*s*t);   // L
+              lin4x4[1][2] = -(t-s*s) / (2*s*t);  // L'
+              lin4x4[2][2] = R(1) / R(2);         // H
+              lin4x4[3][2] = R(1) / R(2);         // H'
+              // a
+              lin4x4[0][3] = R(1) / (2*s*t);   // L
+              lin4x4[1][3] = -R(1) / (2*s*t);  // L'
+            } else { // FFT
+              // L
+              lin4x4[0][0] = R(1);
+              lin4x4[1][0] = -t;
+              lin4x4[3][0] = s*t;
+              // L'
+              lin4x4[0][1] = R(1);
+              lin4x4[1][1] = -t;
+              lin4x4[3][1] = -s*t;
+              // H
+              lin4x4[1][2] = -s;
+              lin4x4[2][2] = R(1);
+              lin4x4[3][2] = s*s-t;
+              // H'
+              lin4x4[1][3] = s;
+              lin4x4[2][3] = R(1);
+              lin4x4[3][3] = s*s-t;
+            }
+            // performing linear combination for each quad-pair
+            for(long j = 0; j < group_size; j += 2) {
+              // long Lidx = i + j * cnt_factors,
+              //      Hidx = i + (j+1) * cnt_factors;
+              // long LLidx = Lidx + cnt_factors / 2,
+              //      HHidx = Hidx + cnt_factors / 2;
+              if(!inverse) // IFFT
+                QuadLinComb(A0, i + j * cnt_factors, cnt_factors / 2, 
+                    lin4x4, diag_set, new_diags);
+              else // FFT
+                QuadLinCombRows(A0, i + j * cnt_factors, cnt_factors / 2,
+                    lin4x4, diag_set, new_diags);
+            }
+          }
+        } else { // forceRadix2
+          NTL::Mat<mat_R> lin2x2;
+          lin2x2.SetDims(2, 2);
+          lin2x2[0][0].SetDims(d, d);
+          lin2x2[0][1].SetDims(d, d);
+          lin2x2[1][0].SetDims(d, d);
+          lin2x2[1][1].SetDims(d, d);
+          for (long i = 0; i < cnt_factors / 2; i++) {
+            s = middle_coeffs[i];
+            t = const_coeff;
+            if (!inverse) { // IFFT
+              for (long j = 0; j < d/2; j++) {
+                // d
+                lin2x2[0][0][j][j] = R(1) / R(2);    // L
+                lin2x2[0][0][j+d/2][j] = -t / (2*s); // H
+                lin2x2[1][0][j][j] = R(1) / R(2);    // L'
+                lin2x2[1][0][j+d/2][j] = t / (2*s);  // H'
+                // b
+                lin2x2[0][0][j+d/2][j+d/2] = -R(1) / (2*s); // H
+                lin2x2[1][0][j+d/2][j+d/2] = R(1) / (2*s);  // H'
+                // c
+                lin2x2[0][1][j][j] = (t-s*s) / (2*s*t);  // L
+                lin2x2[0][1][j+d/2][j] = R(1) / R(2);    // H
+                lin2x2[1][1][j][j] = -(t-s*s) / (2*s*t); // L'
+                lin2x2[1][1][j+d/2][j] = R(1) / R(2);    // H'
+                // a
+                lin2x2[0][1][j][j+d/2] = R(1) / (2*s*t);  // L
+                lin2x2[1][1][j][j+d/2] = -R(1) / (2*s*t); // L'
+              }
+              for (long j = 0; j < group_size; j++)
+                DoubleLinComb(A0, i+j*cnt_factors, i+j*cnt_factors+cnt_factors/2,
+                  lin2x2, diag_set, new_diags);
+            } else { // FFT
+              for (long j = 0; j < d/2; j++) {
+                // L
+                lin2x2[0][0][j][j] = R(1);    // d
+                lin2x2[0][0][j+d/2][j] = -t;  // b
+                lin2x2[1][0][j+d/2][j] = s*t; // a
+                // H
+                lin2x2[0][0][j+d/2][j+d/2] = -s;    // b
+                lin2x2[1][0][j][j+d/2] = R(1);      // c
+                lin2x2[1][0][j+d/2][j+d/2] = s*s-t; // a
+                // L'
+                lin2x2[0][1][j][j] = R(1);     // d
+                lin2x2[0][1][j+d/2][j] = -t;   // b
+                lin2x2[1][1][j+d/2][j] = -s*t; // a
+                // H'
+                lin2x2[0][1][j+d/2][j+d/2] = s;     // b
+                lin2x2[1][1][j][j+d/2] = R(1);      // c
+                lin2x2[1][1][j+d/2][j+d/2] = s*s-t; // a
+              }
+              for (long j = 0; j < group_size; j++)
+                DoubleLinCombRows(A0, i+j*cnt_factors, i+j*cnt_factors+cnt_factors/2,
+                  lin2x2, diag_set, new_diags);
+            }
+          }
+        }
+        // update the diag_set after multiplication is done
+        diag_set.merge(new_diags);
+        new_diags.clear();
+        // update coeff vectors
+        std::vector<R> &cur = *middle_coeff_vec_ptr;
+        std::vector<R> &next = *bak_vec_ptr;
+        cnt_factors /= 2;
+        next.resize(cnt_factors);
+        for(long i = 0; i < cnt_factors; i++)
+          next[i] = 2*const_coeff-cur[i]*cur[i];
+        cur.clear();
+        std::swap(middle_coeff_vec_ptr, bak_vec_ptr);
+        const_coeff *= const_coeff; // const_coeff = 1
+      }
+    }
+    else { // p = 1 mod 4, radix-2 FFT
+      /**
+       * f = a*X^{k}+b, where a,b are k-length vectors
+       * reducing f modulo X^{k}\pm s, we have
+       * f mod X^{k}+s = b-as = u
+       * f mod X^{k}-s = b+as = v
+       * inversely, we have
+       * a = -(u-v)/(2s)
+       * b = (u+v)/2
+       * the FFT structure is the classic radix-2 butterfly
+       *                     | x x |
+       * | b a | = | u v | * | x x |
+       * and
+       *                     | x x |
+       * | u v | = | b a | * | x x |
+       * The indices are bit-reversed in a special way:
+       * the highest bit and the lowest log2(d) bits are kept in order,
+       * while the other bits are reversed
+      */
+      assertTrue(isThick, "thin bts for p = 1 mod 4 should not include BlockMatmul1D");
+      assertTrue(multiple_blocks, "p = 1 mod 4 should have multiple blocks");
+      assertTrue(end_mat < nmats, 
+        "the multiDim map should not be included in Po2IFFTStep1Matrix");
+      std::unique_ptr<std::vector<R>> const_coeff_vec_ptr = std::make_unique<std::vector<R>>();
+      std::unique_ptr<std::vector<R>> bak_vec_ptr = std::make_unique<std::vector<R>>();
+      {
+        std::vector<R> &const_coeffs = *const_coeff_vec_ptr;
+        const_coeffs.resize(2*D);
+        for(long i = 0; i < D; i++) {
+          const_coeffs[i] = NTL::coeff(alMod.getFactors()[i], 0);
+          const_coeffs[i + D] = NTL::coeff(alMod.getFactors()[i + D], 0);
+        }
+      }
+      // prepare the const coeffs
+      long cnt_factors = 2*D;
+      for (long k = 1; k < start_mat; k++) {
+        std::vector<R> &cur = *const_coeff_vec_ptr;
+        std::vector<R> &next = *bak_vec_ptr;
+        cnt_factors /= 2;
+        next.resize(cnt_factors);
+        for(long i = 0; i < cnt_factors/2; i++) {
+          next[i] = -cur[i] * cur[i];
+          next[i + cnt_factors/2] = -cur[i + cnt_factors] * cur[i + cnt_factors];
+        }
+        cur.clear();
+        std::swap(const_coeff_vec_ptr, bak_vec_ptr);
+      }
+      R s;
+      /**
+       * for the k-th layer, there are 2D/2^{k-1} factors
+       * i.e., D/2^{k-1} factors for each block
+       * in each block, the coeff group of the i-th factor occupies
+       * the slots indexed by i + j * D/2^{k-1} in a bit-reversed order
+       * the i-th coeff group can be combined with the i + D/2^k-th group
+       * (combing u0 & v0, u1 & v1, ...)
+       * u0  u1  ...
+       *   v0  v1  ...
+      */
+      for (long k = start_mat; k < end_mat; k++) {
+        std::vector<R> &const_coeffs = *const_coeff_vec_ptr;
+        assertEq((long)const_coeffs.size(),(2*D) >> (k-1), 
+          "cnt_factors mismatch");
+        NTL::Mat<R> lin2x2;
+        lin2x2.SetDims(2, 2);
+        long group_size = 1L << (k-1);
+        long stride = cnt_factors / 2;
+        for(long Aidx = 0; Aidx < 2; Aidx++) {
+          for(long i = 0; i < stride / 2; i++) {
+            s = const_coeffs[i + Aidx * cnt_factors / 2];
+            if(!inverse) { // IFFT
+              // b
+              lin2x2[0][0] = R(1) / R(2); // u
+              lin2x2[1][0] = R(1) / R(2); // v
+              // a
+              lin2x2[0][1] = -R(1) / (2*s); // u
+              lin2x2[1][1] = R(1) / (2*s);  // v
+            } else { // FFT
+              // u
+              lin2x2[0][0] = R(1); // b
+              lin2x2[1][0] = -s;   // a
+              // v
+              lin2x2[0][1] = R(1); // b
+              lin2x2[1][1] = s;    // a
+            }
+            for(long j = 0; j < group_size; j++) {
+              if(!inverse) // IFFT
+                DoubleLinComb(As[Aidx], i + j * stride, 
+                  i + j * stride + stride / 2, lin2x2, diag_set, new_diags);
+              else // FFT
+                DoubleLinCombRows(As[Aidx], i + j * stride,
+                  i + j * stride + stride / 2, lin2x2, diag_set, new_diags);
+            }
+          }
+        }
+        // update diag_set (both block share the same diag_set)
+        diag_set.merge(new_diags);
+        new_diags.clear();
+        // update coeff vector
+        std::vector<R> &cur = *const_coeff_vec_ptr;
+        std::vector<R> &next = *bak_vec_ptr;
+        cnt_factors /= 2;
+        next.resize(cnt_factors);
+        for(long i = 0; i < cnt_factors / 2; i++) {
+          next[i] = -cur[i]*cur[i];
+          next[i + cnt_factors/2] = -cur[i+cnt_factors]*cur[i+cnt_factors];
+        }
+        cur.clear();
+        std::swap(const_coeff_vec_ptr, bak_vec_ptr);
+      }
+    } // end p = 1 mod 4
+    // FIXME:        | aI bI |
+    //  the matrices | cI dI | do not correspond to sparse frobenius transforms...
+    // NOTE: for non-forceRadix2:
+    //  1. the first IFFT map is followed by a P->N basis-switch
+    //  2. the last FFT map does NOT include a N->P basis-swtich
+    //    because the FFT inputs are already in X-basis
+    //  3. the other IFFT/FFT maps are performed on the X-basis
+    // NOTE: for forceRadix2:
+    //  1. the first IFFT map is followed by a P->N basis-switch
+    //  2. the last FFT includes a N->P basis-swtich
+    //    because the FFT inputs are in normal-basis
+    //  3. the other IFFT/FFT maps are performed on the normal basis
+    // 
+    // to transform a map M on normal basis to X-basis
+    // compute M_p2n * M * M_n2p
+    // NOTE: the linearized polynomials in forceRadix2 case can be obtained directly,
+    //  but we choose to reuse helib's code as much as we can
+
+    // // the first IFFT / last FFT matrix
+    // if(GtoFi) { // start_mat has been modified... so use GtoFi
+    //   // NOTE: for IFFT, always perforn P->N basis switch
+    //   //  after the first BlockMatMul1D
+    //   if(!inverse) {
+    //     const auto& n2p_mat =
+    //       base_ea.getDerived(PA_zz_p()).getNormalBasisMatrix();
+    //     for(long Aidx = 0; Aidx < cnt_A; Aidx++)
+    //       for(long i = 0; i < D; i++)
+    //         MulCol(As[Aidx], i, n2p_mat, diag_set);
+    //   } else if (forceRadix2) {
+    //     // the last layer in FFT for forceRadix2 
+    //     // includes a N->P basis switch
+    //     const auto& p2n_mat = 
+    //       base_ea.getDerived(PA_zz_p()).getNormalBasisMatrixInverse();
+    //     for (long Aidx = 0; Aidx < cnt_A; Aidx++)
+    //       for (long i = 0; i < D; i++)
+    //         MulRow(As[Aidx], i, p2n_mat, diag_set);
+    //   }
+    // } else if (forceRadix2) {
+    //   // for forceRadix2, other layers are performed on the normal basis
+    //   const auto& n2p_mat =
+    //     base_ea.getDerived(PA_zz_p()).getNormalBasisMatrix();
+    //   const auto& p2n_mat = 
+    //     base_ea.getDerived(PA_zz_p()).getNormalBasisMatrixInverse();
+    //   for (long Aidx = 0; Aidx < cnt_A; Aidx++)
+    //     for (long i = 0; i < D; i++){
+    //       MulRow(As[Aidx], i, p2n_mat, diag_set);
+    //       MulCol(As[Aidx], i, n2p_mat, diag_set);
+    //   }
+    // }
+
+    // include the P->N mat in the last BlockMatMul1D of thick bts
+    // i.e., (1) p % 4 == 1
+    // (2) start_mat = 0 for p % 4 == 3 and not forceRadix2
+    // (3) end_mat = nmats for p % 4 == 3 and forceRadix2
+    // which is equivalent to !forceRadix2 || end_mat == nmats
+    if ((!forceRadix2 || end_mat == nmats) && !inverse && isThick) {
+      const auto& n2p_mat =
+        base_ea.getDerived(PA_zz_p()).getNormalBasisMatrix();
+      for(long Aidx = 0; Aidx < cnt_A; Aidx++)
+        for(long i = 0; i < D; i++)
+          MulCol(As[Aidx], i, n2p_mat, diag_set);
+    }
+    // for the last IFFT layer in thin bts + forceRadix2
+    // we need an extra projection map in the end 
+    if (!isThick && !inverse && forceRadix2 && end_mat == nmats) {
+      mat_R proj_mat;
+      proj_mat.SetDims(d, d);
+      proj_mat[0][0] = 1;
+      for (long i = 0; i < D; i++)
+        MulCol(As[0], i, proj_mat, diag_set);
+    }
+    // build diag_indices
+    diag_indices.assign(diag_set.begin(), diag_set.end());
+    std::sort(diag_indices.begin(), diag_indices.end());
+  }
+
+  const std::vector<long>& nonzeroDiagnoals() const override
+  {
+    return diag_indices;
+  }
+
+  bool get(mat_R& out, long i, long j, long k) const override
+  {
+    if (multiple_blocks) {
+      if (k == 0)
+        out = As[0][i][j];
+      else
+        out = As[1][i][j];
+    } else
+      out = As[0][i][j];
+    return IsZero(out);
+  }
+
+  const EncryptedArray& getEA() const override { return base_ea; }
+  bool multipleTransforms() const override { return multiple_blocks; }
+  long getDim() const override { return base_ea.dimension() - 1; }
+  bool isSubField() const override { return subfield; }
+};
+
+/*
+  the hypercube may contain one or two hypercolumns (stored in A0, A1)
+*/
+class Po2IFFTStep2Matrix : public MatMul1D_derived<PA_zz_p>
+{
+  PA_INJECT(PA_zz_p)
+
+  const EncryptedArray& base_ea;
+  bool multiple_blocks;
+  bool inverse;
+  NTL::Mat<RX> As[2];
+  // whether this is a two-dim transform
+  int multiDim;
+  // a 2x2 matrix
+  // for IFFT, the actual multi-dim matrix is 
+  // | As[0], 0     |   | multiDimMat[0][0]*I, multiDimMat[0][1]*I |
+  // | 0    , As[1] | * | multiDimMat[1][0]*I, multiDimMat[1][1]*I |
+  // for FFT, the two multiplicand are swapped
+  NTL::Mat<RX> multiDimMat;
+  std::vector<long> diag_indices;
+
+public:
+  // mainly copied from Po2IFFTStep1Matrix
+  Po2IFFTStep2Matrix(const EncryptedArray& _ea,
+                     bool _inverse,
+                     bool isThick,
+                     long start_mat,
+                     long end_mat) : /* nmats is the number of steps in FFT*/
+      base_ea(_ea), inverse(_inverse)
+  {
+    multiple_blocks = base_ea.dimension() > 1;
+    const auto& alMod = base_ea.getAlMod().getDerived(PA_zz_p());
+    const auto& zmStar = alMod.getZMStar();
+    const auto& palg = base_ea.getPAlgebra();
+    // NOTE: the larger dimension should always be the second one!!!
+    long D = base_ea.sizeOfDimension(base_ea.dimension() - 1);
+    long d = palg.getOrdP();
+    // long M = palg.getM();
+    long p = zmStar.getP();
+    // long r = alMod.getR();
+
+    long nmats = NTL::NumTwos(NTL::ZZ(palg.getNSlots())) + 1;
+    multiDim = 0;
+    if((p % 4 == 1) && (end_mat == nmats)) 
+      multiDim = inverse ? -1 : 1;
+    if(p % 4 == 3)
+      assertTrue(start_mat > 1, "Po2IFFTStep2: expecting start_mat > 1 for [p]_4=3");
+    else // for p % 4 = 1, start_mat = 0 is possible when d = 1 or bts is thin
+      assertTrue(d == 1 || !isThick || start_mat > 0, "Po2IFFTStep2: expecting start_mat > 1 for [p]_4=1");
+    assertTrue(start_mat < end_mat, "err: start >= end_mat");
+    assertTrue(end_mat <= nmats, "err: end_mat > nmats");
+    assertTrue(palg.getNSlots() == D * (1 + multiple_blocks), "what happened ???");
+
+    RBak bak;
+    bak.save();
+    alMod.restoreContext();
+    // build A0, A1, diag_indices
+    long cnt_A = 1 + multiple_blocks;
+    for(long Aidx = 0; Aidx < cnt_A; Aidx++){
+      As[Aidx].SetDims(D, D);
+      for(long i = 0; i < D; i++)
+        As[Aidx][i][i] = 1;
+    }
+    std::set<long> diag_set, new_diags;
+    diag_set.insert(0);
+    if(p % 4 == 3) {
+      NTL::Mat<RX> &A0 = As[0];
+      assertFalse(multiple_blocks, "p = 3 mod 4 should have only one dim");
+      std::unique_ptr<std::vector<R>> middle_coeff_vec_ptr = std::make_unique<std::vector<R>>();
+      std::unique_ptr<std::vector<R>> bak_vec_ptr = std::make_unique<std::vector<R>>();
+      {
+        std::vector<R> &middle_coeffs = *middle_coeff_vec_ptr;
+        middle_coeffs.resize(D);
+        for(long i = 0; i < D; i++)
+          middle_coeffs[i] = NTL::coeff(alMod.getFactors()[i], d/2);
+      }
+      R const_coeff = NTL::coeff(alMod.getFactors()[0], 0);
+      assertTrue(const_coeff == 1 || const_coeff == -1, "const coeff not \\pm 1");
+      R s, t;
+#if 0
+      // handle the special whole-mat case
+      if (start_mat == 0 && end_mat == nmats && !isThick) {
+        REBak rebak;
+        rebak.save();
+        base_ea.restoreContextForG();
+
+        std::vector<R> &middle_coeffs = *middle_coeff_vec_ptr;
+        RX G = alMod.getFactors()[0]; // should be equal to G
+        NTL::Mat<mat_R> lin2x2;
+        NTL::Mat<RX> lin2x2_RX;
+        NTL::Mat<RE> lin2x2_RE, lin2x2_RE_tmp;
+        lin2x2.SetDims(2, 2);
+        lin2x2_RX.SetDims(2, 2);
+        lin2x2_RE.SetDims(2, 2);
+        lin2x2_RE_tmp.SetDims(2, 2);
+        lin2x2[0][0].SetDims(d, d);
+        lin2x2[0][1].SetDims(d, d);
+        lin2x2[1][0].SetDims(d, d);
+        lin2x2[1][1].SetDims(d, d);
+        long r = alMod.getR();
+        // the FFT case is easier to compute (i.e., inverse = 1)
+        mat_R Fi2G_lo, Fi2G_hi;
+        for (long i = 0; i < D/2; i++) {
+          ppInvert(Fi2G_lo, _ea.getDerived(PA_zz_p()).getMat(i), p, r);
+          ppInvert(Fi2G_hi, _ea.getDerived(PA_zz_p()).getMat(i+D/2), p, r);
+          s = middle_coeffs[i];
+          t = const_coeff;
+          lin2x2[0][0][0][0] = R(1);    // d
+          lin2x2[1][0][0][0] = -t;      // b
+          lin2x2[1][0][d/2][0] = s*t; // a
+          // H
+          lin2x2[0][0][d/2][d/2] = R(1);  // c
+          lin2x2[1][0][0][d/2] = -s;        // b
+          lin2x2[1][0][d/2][d/2] = s*s-t; // a
+          // L'
+          lin2x2[0][1][0][0] = R(1);     // d
+          lin2x2[1][1][0][0] = -t;       // b
+          lin2x2[1][1][d/2][0] = -s*t; // a
+          // H'
+          lin2x2[0][1][d/2][d/2] = R(1);  // c
+          lin2x2[1][1][0][d/2] = s;         // b
+          lin2x2[1][1][d/2][d/2] = s*s-t; // a
+
+          lin2x2[0][0] *= Fi2G_lo;
+          lin2x2[1][0] *= Fi2G_lo;
+          lin2x2[0][1] *= Fi2G_hi;
+          lin2x2[1][1] *= Fi2G_hi;
+          // get the first row
+          NTL::conv(lin2x2_RX[0][0], lin2x2[0][0][0]);
+          NTL::conv(lin2x2_RX[0][1], lin2x2[0][1][0]);
+          NTL::conv(lin2x2_RX[1][0], lin2x2[1][0][0]);
+          NTL::conv(lin2x2_RX[1][1], lin2x2[1][1][0]);
+          std::cout << lin2x2 << "\n\n";
+          std::cout << lin2x2_RX[0][0] << "\n"
+                    << lin2x2_RX[0][1] << "\n"
+                    << lin2x2_RX[1][0] << "\n"
+                    << lin2x2_RX[1][1] << "\n\n";
+          if (!inverse) {
+            NTL::conv(lin2x2_RE_tmp, lin2x2_RX);
+            ppInvert(lin2x2_RE, lin2x2_RE_tmp, p, r);
+            NTL::conv(lin2x2_RX, lin2x2_RE);
+          }
+          // A0 = I, so it doesn't matter if we perform row or col operation
+          DoubleLinComb(A0, i, i+D/2, lin2x2_RX, diag_set, new_diags);
+        }
+        diag_set.merge(new_diags);
+        new_diags.clear();
+        start_mat = 2;
+      }
+#endif
+      // prepare the middle coeffs
+      long cnt_factors = D;
+      for(long k = 1; k < start_mat; k++) {
+        std::vector<R> &cur = *middle_coeff_vec_ptr;
+        std::vector<R> &next = *bak_vec_ptr;
+        cnt_factors /= 2;
+        next.resize(cnt_factors);
+        for(long i = 0; i < cnt_factors; i++)
+          next[i] = 2*const_coeff-cur[i]*cur[i];
+        cur.clear();
+        std::swap(middle_coeff_vec_ptr, bak_vec_ptr);
+        const_coeff *= const_coeff; // const_coeff = 1
+      }
+      // compute each layer
+      for (long k = start_mat; k < end_mat; k++) {
+        std::vector<R> &middle_coeffs = *middle_coeff_vec_ptr;
+        assertEq(cnt_factors, (long)middle_coeffs.size(), "cnt_factors mismatch");
+        assertEq(cnt_factors, D >> (k-1), "cnt factors wrong");
+        long group_size = 1L << (k-1);
+        NTL::Mat<R> lin4x4; // matrix of R instead of mat_R here
+        lin4x4.SetDims(4, 4);
+        for(long i = 0; i < cnt_factors / 2; i++) {
+          s = middle_coeffs[i];
+          t = const_coeff;
+          // the same lin4x4 is used for all the quad-pairs in the coeff group
+          if(!inverse){ // IFFT
+            // d
+            lin4x4[0][0] = R(1) / R(2);  // L
+            lin4x4[1][0] = R(1) / R(2);  // L'
+            lin4x4[2][0] = -t / (2*s);   // H
+            lin4x4[3][0] = t / (2*s);    // H'
+            // b
+            lin4x4[2][1] = -R(1) / (2*s);  // H
+            lin4x4[3][1] = R(1) / (2*s);   // H'
+            // c
+            lin4x4[0][2] = (t-s*s) / (2*s*t);  // L
+            lin4x4[1][2] = -(t-s*s) / (2*s*t); // L'
+            lin4x4[2][2] = R(1) / R(2);        // H
+            lin4x4[3][2] = R(1) / R(2);        // H'
+            // a
+            lin4x4[0][3] = R(1) / (2*s*t);  // L
+            lin4x4[1][3] = -R(1) / (2*s*t); // L'
+          } else { // FFT
+            // L
+            lin4x4[0][0] = R(1);
+            lin4x4[1][0] = -t;
+            lin4x4[3][0] = s*t;
+            // L'
+            lin4x4[0][1] = R(1);
+            lin4x4[1][1] = -t;
+            lin4x4[3][1] = -s*t;
+            // H
+            lin4x4[1][2] = -s;
+            lin4x4[2][2] = R(1);
+            lin4x4[3][2] = s*s-t;
+            // H'
+            lin4x4[1][3] = s;
+            lin4x4[2][3] = R(1);
+            lin4x4[3][3] = s*s-t;
+          }
+          // performing linear combination for each quad-pair
+          for(long j = 0; j < group_size; j += 2) {
+            // long Lidx = i + j * cnt_factors,
+            //      Hidx = i + (j+1) * cnt_factors;
+            // long LLidx = Lidx + cnt_factors / 2,
+            //      HHidx = Hidx + cnt_factors / 2;
+            if(!inverse) // IFFT
+              QuadLinComb(A0, i + j * cnt_factors, cnt_factors / 2, 
+                  lin4x4, diag_set, new_diags);
+            else // FFT
+              QuadLinCombRows(A0, i + j * cnt_factors, cnt_factors / 2,
+                  lin4x4, diag_set, new_diags);
+          }
+        }
+        // update the diag_set after multiplication is done
+        diag_set.merge(new_diags);
+        new_diags.clear();
+        // update coeff vectors
+        std::vector<R> &cur = *middle_coeff_vec_ptr;
+        std::vector<R> &next = *bak_vec_ptr;
+        cnt_factors /= 2;
+        next.resize(cnt_factors);
+        for(long i = 0; i < cnt_factors; i++)
+          next[i] = 2*const_coeff-cur[i]*cur[i];
+        cur.clear();
+        std::swap(middle_coeff_vec_ptr, bak_vec_ptr);
+        const_coeff *= const_coeff; // const_coeff = 1
+      }
+    } else { // p = 1 mod 4, radix-2 FFT
+      if (start_mat == 0)
+        start_mat++;
+      assertTrue(multiple_blocks, "p = 1 mod 4 should have multiple blocks");
+      std::unique_ptr<std::vector<R>> const_coeff_vec_ptr = std::make_unique<std::vector<R>>();
+      std::unique_ptr<std::vector<R>> bak_vec_ptr = std::make_unique<std::vector<R>>();
+      {
+        std::vector<R> &const_coeffs = *const_coeff_vec_ptr;
+        const_coeffs.resize(2*D);
+        for(long i = 0; i < D; i++) {
+          const_coeffs[i] = NTL::coeff(alMod.getFactors()[i], 0);
+          const_coeffs[i + D] = NTL::coeff(alMod.getFactors()[i + D], 0);
+        }
+      }
+      // prepare the const coeffs
+      long cnt_factors = 2*D;
+      for (long k = 1; k < start_mat; k++) {
+        std::vector<R> &cur = *const_coeff_vec_ptr;
+        std::vector<R> &next = *bak_vec_ptr;
+        cnt_factors /= 2;
+        next.resize(cnt_factors);
+        for(long i = 0; i < cnt_factors/2; i++) {
+          next[i] = -cur[i] * cur[i];
+          next[i + cnt_factors/2] = -cur[i + cnt_factors] * cur[i + cnt_factors];
+        }
+        cur.clear();
+        std::swap(const_coeff_vec_ptr, bak_vec_ptr);
+      }
+      R s;
+      /**
+       * for the k-th layer, there are 2D/2^{k-1} factors
+       * i.e., D/2^{k-1} factors for each block
+       * in each block, the coeff group of the i-th factor occupies
+       * the slots indexed by i + j * D/2^{k-1} in a bit-reversed order
+       * the i-th coeff group can be combined with the i + D/2^k-th group
+       * (combing u0 & v0, u1 & v1, ...)
+       * u0  u1  ...
+       *   v0  v1  ...
+      */
+      for (long k = start_mat; k < end_mat && k < nmats - 1; k++) {
+        std::vector<R> &const_coeffs = *const_coeff_vec_ptr;
+        assertEq((long)const_coeffs.size(),(2*D) >> (k-1), 
+          "cnt_factors mismatch");
+        NTL::Mat<R> lin2x2;
+        lin2x2.SetDims(2, 2);
+        long group_size = 1L << (k-1);
+        long stride = cnt_factors / 2;
+        for(long Aidx = 0; Aidx < 2; Aidx++) {
+          for(long i = 0; i < stride / 2; i++) {
+            s = const_coeffs[i + Aidx * cnt_factors / 2];
+            if(!inverse) { // IFFT
+              // b
+              lin2x2[0][0] = R(1) / R(2); // u
+              lin2x2[1][0] = R(1) / R(2); // v
+              // a
+              lin2x2[0][1] = -R(1) / (2*s); // u
+              lin2x2[1][1] = R(1) / (2*s);  // v
+            } else { // FFT
+              // u
+              lin2x2[0][0] = R(1); // b
+              lin2x2[1][0] = -s;   // a
+              // v
+              lin2x2[0][1] = R(1); // b
+              lin2x2[1][1] = s;    // a
+            }
+            for(long j = 0; j < group_size; j++) {
+              if(!inverse) // IFFT
+                DoubleLinComb(As[Aidx], i + j * stride, 
+                  i + j * stride + stride / 2, lin2x2, diag_set, new_diags);
+              else // FFT
+                DoubleLinCombRows(As[Aidx], i + j * stride,
+                  i + j * stride + stride / 2, lin2x2, diag_set, new_diags);
+            }
+          }
+        }
+        // update diag_set (both block share the same diag_set)
+        diag_set.merge(new_diags);
+        new_diags.clear();
+        // update coeff vector
+        std::vector<R> &cur = *const_coeff_vec_ptr;
+        std::vector<R> &next = *bak_vec_ptr;
+        cnt_factors /= 2;
+        next.resize(cnt_factors);
+        for(long i = 0; i < cnt_factors / 2; i++) {
+          next[i] = -cur[i]*cur[i];
+          next[i + cnt_factors/2] = -cur[i+cnt_factors]*cur[i+cnt_factors];
+        }
+        cur.clear();
+        std::swap(const_coeff_vec_ptr, bak_vec_ptr);
+      }
+      // the multi-dim transform
+      if(multiDim) {
+        assertEq(cnt_factors, 2L, "expecting 2 factors for multi-dim map");
+        s = (*const_coeff_vec_ptr)[0];
+        multiDimMat.SetDims(2, 2);
+        if(!inverse) { // IFFT, multiDIm = 1, right mul
+          // b
+          multiDimMat[0][0] = R(1) / R(2); // u
+          multiDimMat[1][0] = R(1) / R(2); // v
+          // a
+          multiDimMat[0][1] = -R(1) / (2*s); // u
+          multiDimMat[1][1] = R(1) / (2*s);  // v
+        } else { // FFT, multiDim = -1, left mul
+          // u
+          multiDimMat[0][0] = R(1); // b
+          multiDimMat[1][0] = -s;   // a
+          // v
+          multiDimMat[0][1] = R(1); // b
+          multiDimMat[1][1] = s;    // a
+        }
+        // XXX: for p==1 mod 4 and d = 1,
+        //  we still need to include the move-to-normal map...
+        //  because the normal element is randomly chosen and not necessarily 1!!!
+        // NOTE: I have modified the normal element generation process
+        //  so that the normal element is always 1 when d = 1
+        // XXX: debug
+        // std::cout << "DEBUG IS ON, SETTING multiDim = false\n";
+        // std::cout << "s = " << s << "\n\n";
+        // std::cout << alMod.getFactors() << "\n\n";
+        // std::cout << As[0] << "\n\n" << As[1] << "\n\n";
+        // multiDim = 0;
+        // multiDimMat[0][0] = multiDimMat[1][1] = 0;
+        // std::cout << multiDimMat << "\n\n";
+        // As[0][0][1] = As[0][1][0] = As[1][0][1] = As[1][1][0] = 0;
+        // As[0][0][0] = As[0][1][1] = As[1][0][0] = As[1][1][1] = 1;
+      }
+    }
+    // note that the move-to-normal-basis map is included in Po2IFFTStep1Matrix
+    // build diag_indices
+    diag_indices.assign(diag_set.begin(), diag_set.end());
+    std::sort(diag_indices.begin(), diag_indices.end());
+  }
+
+  const std::vector<long>& nonzeroDiagnoals() const override
+  {
+    return diag_indices;
+  }
+
+  bool get(RX& out, long i, long j, long k) const override
+  {
+    if (multiple_blocks) {
+      if (k == 0)
+        out = As[0][i][j];
+      else
+        out = As[1][i][j];
+    } else
+      out = As[0][i][j];
+    return IsZero(out);
+  }
+
+  const EncryptedArray& getEA() const override { return base_ea; }
+  bool multipleTransforms() const override { return multiple_blocks; }
+  int multiDimInfo() const override { return multiDim; }
+  const NTL::Mat<RX>& getPo2MultiDimMat() const override { return multiDimMat; }
+  long getDim() const override { return base_ea.dimension()-1; }
+};
+
+
+// implementation of Po2IFFT
+Po2IFFT::Po2IFFT(const EncryptedArray& _ea,
+                 bool _invert,
+                 const std::vector<long>& _partition,
+                 bool forceRadix2,
+                 bool build_cache) :
+    ea(_ea), invert(_invert)
+{
+  assertEq(ea.getTag(), PA_zz_p_tag, "Expecting PA_zz_p tag in Po2 BTS");
+  const auto& alMod = _ea.getAlMod();
+  const auto& zmStar = alMod.getZMStar();
+  assertTrue(zmStar.getPow2() > 0, "M should be a power of 2");
+  long p = zmStar.getP();
+  assertTrue(p % 2 == 1, "p must be odd");
+  assertTrue(_partition.size() > 1 && _partition[0] == 0, "partition err");
+
+  assertTrue(_partition[_partition.size()-1] == 
+    NTL::NumTwos(NTL::ZZ(ea.getPAlgebra().getNSlots())) + 1,
+    "partition end err");
+  // radix-2 FFT for p = 1 mod 4 or Bruun FFT for p = 3 mod 4
+  if((p % 4 == 1) || !forceRadix2) {
+    // special case where d = 1, all matrices are MatMul1D
+    if(zmStar.getOrdP() == 1) {
+      matvec.SetLength(_partition.size() - 1);
+      for(size_t i = 0; i < _partition.size() - 1; i++) {
+        std::unique_ptr<MatMul1D> mat_data;
+        mat_data.reset(new Po2IFFTStep2Matrix(ea, invert, true, _partition[i], _partition[i+1]));
+        matvec[i].reset(new MatMul1DExec(*mat_data));
+      }
+    } else { // d > 1, the first matrix is BlockMatMul1D while others are MatMul1D
+      mat1vec.SetLength(1);
+      std::unique_ptr<BlockMatMul1D> mat1_data;
+      mat1_data.reset(new Po2IFFTStep1Matrix(ea, invert, forceRadix2, true, _partition[0], _partition[1]));
+      mat1vec[0].reset(new BlockMatMul1DExec(*mat1_data));
+
+      matvec.SetLength(_partition.size() - 2);
+      for(size_t i = 1; i < _partition.size() - 1; i++) {
+        std::unique_ptr<MatMul1D> mat_data;
+        mat_data.reset(new Po2IFFTStep2Matrix(ea, invert, true, _partition[i], _partition[i+1]));
+        matvec[i-1].reset(new MatMul1DExec(*mat_data));
+      }
+    }
+  } else { // radix-2 FFT for p = 3 mod 4, all matrices are BlockMatMul1D
+      mat1vec.SetLength(_partition.size() - 1);
+      for(size_t i = 0; i < _partition.size() - 1; i++){
+        std::unique_ptr<BlockMatMul1D> mat1_data;
+        mat1_data.reset(new Po2IFFTStep1Matrix(ea, invert, forceRadix2, true, _partition[i], _partition[i+1]));
+        mat1vec[i].reset(new BlockMatMul1DExec(*mat1_data));
+      }
+  }
+
+  if(build_cache)
+    upgrade();
+}
+
+void Po2IFFT::upgrade()
+{
+  for(auto &blockmat1D : mat1vec)
+    blockmat1D->upgrade();
+  for (auto& mat1D : matvec)
+    mat1D->upgrade();
+}
+
+void Po2IFFT::apply(Ctxt& ctxt) const
+{
+  if (!invert) {
+    for (auto &blockmat1D : mat1vec)
+      blockmat1D->mul(ctxt);
+    for (auto& mat1D : matvec)
+      mat1D->mul(ctxt);
+  } else {
+    for (long i = matvec.length() - 1; i >= 0; i--)
+      matvec[i]->mul(ctxt);
+    for (long i = mat1vec.length() - 1; i >= 0; i--)
+      mat1vec[i]->mul(ctxt);
+  }
+}
+
+
 template <typename type>
 class Step1Matrix : public BlockMatMul1D_derived<type>
 {
@@ -915,4 +2272,127 @@ static MatMul1D* buildThinStep1Matrix(const EncryptedArray& ea,
 }
 //! \endcond
 
+
+// implementation of ThinPo2IFFT
+ThinPo2IFFT::ThinPo2IFFT(const EncryptedArray& _ea,
+                 bool _invert,
+                 const std::vector<long>& _partition,
+                 bool forceRadix2,
+                 bool build_cache,
+                 bool dummy) :
+    ea(_ea), invert(_invert)
+{
+  assertEq(ea.getTag(), PA_zz_p_tag, "Expecting PA_zz_p tag in Po2 BTS");
+  const auto& alMod = _ea.getAlMod();
+  const auto& zmStar = alMod.getZMStar();
+  assertTrue(zmStar.getPow2() > 0, "M should be a power of 2");
+  long p = zmStar.getP();
+  assertTrue(p % 2 == 1, "p must be odd");
+
+  if (dummy) { // a random matrix for comparing with GV23
+    std::cout << "DUMMY Po2IFFT!!!\n";
+    matvec.SetLength(1);
+    std::unique_ptr<MatMul1D> mat_data;
+    mat_data.reset(new Po2RandBtsMatrix(ea));
+    std::cout << "Start constructing MatMul1DExec for DUMMY Po2IFFT\n";
+    matvec[0].reset(new MatMul1DExec(*mat_data, false, true));
+    cnt_clear_bits = NTL::NumTwos(NTL::ZZ(zmStar.getOrdP()));
+  } else {
+    assertTrue(_partition.size() > 1 && _partition[0] == 0, "partition err");
+
+    assertTrue(_partition[_partition.size()-1] == 
+      NTL::NumTwos(NTL::ZZ(ea.getPAlgebra().getNSlots())) + 1,
+      "partition end err");
+    cnt_clear_bits = NTL::NumTwos(NTL::ZZ(zmStar.getOrdP()));
+    // radix-2 FFT for p = 1 mod 4 or Bruun FFT for p = 3 mod 4
+    if(p % 4 == 1) {
+      // for p = 1 mod 4, the encoding map is identity, all matrices are MatMul1D
+      matvec.SetLength(_partition.size() - 1);
+      for(size_t i = 0; i < _partition.size() - 1; i++) {
+        std::unique_ptr<MatMul1D> mat_data;
+        mat_data.reset(new Po2IFFTStep2Matrix(ea, invert, false, _partition[i], _partition[i+1]));
+        matvec[i].reset(new MatMul1DExec(*mat_data));
+      }
+    } else { // p = 3 mod 4
+      if (!forceRadix2) {
+        // Bruun FFT, the encoding map and the first IFFT layer
+        //  take place in a degree-2 subfield
+        //  other matrices are MatMul1D
+        // NOTE: the whole FFT map can be represented as a MatMul1D
+        //  be constraining the map on Z_{p^r} \subset Z_{p^r}[X]/G
+        //  however, this is not true for the IFFT map
+        // if(_partition.size() == 2) {
+        //   matvec.SetLength(1);
+        //   std::unique_ptr<MatMul1D> mat_data;
+        //   mat_data.reset(new Po2IFFTStep2Matrix(ea, invert, false, _partition[0], _partition[1]));
+        //   matvec[0].reset(new MatMul1DExec(*mat_data));
+        // } else {
+        mat1vec.SetLength(1);
+        std::unique_ptr<BlockMatMul1D> mat1_data;
+        mat1_data.reset(new Po2IFFTStep1Matrix(ea, invert, forceRadix2, false, _partition[0], _partition[1]));
+        mat1vec[0].reset(new BlockMatMul1DExec(*mat1_data));
+
+        matvec.SetLength(_partition.size() - 2);
+        for(size_t i = 1; i < _partition.size() - 1; i++) {
+          std::unique_ptr<MatMul1D> mat_data;
+          mat_data.reset(new Po2IFFTStep2Matrix(ea, invert, false, _partition[i], _partition[i+1]));
+          matvec[i-1].reset(new MatMul1DExec(*mat_data));
+        }
+        // }
+      } else { // forceRadix2
+          // radix-2 FFT for p = 3 mod 4, all matrices are BlockMatMul1D on degree-2 subfield
+          mat1vec.SetLength(_partition.size() - 1);
+          for(size_t i = 0; i < _partition.size() - 1; i++){
+            std::unique_ptr<BlockMatMul1D> mat1_data;
+            mat1_data.reset(new Po2IFFTStep1Matrix(ea, invert, forceRadix2, false, _partition[i], _partition[i+1]));
+            mat1vec[i].reset(new BlockMatMul1DExec(*mat1_data));
+          }
+          cnt_clear_bits -= 1; // clear one bit less
+      }
+    }
+  }
+
+  if(build_cache){
+    if(dummy)
+      std::cout << "Start upgrading in DUMMY transform\n";
+    upgrade();
+  }
+}
+
+void ThinPo2IFFT::upgrade()
+{
+  for(auto &blockmat1D : mat1vec)
+    blockmat1D->upgrade();
+  for (auto& mat1D : matvec)
+    mat1D->upgrade();
+}
+
+void ThinPo2IFFT::apply(Ctxt& ctxt) const
+{
+  if (!invert) { // IFFT
+    // remove extra coefficients first
+    Ctxt c1(ZeroCtxtLike, ctxt);
+    long m = ea.getAlMod().getZMStar().getM();
+    for (long i = 0; i < cnt_clear_bits; i++) {
+      c1 = ctxt;
+      // X->X^{m/2^{i+1}+1}
+      ctxt.smartAutomorph((m >> (i+1)) + 1);
+      ctxt += c1;
+    }
+    ctxt *= NTL::InvMod(1L << cnt_clear_bits, ctxt.getPtxtSpace());
+    // then apply the linear transforms
+    for (auto &blockmat1D : mat1vec)
+      blockmat1D->mul(ctxt);
+    for (auto& mat1D : matvec)
+      mat1D->mul(ctxt);
+  } else { // FFT
+    for (long i = matvec.length() - 1; i >= 0; i--)
+      matvec[i]->mul(ctxt);
+    for (long i = mat1vec.length() - 1; i >= 0; i--)
+      mat1vec[i]->mul(ctxt);
+  }
+}
+
+
+
 } // namespace helib
diff --git a/src/NumbTh.cpp b/src/NumbTh.cpp
index 5e60bcd..7e22d01 100644
--- a/src/NumbTh.cpp
+++ b/src/NumbTh.cpp
@@ -1096,21 +1096,29 @@ void seekPastChar(std::istream& str, int cc)
 // map defined by its action on the standard basis for zz_pE over zz_p:
 // for i = 0..zz_pE::degree()-1: x^i -> L[i], where x = (X mod zz_pE::modulus())
 
-void buildLinPolyMatrix(NTL::mat_zz_pE& M, long p)
+void buildLinPolyMatrix(NTL::mat_zz_pE& M, long p, bool subfield)
 {
   long d = NTL::zz_pE::degree();
+  if (!subfield) {
+    M.SetDims(d, d);
 
-  M.SetDims(d, d);
+    for (long j = 0; j < d; j++)
+      NTL::conv(M[0][j], NTL::zz_pX(j, 1));
 
-  for (long j = 0; j < d; j++)
-    NTL::conv(M[0][j], NTL::zz_pX(j, 1));
+    for (long i = 1; i < d; i++)
+      for (long j = 0; j < d; j++)
+        M[i][j] = power(M[i - 1][j], p);
+  } else {
+    M.SetDims(2, 2);
 
-  for (long i = 1; i < d; i++)
-    for (long j = 0; j < d; j++)
-      M[i][j] = power(M[i - 1][j], p);
+    for (long j = 0; j < 2; j++){
+      NTL::conv(M[0][j], NTL::zz_pX(j * d/2, 1));
+      M[1][j] = power(M[0][j], p);
+    }
+  }
 }
 
-void buildLinPolyMatrix(NTL::mat_GF2E& M, long p)
+void buildLinPolyMatrix(NTL::mat_GF2E& M, long p, bool subfield)
 {
   assertEq<InvalidArgument>(p,
                             2l,
@@ -1118,15 +1126,23 @@ void buildLinPolyMatrix(NTL::mat_GF2E& M, long p)
                             "a mat_GF2E (Galois field 2)");
 
   long d = NTL::GF2E::degree();
+  if (!subfield) {
+    M.SetDims(d, d);
 
-  M.SetDims(d, d);
+    for (long j = 0; j < d; j++)
+      NTL::conv(M[0][j], NTL::GF2X(j, 1));
 
-  for (long j = 0; j < d; j++)
-    NTL::conv(M[0][j], NTL::GF2X(j, 1));
+    for (long i = 1; i < d; i++)
+      for (long j = 0; j < d; j++)
+        M[i][j] = power(M[i - 1][j], p);
+  } else {
+    M.SetDims(2, 2);
 
-  for (long i = 1; i < d; i++)
-    for (long j = 0; j < d; j++)
-      M[i][j] = power(M[i - 1][j], p);
+    for (long j = 0; j < 2; j++){
+      NTL::conv(M[0][j], NTL::GF2X(j * d/2, 1));
+      M[1][j] = power(M[0][j], p);
+    }
+  }
 }
 
 // some auxiliary conversion routines
diff --git a/src/PAlgebra.cpp b/src/PAlgebra.cpp
index b24f9de..4e8d9f1 100644
--- a/src/PAlgebra.cpp
+++ b/src/PAlgebra.cpp
@@ -487,7 +487,7 @@ PAlgebra::PAlgebra(long mm,
 
   resize(native, lsize(tmpOrds));
   resize(frob_perturb, lsize(tmpOrds));
-  std::vector<long> p_subgp(mm);
+  std::vector<long> p_subgp(mm); // NOTE: p_subgp[a] = log_p(a) if a is in <p>, otherwise -1. i.e., discrete logarithm
   for (long i : range(mm))
     p_subgp[i] = -1;
   long pmodm = pp % mm;
@@ -550,6 +550,10 @@ PAlgebra::PAlgebra(long mm,
   // The comment about reverse order is correct, SH.
 
   // buffer is initialized to all-zero, which represents 1=\prod_i gi^0
+  // NOTE: the order of T[i]s:
+  //       start: (e0, ..., en) = (0,...,0)
+  //       next:                = (0,...,1)
+  //       ......
   std::vector<long> buffer(gens.size()); // temporary holds exponents
 
   long ctr = 0;
@@ -724,11 +728,14 @@ PAlgebraModDerived<type>::PAlgebraModDerived(const PAlgebra& _zMStar, long _r) :
   // The remaining factors are ordered according to their representatives.
 
   RXModulus F1(localFactors[0]);
+  // std::cout << localFactors[0] << '\n';
   for (long i = 1; i < nSlots; i++) {
+    // NOTE: why not the minimal poly of x^t ?
     long t = zMStar.ith_rep(i);      // Ft is minimal poly of x^{1/t} mod F1
     long tInv = NTL::InvMod(t, m);   // tInv = t^{-1} mod m
     RX X2tInv = PowerXMod(tInv, F1); // X2tInv = X^{1/t} mod F1
     NTL::IrredPolyMod(localFactors[i], X2tInv, F1);
+    // std::cout << localFactors[i] << '\n';
     // IrredPolyMod(X,P,Q) returns in X the minimal polynomial of P mod Q
   }
   /* Debugging sanity-check #1: we should have Ft= GCD(F1(X^t),Phi_m(X))
@@ -934,6 +941,7 @@ void PAlgebraModDerived<type>::embedInAllSlots(
   HELIB_TIMER_STOP;
 }
 
+// NOTE: actual encoding here
 template <typename type>
 void PAlgebraModDerived<type>::embedInSlots(
     RX& H,
@@ -985,13 +993,13 @@ void PAlgebraModDerived<type>::embedInSlots(
     }
 #else
     vec_R in, out;
-
+    // NOTE: map the i-th slot from R[X]/G into R[X]/Fi 
     for (long i : range(nSlots)) {
       if (deg(alphas[i]) <= 0)
         crt[i] = alphas[i];
       else {
         VectorCopy(in, alphas[i], d);
-        mul(out, in, mappingData.matrix_maps[i]);
+        mul(out, in, mappingData.matrix_maps[i]); // NOTE: out = in * matrix_maps[i]
         conv(crt[i], out);
       }
     }
@@ -1037,7 +1045,7 @@ void PAlgebraModDerived<type>::CRT_reconstruct(RX& H,
     resize(crt1, nslots);
     for (long i = 0; i < nslots; i++)
       MulMod(crt1[i], crt[i], crtCoeffs[i], factors[i]);
-
+    // crt1[i] = \prod_{j\ne i}(Fj^-1) * crt[i] mod Fi, evalTree mults crt1[i] with \prod_{j\ne i}Fj and sums them
     evalTree(H, crtTree, crt1, 0, nslots);
   }
   HELIB_TIMER_STOP;
@@ -1093,6 +1101,8 @@ void PAlgebraModDerived<type>::mapToFt(RX& w,
     w = rep(*smallest);
     return;
   }
+  // NOTE: If F1 = G, rF1 = X \in G
+  //       we have w = X^t \in Ft is a root of G (since w^{1/t} has a minimal poly of Ft)
   // if rF1 is set, then use it instead, setting w = rF1(X^t) mod Ft(X)
   RXModulus Ft(factors[i]);
   //  long tInv = InvMod(t,m);
@@ -1112,6 +1122,7 @@ void PAlgebraModDerived<type>::mapToFt(RX& w,
   }*******************************************************************/
 }
 
+// NOTE: EncryptedArray::mappingData is initialized here
 template <typename type>
 void PAlgebraModDerived<type>::mapToSlots(MappingData<type>& mappingData,
                                           const RX& G) const
@@ -1119,6 +1130,7 @@ void PAlgebraModDerived<type>::mapToSlots(MappingData<type>& mappingData,
   assertTrue<InvalidArgument>(
       deg(G) > 0,
       "Polynomial G is constant (has degree less than one)");
+  // NOTE: G can be the minimal polynomial of a subfield of the slot algebra
   assertEq(zMStar.getOrdP() % deg(G),
            0l,
            "Degree of polynomial G does not divide zMStar.getOrdP()");
@@ -1134,6 +1146,9 @@ void PAlgebraModDerived<type>::mapToSlots(MappingData<type>& mappingData,
 
   resize(mappingData.maps, nSlots);
 
+  // NOTE: the code below establishes isomorphisms between R[X]/G and R[X]/factors[i]
+  //  it is given by X \in R[X]/G -> mappingData.maps[i] \in R[X]/Fi
+  // for most cases where G = F0, mappingData.maps[i] = X^ti \in R[X]/Fi 
   mapToF1(mappingData.maps[0], mappingData.G); // mapping from base-G to base-F1
   for (long i = 1; i < nSlots; i++)
     mapToFt(mappingData.maps[i],
@@ -1144,6 +1159,8 @@ void PAlgebraModDerived<type>::mapToSlots(MappingData<type>& mappingData,
   // create matrices to streamline CompMod operations
   resize(mappingData.matrix_maps, nSlots);
   for (long i : range(nSlots)) {
+    // NOTE: the j-th row of matrix_maps[i] is mappingData.map[i]^j
+    //  i.e., v^T * matrix_maps[i] is an isomorphism from R[X]/G to R[X]/Fi
     mat_R& mat = mappingData.matrix_maps[i];
     mat.SetDims(d, ordp);
     RX pow;
@@ -1172,7 +1189,7 @@ void PAlgebraModDerived<type>::mapToSlots(MappingData<type>& mappingData,
       long t = zMStar.ith_rep(i);
       long tInv = NTL::InvMod(t, m);
 
-      RX ct_rep;
+      RX ct_rep; // NOTE: ct_rep = X^{1/t} \in R[X]/G[X], the element with minpoly of Ft
       PowerXMod(ct_rep, tInv, G);
 
       RE ct;
diff --git a/src/extractDigits.cpp b/src/extractDigits.cpp
index c2a484a..32f22e2 100644
--- a/src/extractDigits.cpp
+++ b/src/extractDigits.cpp
@@ -25,7 +25,7 @@ namespace helib {
 // We get poly(x) by interpolating a degree-(p-1) polynomial poly'(x)
 // s.t. poly'(z0)=z0 - z0^p (mod p^e) for all 0<=z0<p, and then setting
 // poly(x) = x^p + poly'(x).
-static void buildDigitPolynomial(NTL::ZZX& result, long p, long e)
+void buildDigitPolynomial(NTL::ZZX& result, long p, long e)
 {
   if (p < 2 || e <= 1)
     return; // nothing to do
@@ -76,10 +76,12 @@ void extractDigits(std::vector<Ctxt>& digits, const Ctxt& c, long r)
 
   long p = context.getP();
 
-  NTL::ZZX x2p;
-  if (p > 3) {
-    buildDigitPolynomial(x2p, p, r);
-  }
+  assertTrue(r == context.getDebugRR(), "rr doesn't match");
+
+  const NTL::ZZX& x2p = context.getLiftPoly();
+  // if (p > 3) {
+  //   buildDigitPolynomial(x2p, p, r);
+  // }
 
   Ctxt tmp(c.getPubKey(), c.getPtxtSpace());
   digits.resize(r, tmp); // allocate space
@@ -170,10 +172,30 @@ static void compute_a_vals(NTL::Vec<NTL::ZZ>& a, long p, long e)
 // has the property that G(x) = (x mod p) (mod p^e).
 // Here, (x mod p) is in the interval [0,1] if p == 2,
 // and otherwise, is in the interval (-p/2, p/2).
-static void compute_magic_poly(NTL::ZZX& poly1, long p, long e)
+void compute_magic_poly(NTL::ZZX& poly1, long p, long e)
 {
   HELIB_TIMER_START;
 
+  // NOTE: this can be really time-consuming for large p
+  // thus, we store the computed value into files
+  // and load them later
+  char buf[200] = "";
+  sprintf(buf, path_of_fatboot.cpp/saved_ZZX/%ld_%ld_ZZX.txt, p, e);
+  {
+    FILE* file = fopen(buf, "r");
+    if (file != nullptr) {
+      long tmp;
+      long idx = 0;
+      while (fscanf(file, "%ld", &tmp) > 0) {
+        NTL::SetCoeff(poly1, idx, tmp);
+        idx++;
+      }
+      fclose(file);
+      std::cerr << "read file " << buf << '\n';
+      return;
+    }
+  }
+
   NTL::Vec<NTL::ZZ> a;
 
   compute_a_vals(a, p, e);
@@ -211,6 +233,206 @@ static void compute_magic_poly(NTL::ZZX& poly1, long p, long e)
 
   poly = X - poly;
   poly1 = NTL::conv<NTL::ZZX>(poly);
+
+  // write to file for large p
+  if (p > 1000) {
+    FILE* file = fopen(buf, "w");
+    for (long i = 0; i <= NTL::deg(poly1); i++)
+      fprintf(file, "%ld\n", NTL::to_long(poly1[i]));
+    fclose(file);
+    std::cerr << "write file " << buf << '\n';
+  }
+}
+
+// return p-valuation of x
+static long valuation(long x, long p)
+{
+  long val = 0;
+  while (x % p == 0) {
+    val++;
+    x /= p;
+  }
+  return val;
+}
+
+// return p-valuation of factorial(n)
+static long valuationFactorial(long n, long p)
+{
+  long i = p;
+  long val = 0;
+  while (i <= n) {
+    val += valuation(i, p);
+    i += p;
+  }
+  return val;
+}
+
+// return min(i) s.t. p^e | factorial(i)
+// NOTE: seems unused...
+// static long smarandache(long p, long e)
+// {
+//   long i = p;
+//   long count = 0;
+//   while (true) {
+//     count += valuation(i, p);
+//     if (count >= e)
+//       return i;
+//     i += p;
+//   }
+// }
+
+// return min(i), s.t., p^e | ((n+i)*...*(n+1))
+static long truncated_smarandache(long n, long p, long e)
+{
+  // start from p*ceil((n+1)/p)
+  long i = p*(1+n/p);
+  long count = 0;
+  while (true) {
+    count += valuation(i, p);
+    if(count >= e)
+      return i;
+    i += p;
+  }
+  return i - n;
+}
+
+// n consecutive numbers S={i,i+1,...i+n-1}
+// compute min(valuation(Prod(S \ {j})), for j in S
+static long absent_valuation(long n, long p)
+{
+  long val = valuationFactorial(n - 1, p);
+  val -= floor(log(n - 1) / log(p));
+  return val;
+}
+
+// compute the local null polynomial
+void compute_null_poly(NTL::ZZX& poly,
+                       long p,
+                       long e,
+                       long t,
+                       long B,
+                       bool isFirstRow)
+{
+  // assertTrue(t <= 2, "t > 2 not supported");
+  // each digit lies in [lo, hi]
+  // we assume here p is odd
+  long hi = (p - 1) >> 1;
+  long lo = -hi;
+  // secondDigitHi * p + hi >= B, xxx = ceil((B - hi) / p)
+  long secondDigitHi = (B - hi + p - 1) / p;
+  // secondDigitLo * p + lo <= -B, xxx = floor((-B - lo) / p)
+  // NOTE: negative numbers are rounded toward 0
+  long secondDigitLo = (-B - lo - p + 1) / p;
+
+  long curHi = isFirstRow ? B : secondDigitHi;
+  long curLo = isFirstRow ? -B : secondDigitLo;
+
+  // the p-valuation of Prod(x-i) for i in [lo,hi]
+  long pexp = absent_valuation(curHi - curLo + 1, p) + t;
+  long nparts = e / pexp;
+  long pexp_total = valuationFactorial(nparts, p) + nparts * pexp;
+  while(pexp_total > e) {
+    nparts--;
+    pexp_total = valuationFactorial(nparts, p) + nparts * pexp;
+  }
+  // now, increasing nparts by 1 will guarantee pexp_total >= e
+  // however, it may not be the optimal strategy
+  long trunc_deg = 0;
+  if (pexp_total < e){
+    long tmp_trunc_deg = truncated_smarandache(curHi - curLo + 1, p, e - pexp_total);
+    if (tmp_trunc_deg < (curHi - curLo + 1)){
+      trunc_deg = tmp_trunc_deg;
+      std::cout << "using truncated smarandache of degree " << tmp_trunc_deg << " < " << (curHi - curLo + 1) << "\n";
+    }
+    else
+      nparts++;
+  }
+  NTL::ZZ p2e = NTL::power(NTL::ZZ(p), e);
+  NTL::ZZ_pPush push(p2e);
+  // std::cout << "current ZZ_p modulus " << NTL::ZZ_p::modulus() << "\n";
+  NTL::ZZ_pX nullpoly(1), basicPoly(1), tmpPoly;
+  NTL::SetCoeff(tmpPoly, 1, 1);
+  for (long i = curLo; i <= curHi; i++) {
+    NTL::SetCoeff(tmpPoly, 0, -i);
+    basicPoly *= tmpPoly;
+  }
+  long p2pexp = NTL::power_long(p, pexp);
+  for (long i = 0; i < nparts; i++) {
+    tmpPoly = basicPoly;
+    tmpPoly[0] -= i * p2pexp;
+    nullpoly *= tmpPoly;
+  }
+  // finally mult by the truncated poly
+  tmpPoly = NTL::ZZ_pX::zero();
+  NTL::SetCoeff(tmpPoly, 1, 1);
+  for (long i = curHi + 1; i <= curHi + trunc_deg; i++) {
+    NTL::SetCoeff(tmpPoly, 0, -i);
+    nullpoly *= tmpPoly;
+  }
+#ifdef HELIB_DEBG
+  // XXX: debug
+  if (isFirstRow == false) {
+    for (long low = curLo; low <= curHi; low++)
+      for (long high = 0; high < NTL::power_long(p, e - 1); high++) {
+        long xin = high * p + low;
+        auto res = NTL::eval(nullpoly, NTL::conv<NTL::ZZ_p>(xin));
+        if (res != NTL::ZZ_p::zero())
+          assertTrue(false, "not a null poly?");
+      }
+    std::cout << "is indeed a null poly\n";
+  }
+  // XXX: debug
+#endif
+  poly = NTL::conv<NTL::ZZX>(nullpoly);
+}
+
+// compute the digit extraction poly for ptxt space p^r and |I| <= B
+void compute_prime_aux_poly(NTL::ZZX& poly, long p, long r, long B, long aux)
+{
+  NTL::ZZ p_ZZ(p);
+  // NOTE: NTL::ZZ_pPush push(NTL::ZZ(p)) is buggy?
+  NTL::ZZ_pPush push(p_ZZ);
+  // std::cout << "current ZZ_p modulus " << NTL::ZZ_p::modulus() << "\n";
+  NTL::ZZX interp_poly, diff_poly;
+  NTL::vec_ZZ inputs, outputs;
+  // long I_range = (2 * B + 1) * (2 * B + 1);
+
+  for (long hi = -B; hi <= B; hi++)
+    for (long lo = -B; lo <= B; lo++) {
+      inputs.append(NTL::ZZ(hi * aux + lo));
+      outputs.append(NTL::ZZ(lo));
+    }
+
+  NTL::vec_ZZ_p inputs_p = NTL::conv<NTL::vec_ZZ_p>(inputs);
+  interp_poly = NTL::conv<NTL::ZZX>(
+      NTL::interpolate(inputs_p, NTL::conv<NTL::vec_ZZ_p>(outputs)));
+  // now lift the poly to Z_p^r
+  NTL::vec_ZZ diff;
+  for (long i = 2; i <= r; i++) {
+    NTL::ZZ curMod = NTL::power(NTL::ZZ(p), i);
+    NTL::ZZ pfactor = curMod / p;
+    { // working modulo p^i
+      NTL::ZZ_pPush push_i(curMod);
+      NTL::ZZ_pX interp_poly_p = NTL::conv<NTL::ZZ_pX>(interp_poly);
+      NTL::vec_ZZ_p diff_p;
+      NTL::eval(diff_p, interp_poly_p, NTL::conv<NTL::vec_ZZ_p>(inputs));
+      // [f(X)]_p^(i-1) - f(X) == p * I(X) mod p^i
+      NTL::sub(diff_p, NTL::conv<NTL::vec_ZZ_p>(outputs), diff_p);
+      diff = NTL::conv<NTL::vec_ZZ>(diff_p);
+
+      for (long j = 0; j < diff.length(); j++)
+        diff[j] /= pfactor;
+    }
+    // now the modulus is back to p
+    interp_poly +=
+        NTL::conv<NTL::ZZX>(
+            NTL::interpolate(inputs_p, NTL::conv<NTL::vec_ZZ_p>(diff))) *
+        pfactor;
+  }
+  NTL::ZZ p2r = NTL::power(NTL::ZZ(p), r);
+  for (long i = 0; i <= deg(interp_poly); i++)
+    interp_poly[i] %= p2r;
+  poly = interp_poly;
 }
 
 // extendExtractDigits assumes that the slots of *this contains integers mod
@@ -221,7 +443,10 @@ static void compute_magic_poly(NTL::ZZX& poly1, long p, long e)
 // integers in the slots of the input. Namely, the i'th slot of digits[j]
 // contains the j'th digit in the p-base expansion of the integer in the i'th
 // slot of the *this.  The plaintext space of digits[j] is mod p^{e+r-j}.
-
+//
+// the notation here is slightly different from the outside
+// r is the number of lower digits to discard, r = caller botHigh = e - e'
+// e is the number of higher digits to keep, e = caller r
 void extendExtractDigits(std::vector<Ctxt>& digits,
                          const Ctxt& c,
                          long r,
@@ -229,19 +454,22 @@ void extendExtractDigits(std::vector<Ctxt>& digits,
 {
   const Context& context = c.getContext();
 
+  assertTrue(r == context.getDebugRR(), "rr doesn't match");
+  assertTrue(e == context.getDebugEE(), "ee doesn't match");
+
   long p = context.getP();
-  NTL::ZZX x2p;
-  if (p > 3) {
-    buildDigitPolynomial(x2p, p, r);
-  }
+  const NTL::ZZX& x2p = context.getLiftPoly();
+  // if (p > 3) {
+  // buildDigitPolynomial(x2p, p, r);
+  // }
 
   // we should pre-compute this table
   // for i = 0..r-1, entry i is G_{e+r-i} in Chen and Han
-  NTL::Vec<NTL::ZZX> G;
-  G.SetLength(r);
-  for (long i : range(r)) {
-    compute_magic_poly(G[i], p, e + r - i);
-  }
+  const NTL::Vec<NTL::ZZX>& G = context.getExtractPolys();
+  // G.SetLength(r);
+  // for (long i : range(r)) {
+  //   compute_magic_poly(G[i], p, e + r - i);
+  // }
 
   std::vector<Ctxt> digits0;
 
@@ -307,4 +535,343 @@ void extendExtractDigits(std::vector<Ctxt>& digits,
   }
 }
 
+void newExtractDigits(std::vector<Ctxt>& digits, const Ctxt& c)
+{
+  const Context& context = c.getContext();
+
+  long t = context.getT();
+  // long aux = context.getAux();
+  // long B = ceil(context.boundForRecryption());
+  long numExtract = context.getNumExtract();
+
+  Ctxt tmp(c.getPubKey(), c.getPtxtSpace());
+
+#if 1
+  if (t < 0) {
+    // non-power-of-p aux
+    // now the digit extraction is actually interpolation within the lowest
+    // digit
+    digits.resize(1, tmp);
+    std::vector<Ctxt*> ctxt_ptr_vec{&digits[0]};
+    polyEvalNew(ctxt_ptr_vec, context.getExtractPolys(), c);
+  } else {
+    // power-of-p aux
+    // numExtract is either 1 or 2
+    digits.resize(numExtract, tmp);
+    NTL::vec_ZZX firstRowPolys;
+    firstRowPolys.SetLength(1);
+    std::vector<Ctxt*> ctxt_ptr_vec;
+    firstRowPolys[0] = context.getExtractPolys()[0];
+    // compute_magic_poly(firstRowPolys[0], p, eNew);
+    if (numExtract == 1) {
+      ctxt_ptr_vec.push_back(&digits[0]);
+      polyEvalNew(ctxt_ptr_vec, firstRowPolys, c);
+    } else if (numExtract == 2) {
+      NTL::vec_ZZX secondRowPolys;
+      secondRowPolys.SetLength(1);
+      // index 0 -> ext poly; index 1 -> lift poly
+      firstRowPolys.SetLength(2);
+      firstRowPolys[1] = context.getLiftPoly();
+      secondRowPolys[0] = context.getExtractPolys()[1];
+      // buildDigitPolynomial(firstRowPolys[1], p, 2);
+      // compute_magic_poly(secondRowPolys[0], p, eNew - 1);
+
+      // polyEval(tmp, x2p, c);
+      ctxt_ptr_vec.push_back(&digits[0]);
+      ctxt_ptr_vec.push_back(&tmp);
+      polyEvalNew(ctxt_ptr_vec, firstRowPolys, c);
+
+#ifdef HELIB_DEBUG
+      // XXX: debug
+      {
+        long p = context.getP();
+        long p2t = NTL::power_long(p, context.getT());
+        // long p2eNew = NTL::power_long(p, context.getENew());
+        auto ea = context.getRcData().ea;
+        std::vector<NTL::ZZX> c_slots, tmp_slots;
+        ea->decrypt(c, *dbgKey, c_slots);
+        ea->decrypt(tmp, *dbgKey, tmp_slots);
+        long n_slots = c_slots.size();
+        for (long i = 0; i < n_slots; i++) {
+          if (NTL::deg(c_slots[i]) == -1)
+            continue;
+          long c_val = balRem(NTL::rem(c_slots[i][0], p2t), p2t);
+          long tmp_val = balRem(NTL::rem(tmp_slots[i][0], p2t), p2t);
+          if (abs(tmp_val) > p / 2)
+            assertTrue(false, "tmp_val wrong");
+          if ((c_val - tmp_val) % p != 0)
+            assertTrue(false, "mod wrong");
+          if (std::abs((c_val - tmp_val) / p) > 1)
+            assertTrue(false, "high digit wrong");
+        }
+      }
+      // XXX: end debug
+#endif
+
+      // tmp = lift(c)
+      tmp -= c;
+      tmp.negate();
+      tmp.divideByP(); // (c - lift(c)) / p, input to the second row
+
+      ctxt_ptr_vec.clear();
+      ctxt_ptr_vec.push_back(&digits[1]);
+      polyEvalNew(ctxt_ptr_vec, secondRowPolys, tmp);
+
+#ifdef HELIB_DEBUG
+      // XXX: debug
+      {
+        long p = context.getP();
+        long p2t = NTL::power_long(p, context.getT());
+        long p2eNew = NTL::power_long(p, context.getENew());
+        auto ea = context.getRcData().ea;
+        std::vector<NTL::ZZX> c_slots, tmp_slots, d0_slots, d1_slots;
+        ea->decrypt(c, *dbgKey, c_slots);
+        ea->decrypt(tmp, *dbgKey, tmp_slots);
+        ea->decrypt(digits[0], *dbgKey, d0_slots);
+        ea->decrypt(digits[1], *dbgKey, d1_slots);
+        // now check
+        // (1) tmp_slots is indeed the second digit
+        // (2) digits[1] is ok
+        long n_slots = c_slots.size();
+        for (long i = 0; i < n_slots; i++) {
+          if (NTL::deg(c_slots[i]) == -1)
+            continue;
+          long c_val = balRem(NTL::rem(c_slots[i][0], p2t), p2t);
+          long tmp_val, d0_val, d1_val;
+          if (c_val % p != 0) { // check first digit
+            d0_val = balRem(NTL::rem(d0_slots[i][0], p2eNew), p2eNew);
+            if ((c_val - d0_val) % p != 0)
+              assertTrue(false, "d0 wrong");
+            c_val = balRem((c_val - d0_val) / p, p);
+          } else {
+            assertTrue(NTL::deg(d0_slots[i]) == -1, "aaa");
+            c_val /= p;
+          }
+          // check second digit
+          if (c_val != 0) {
+            tmp_val = balRem(NTL::rem(tmp_slots[i][0], p), p);
+            d1_val = balRem(NTL::rem(d1_slots[i][0], p2eNew / p), p2eNew / p);
+            if (c_val != tmp_val)
+              assertTrue(false, "tmp wrong");
+            if (tmp_val != d1_val) {
+              // directly evaluate it
+              NTL::ZZ curMod(p2eNew / p);
+              NTL::ZZ_pPush push(curMod);
+              NTL::ZZX secondExtPoly = context.getExtractPolys()[1];
+              for (long ii = 0; ii <= NTL::deg(secondExtPoly); ii += 2)
+                NTL::SetCoeff(secondExtPoly, ii, 0);
+              secondExtPoly.normalize();
+              auto polyeval = NTL::eval(NTL::conv<NTL::ZZ_pX>(secondExtPoly),
+                                        NTL::conv<NTL::ZZ_p>(tmp_slots[i][0]));
+              long polyeval_val =
+                  balRem(NTL::rem(NTL::conv<NTL::ZZ>(polyeval), p2eNew / p),
+                         p2eNew / p);
+              assertTrue(polyeval_val == tmp_val, "......");
+              assertTrue(false, "d1 wrong");
+            }
+          }
+        }
+      }
+      // XXX: end debug
+#endif
+    } else
+      assertTrue(false, "extracting more than 2 digits is not supported");
+  }
+#else // XXX: only for testing, use the native polynomials
+
+  long p = context.getP();
+  long eNew = context.getENew();
+  if (t > 0) { // ignore the t < 0 case...
+    digits.resize(numExtract, tmp);
+    NTL::vec_ZZX firstRowPolys;
+    firstRowPolys.SetLength(1);
+    std::vector<Ctxt*> ctxt_ptr_vec;
+    compute_magic_poly(firstRowPolys[0], p, eNew);
+    if (numExtract == 1) {
+      ctxt_ptr_vec.push_back(&digits[0]);
+      polyEvalNew(ctxt_ptr_vec, firstRowPolys, c);
+    } else if (numExtract == 2) {
+      NTL::vec_ZZX secondRowPolys;
+      secondRowPolys.SetLength(1);
+      // index 0 -> ext poly; index 1 -> lift poly
+      firstRowPolys.SetLength(2);
+      buildDigitPolynomial(firstRowPolys[1], p, 2);
+      compute_magic_poly(secondRowPolys[0], p, eNew - 1);
+
+      // polyEval(tmp, x2p, c);
+      ctxt_ptr_vec.push_back(&digits[0]);
+      ctxt_ptr_vec.push_back(&tmp);
+      polyEvalNew(ctxt_ptr_vec, firstRowPolys, c);
+      // tmp = lift(c)
+      tmp -= c;
+      tmp.negate();
+      tmp.divideByP(); // (c - lift(c)) / p, input to the second row
+
+      ctxt_ptr_vec.clear();
+      ctxt_ptr_vec.push_back(&digits[1]);
+      polyEvalNew(ctxt_ptr_vec, secondRowPolys, tmp);
+    } else
+      assertTrue(false, "extracting more than 2 digits is not supported");
+  } else
+    assertTrue(false, "not expecting non-power-of-p aux for now");
+#endif
+}
+
+static void reduceOddPoly(NTL::ZZX& poly)
+{
+  long deg = NTL::deg(poly);
+  for (long i = 0; i <= deg; i += 2)
+    NTL::SetCoeff(poly, i, 0);
+  poly.normalize();
+}
+
+void Context::buildBtsPolys()
+{
+  // precompute polynomials for bts
+  if (!newBtsFlag) { // NOTE: tested ok
+    long botHigh = e_param - ePrime_param;
+    long r = getR();
+    long p = getP();
+    long topHigh = botHigh + r - 1;
+
+    bool use_chen_han = false;
+    if (r > 1) {
+      double chen_han_cost = log(p - 1) + log(r);
+      double basic_cost;
+      if (p == 2 && r > 2 && botHigh + r > 2)
+        basic_cost = (r - 1) * log(p);
+      else
+        basic_cost = r * log(p);
+
+      // std::cerr << "*** basic: " << basic_cost << "\n";
+      // std::cerr << "*** chen/han: " << chen_han_cost << "\n";
+
+      double thresh = 1.5;
+      if (p == 2)
+        thresh = 1.75;
+      // increasing thresh makes chen_han less likely to be chosen.
+      // For p == 2, the basic algorithm is just squaring,
+      // and so is a bit cheaper, so we raise thresh a bit.
+      // This is all a bit heuristic.
+
+      if (basic_cost > thresh * chen_han_cost)
+        use_chen_han = true;
+    }
+
+    if (fhe_force_chen_han > 0)
+      use_chen_han = true;
+    else if (fhe_force_chen_han < 0)
+      use_chen_han = false;
+    ch18Flag = use_chen_han;
+#ifdef HELIB_DEBUG
+    std::cerr << "CH18 enabled? " << ch18Flag << '\n';
+#endif
+    // now compute the polynomials
+    if (use_chen_han) {
+      // ee and rr are the arguments of extendExtractDigits
+      long rr = botHigh;
+      long ee = r;
+      debug_ee = ee;
+      debug_rr = rr;
+      if (p > 3)
+        buildDigitPolynomial(liftPoly, p, rr);
+      extractPolys.SetLength(rr);
+      for (long i : range(rr)) {
+        compute_magic_poly(extractPolys[i], p, ee + rr - i);
+      }
+    } else { // HS21
+      if (p == 2 && r > 2 && topHigh + 1 > 2)
+        topHigh--; // For p==2 we sometime get a bit for free
+      long rr = topHigh + 1;
+      debug_rr = rr;
+      // NOTE: we assume ptxtSpace is p2r
+      //  and ignore the effectiveR() stuff
+      if (p > 3)
+        buildDigitPolynomial(liftPoly, p, rr);
+    }
+  } else { // new bts
+    long eNew = eNew_param;
+    long p = getP();
+    long r = getR();
+    long t = getT();
+    long aux = getAux();
+    long bnd = ceil(boundForRecryption());
+
+    if (t < 0) { // non-power-of-p aux
+      extractPolys.SetLength(1);
+      compute_prime_aux_poly(extractPolys[0], p, r, bnd, aux);
+      std::cout << "deg of poly for non-power-of-p aux is " << NTL::deg(extractPolys[0]) << "\n";
+    } else { // power-of-p aux
+      if (numExtract_param == 1) {
+        extractPolys.SetLength(1);
+        compute_magic_poly(extractPolys[0], p, eNew);
+
+        NTL::ZZX null_poly;
+        // when we only need to extract a single digit,
+        //  the null poly is modulo p^eNew
+        compute_null_poly(null_poly, p, eNew, t, bnd, true);
+        std::cout << "degs of poly for the first row and its null poly are " << NTL::deg(extractPolys[0])
+          << " / " << NTL::deg(null_poly) << "\n";
+        if (deg(null_poly) <= deg(extractPolys[0])) {
+          // reduce w.r.t the null poly modulo p2eNew
+          NTL::ZZ p2eNew = NTL::power(NTL::ZZ(p), eNew);
+          NTL::ZZ_pPush push(p2eNew);
+          NTL::ZZ_pX reduced = NTL::conv<NTL::ZZ_pX>(extractPolys[0]);
+          NTL::ZZ_pX null_poly_p = NTL::conv<NTL::ZZ_pX>(null_poly);
+          NTL::rem(reduced, reduced, null_poly_p);
+          extractPolys[0] = NTL::conv<NTL::ZZX>(reduced);
+        }
+        reduceOddPoly(extractPolys[0]);
+      } else if (numExtract_param == 2) {
+        // buildDigitPolynomial(liftPoly, p, 2);
+        compute_magic_poly(liftPoly, p, 2);
+        extractPolys.SetLength(2);
+        compute_magic_poly(extractPolys[0], p, eNew);
+        compute_magic_poly(extractPolys[1], p, eNew - 1);
+
+        NTL::ZZX lift_null_poly;
+        // for the lift poly, null polynomial is computed modulo p^2
+        compute_null_poly(lift_null_poly, p, 2, t, bnd, true);
+        std::cout << "degs of the lift poly and its null poly are " << NTL::deg(liftPoly)
+          << " / " << NTL::deg(lift_null_poly) << "\n";
+        NTL::ZZ p2two = NTL::ZZ(p * p);
+        if (deg(lift_null_poly) <= deg(liftPoly)) {
+          NTL::ZZ_pPush push(p2two);
+          NTL::ZZ_pX reduced = NTL::conv<NTL::ZZ_pX>(liftPoly);
+          NTL::ZZ_pX null_poly_p = NTL::conv<NTL::ZZ_pX>(lift_null_poly);
+          NTL::rem(reduced, reduced, null_poly_p);
+          liftPoly = NTL::conv<NTL::ZZX>(reduced);
+        }
+        reduceOddPoly(liftPoly);
+        PolyRed(liftPoly, p2two, false);
+
+        NTL::ZZX null_polys[2];
+        // for the first-row ext poly, compute null poly modulo p^eNew
+        compute_null_poly(null_polys[0], p, eNew, t, bnd, true);
+        // for the second-row ext poly, compute null poly modulo p^(eNew-1)
+        compute_null_poly(null_polys[1], p, eNew - 1, t - 1, bnd, false);
+        std::cout << "degs of the ext polys and their null polys are " <<
+          NTL::deg(extractPolys[0]) << " / " << NTL::deg(null_polys[0]) << ", " <<
+          NTL::deg(extractPolys[1]) << " / " << NTL::deg(null_polys[1]) << "\n";
+
+        std::vector<long> p_pows = {eNew, eNew - 1};
+        for (long i = 0; i < 2; i++) {
+          if (NTL::deg(null_polys[i]) > NTL::deg(extractPolys[i]))
+            continue;
+          printf("reducing the ext poly for No.%ld row\n", i);
+          NTL::ZZ curMod = NTL::power(NTL::ZZ(p), p_pows[i]);
+          NTL::ZZ_pPush push(curMod);
+          NTL::ZZ_pX reduced = NTL::conv<NTL::ZZ_pX>(extractPolys[i]);
+          NTL::ZZ_pX null_poly_p = NTL::conv<NTL::ZZ_pX>(null_polys[i]);
+          NTL::rem(reduced, reduced, null_poly_p);
+          extractPolys[i] = NTL::conv<NTL::ZZX>(reduced);
+        }
+        reduceOddPoly(extractPolys[0]);
+        reduceOddPoly(extractPolys[1]);
+      } else // extraction more than 2 digits is not supported
+        assertTrue(false, "something wrong");
+    }
+  }
+}
+
 } // namespace helib
diff --git a/src/hypercube.cpp b/src/hypercube.cpp
index d19d12c..c6d8a32 100644
--- a/src/hypercube.cpp
+++ b/src/hypercube.cpp
@@ -17,6 +17,10 @@ namespace helib {
 
 //! Break an index into the hypercube to index of the
 //! dimension-dim subcube and index inside that subcube.
+// NOTE: `idx` can be treated as a mixed radix integer a_0,a_1,...,a_{n-1}, where the radix of a_i is L_i
+// this function returns
+// 1. a_0,...a_{dim-1},a_{dim+1},...,a_{n-1} as the index of the dim-th hypercolumn
+// 2. a_{dim} as the index inside the dim-th hypercolumn
 std::pair<long, long> CubeSignature::breakIndexByDim(long idx, long dim) const
 {
   std::pair<long, long> ans;
diff --git a/src/keySwitching.cpp b/src/keySwitching.cpp
index d2604f0..a7bfa57 100644
--- a/src/keySwitching.cpp
+++ b/src/keySwitching.cpp
@@ -34,14 +34,16 @@ namespace helib {
 
 KeySwitch::KeySwitch(long sPow, long xPow, long fromID, long toID, long p) :
     fromKey(sPow, xPow, fromID), toKeyID(toID), ptxtSpace(p)
-{}
+{
+}
 
 KeySwitch::KeySwitch(const SKHandle& _fromKey,
                      UNUSED long fromID,
                      long toID,
                      long p) :
     fromKey(_fromKey), toKeyID(toID), ptxtSpace(p)
-{}
+{
+}
 
 bool KeySwitch::operator==(const KeySwitch& other) const
 {
@@ -294,9 +296,17 @@ void KeySwitch::readJSON(const JsonWrapper& jw, const Context& context)
   this->noiseBound = j.at("noiseBound").get<NTL::xdouble>();
 }
 
+#define PO2_GIANT_STEP
+
 long KSGiantStepSize(long D)
 {
   assertTrue<InvalidArgument>(D > 0l, "Step size must be positive");
+#ifdef PO2_GIANT_STEP
+  if (is2power(D)) {
+    // for power of 2 dimension
+    return 1L << ((NTL::NumTwos(NTL::ZZ(D)) + 1) / 2);
+  }
+#endif
   long g = NTL::SqrRoot(D);
   if (g * g < D)
     g++; // g = ceiling(sqrt(D))
@@ -577,10 +587,17 @@ void addSome1DMatrices(SecKey& sKey, long bound, long keyID)
   // key-switching matrices for the automorphisms
   for (long i : range(context.getZMStar().numOfGens())) {
     // For generators of small order, add all the powers
-    if (bound >= context.getZMStar().OrderOf(i))
+    if (bound >= context.getZMStar().OrderOf(i)) {
       add1Dmats4dim(sKey, i, keyID);
-    else // For generators of large order, add only some of the powers
+      printf("Dim %ld has size %ld, using KSS_FULL\n",
+             i,
+             context.getZMStar().OrderOf(i));
+    } else { // For generators of large order, add only some of the powers
       addSome1Dmats4dim(sKey, i, bound, keyID);
+      printf("Dim %ld has size %ld, using KSS_BSGS\n",
+             i,
+             context.getZMStar().OrderOf(i));
+    }
   }
   sKey.setKeySwitchMap(); // re-compute the key-switching map
 }
diff --git a/src/keys.cpp b/src/keys.cpp
index 59c24f1..4f5241c 100644
--- a/src/keys.cpp
+++ b/src/keys.cpp
@@ -9,12 +9,12 @@
  * See the License for the specific language governing permissions and
  * limitations under the License. See accompanying LICENSE file.
  */
- 
+
 /* Copyright (C) 2022 Intel Corporation
-* SPDX-License-Identifier: Apache-2.0
-*
-* Added functionallity for separating the SK, PK, and key switching matrices.
-*/
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Added functionallity for separating the SK, PK, and key switching matrices.
+ */
 
 #include <queue>
 
@@ -1156,11 +1156,15 @@ long SecKey::GenSecKey(long ptxtSpace, long maxDegKswitch)
 
 // Generate a key-switching matrix and store it in the public key.
 // The argument p denotes the plaintext space
+// NOTE: toNewBootKey == true means:
+// (1) newKSFlag is true
+// (2) toIdx represents a bts key
 void SecKey::GenKeySWmatrix(long fromSPower,
                             long fromXPower,
                             long fromIdx,
                             long toIdx,
-                            long p)
+                            long p,
+                            bool toNewBootKey)
 {
   HELIB_TIMER_START;
 
@@ -1174,8 +1178,24 @@ void SecKey::GenKeySWmatrix(long fromSPower,
   if (haveKeySWmatrix(fromSPower, fromXPower, fromIdx, toIdx))
     return; // nothing to do here
 
-  DoubleCRT fromKey = sKeys.at(fromIdx);    // copy object, not a reference
+  DoubleCRT fromKey = sKeys.at(fromIdx); // copy object, not a reference
+  IndexSet newSpecialPrimes, newCtxtPrimes;
+  if (toNewBootKey) {
+    newSpecialPrimes.insert(context.getIndexR());
+    newCtxtPrimes.insert(context.getIndexQks());
+    // represent the key under the BTS primes
+  } else {
+    newSpecialPrimes = context.getSpecialPrimes();
+    newCtxtPrimes = context.getCtxtPrimes();
+  }
   const DoubleCRT& toKey = sKeys.at(toIdx); // this can be a reference
+  // when toKey or fromKey is equal to the encapsulated BTS key
+  // this is needed to make their primeSets match
+  assertTrue(
+      fromKey.getIndexSet() == toKey.getIndexSet() ||
+          (context.getNewKSFlag() && (toNewBootKey || fromIdx == recryptKeyID)),
+      "something wrong with GenKSMatrix");
+  fromKey.setPrimes(toKey.getIndexSet());
 
   if (fromXPower > 1)
     fromKey.automorph(fromXPower); // compute s(X^t)
@@ -1188,17 +1208,12 @@ void SecKey::GenKeySWmatrix(long fromSPower,
   KeySwitch ksMatrix(fromSPower, fromXPower, fromIdx, toIdx);
   RandomBits(ksMatrix.prgSeed, 256); // a random 256-bit seed
 
-  long n = context.getDigits().size();
-
+  long n = toNewBootKey ? context.getBtsDigits() : context.getDigits().size();
   // size-n vector
-  ksMatrix.b.resize(
-      n,
-      DoubleCRT(context, context.getCtxtPrimes() | context.getSpecialPrimes()));
+  ksMatrix.b.resize(n, DoubleCRT(context, newCtxtPrimes | newSpecialPrimes));
 
   std::vector<DoubleCRT> a;
-  a.resize(
-      n,
-      DoubleCRT(context, context.getCtxtPrimes() | context.getSpecialPrimes()));
+  a.resize(n, DoubleCRT(context, newCtxtPrimes | newSpecialPrimes));
 
   {
     RandomState state;
@@ -1231,14 +1246,18 @@ void SecKey::GenKeySWmatrix(long fromSPower,
 
   // generate the RLWE instances with pseudorandom ai's
 
+  // the noiseBound is only an estimation, thus the same for all i's
   for (long i = 0; i < n; i++) {
     ksMatrix.noiseBound = RLWE1(ksMatrix.b[i], a[i], toKey, p);
   }
   // Add in the multiples of the fromKey secret key
-  fromKey *= context.productOfPrimes(context.getSpecialPrimes());
+  fromKey *= context.productOfPrimes(newSpecialPrimes);
   for (long i = 0; i < n; i++) {
     ksMatrix.b[i] += fromKey;
-    fromKey *= context.productOfPrimes(context.getDigit(i));
+    if (toNewBootKey)
+      fromKey *= context.getBtsBaseKS();
+    else
+      fromKey *= context.productOfPrimes(context.getDigit(i));
   }
 
   // Push the new matrix onto our list
@@ -1684,32 +1703,57 @@ long SecKey::genRecryptData()
   assertTrue(context.isBootstrappable(),
              "Cannot generate recrypt data for non-bootstrappable context");
 
-  long p2ePr = context.getRcData().alMod->getPPowR(); // p^{e-e'+r}
-  long p2r = context.getAlMod().getPPowR();           // p^r
+  long p2ePr =
+      context.getRcData()
+          .alMod->getPPowR(); // p^{e-e'+r} = if !newBtsFlag else p^eNew
+  long p2r = context.getAlMod().getPPowR(); // p^r
 
   // Generate a new bootstrapping key
   zzX keyPoly;
-  long hwt = context.getRcData().skHwt;
+  long hwt =
+      context.getRcData()
+          .skHwt; // NOTE: skHwt in rcData is initialized to the encapSkHwt
+  std::cout << "Sparse boot key hwt = " << hwt << "\n";
   double bound = sampleHWtBounded(keyPoly, context, hwt);
 
-  DoubleCRT newSk(keyPoly,
-                  context,
-                  context.getCtxtPrimes() | context.getSpecialPrimes());
+  bool newBtsFlag = context.getNewBTSFlag();
+  bool newKSFlag = context.getNewKSFlag();
+  IndexSet skPrimes;
+  if (newKSFlag) {
+    skPrimes.insert(context.getIndexQks());
+    skPrimes.insert(context.getIndexR());
+  } else {
+    skPrimes = context.getCtxtPrimes() | context.getSpecialPrimes();
+  }
+  DoubleCRT newSk(keyPoly, context, skPrimes);
   // defined relative to all primes
 
   long keyID = ImportSecKey(newSk, bound, p2r, /*maxDegKswitch=*/1);
+  recryptKeyID = keyID;
 
   // Generate a key-switching matrix from key 0 to this key
-  GenKeySWmatrix(/*fromSPower=*/1,
-                 /*fromXPower=*/1,
-                 /*fromIdx=*/0,
-                 /*toIdx=*/keyID,
-                 /*ptxtSpace=*/p2r);
-
+  // > procedure for new bts is added
+  GenKeySWmatrix(
+      /*fromSPower=*/1,
+      /*fromXPower=*/1,
+      /*fromIdx=*/0,
+      /*toIdx=*/keyID,
+      /*ptxtSpace=*/p2r,
+      /*toBootKey=*/newKSFlag); // NOTE: SecKey do not have access to
+                                // recryptKeyID, so we have to tell it here
+  // no need to KS from encapKey to the normalKey for native BTS
+  if (newBtsFlag) // generate encapKey => normalKey KS matrix
+    GenKeySWmatrix(1, 1, keyID, 0, p2ePr, false);
+
+  // NOTE: actually we can generate an RLWE' encryption of the encapKey
   // Encrypt new key under key #0 and plaintext space p^{e+r}
-  Encrypt(recryptEkey, keyPoly, p2ePr);
+  Encrypt(recryptEkey,
+          keyPoly,
+          p2ePr); // this key is for bootstrapping (the homomorphic a*s+b before
+                  // linear transformation)
+                  // this encryption contains all the prime, and that is ok
 
-  return (recryptKeyID = keyID); // return the new key-ID
+  return keyID; // return the new key-ID
 }
 
 std::ostream& operator<<(std::ostream& str, const SecKey& sk)
diff --git a/src/matmul.cpp b/src/matmul.cpp
index 06eef33..6a84bee 100644
--- a/src/matmul.cpp
+++ b/src/matmul.cpp
@@ -12,6 +12,7 @@
 #include <cstddef>
 #include <tuple>
 #include <algorithm>
+#include <numeric>
 #include <NTL/BasicThreadPool.h>
 #include <helib/matmul.h>
 #include <helib/norms.h>
@@ -231,7 +232,8 @@ public:
                               long _dim,
                               const EncryptedArray& ea) :
       precon(_ctxt), dim(_dim), zMStar(ea.getPAlgebra())
-  {}
+  {
+  }
 
   std::shared_ptr<Ctxt> automorph(long i) const override
   {
@@ -250,35 +252,102 @@ private:
   long h;
   std::vector<std::shared_ptr<BasicAutomorphPrecon>> precon;
 
+  const std::set<long> giantIndices;
+  const std::set<long> babyIndices;
+  bool isSwap = false;
+
 public:
-  GeneralAutomorphPrecon_BSGS(const Ctxt& _ctxt,
-                              long _dim,
-                              const EncryptedArray& ea) :
-      dim(_dim), zMStar(ea.getPAlgebra())
+  GeneralAutomorphPrecon_BSGS(
+      const Ctxt& _ctxt,
+      long _dim,
+      const EncryptedArray& ea,
+      /* every automorphism index `i` is divisible by `g` */
+      const std::vector<long>& _giantIndices = {},
+      /* the giant step indices (set of `k`) */
+      const std::vector<long>& _babyIndices = {}
+      ) :
+      dim(_dim),
+      zMStar(ea.getPAlgebra()),
+      giantIndices(_giantIndices.begin(), _giantIndices.end()),
+      babyIndices(_babyIndices.begin(), _babyIndices.end())
   {
     D = (dim == -1) ? zMStar.getOrdP() : zMStar.OrderOf(dim);
     g = KSGiantStepSize(D);
     h = divc(D, g);
 
-    BasicAutomorphPrecon precon0(_ctxt);
+    // BasicAutomorphPrecon precon0(_ctxt);
     precon.resize(h);
 
-    // parallel for k in [0..h)
-    NTL_EXEC_RANGE(h, first, last)
-    for (long k = first; k < last; k++) {
-      std::shared_ptr<Ctxt> p = precon0.automorph(zMStar.genToPow(dim, g * k));
-      precon[k] = std::make_shared<BasicAutomorphPrecon>(*p);
+    // NOTE: we need to make the following computation a lazy one to exploit the
+    // sparsity of evaluated polynomials
+    //  i.e., precon[k] is computed only when needed
+    //  however, this will break the multithreading safety of `automorph`
+    //  so we choose to move the laziness to the constructor
+
+    // NOTE: precon[0] can be assigned as precon0 to save some computation
+    precon[0] = std::make_shared<BasicAutomorphPrecon>(_ctxt);
+
+    assertTrue(giantIndices.empty() == babyIndices.empty(), "some debug");
+    if (giantIndices.empty() || babyIndices.empty()) {
+      // parallel for k in [0..h)
+      NTL_EXEC_RANGE(h, first, last)
+      for (long k = first + 1; k < last; k++) { // skip 0
+        std::shared_ptr<Ctxt> p =
+            precon[0]->automorph(zMStar.genToPow(dim, g * k));
+        precon[k] = std::make_shared<BasicAutomorphPrecon>(*p);
+      }
+      NTL_EXEC_RANGE_END
+    } else {
+      // no need to swap
+      if (giantIndices.size() <= babyIndices.size()) {
+        isSwap = false;
+        // parallel for k in [0..giantIndices.size())
+        NTL_EXEC_RANGE(giantIndices.size(), first, last)
+        for (long k = first; k < last; k++) {
+          long kk = mcMod(_giantIndices[k], h);
+          if (kk != 0 && !precon[kk]) {
+            std::shared_ptr<Ctxt> p =
+                precon[0]->automorph(zMStar.genToPow(dim, g * kk));
+            precon[kk] = std::make_shared<BasicAutomorphPrecon>(*p);
+          }
+        }
+        NTL_EXEC_RANGE_END
+      } else {
+        isSwap = true;
+        // parallel for k in [0..babyIndices.size()]
+        precon.resize(g);
+        NTL_EXEC_RANGE(_babyIndices.size(), first, last)
+        for (long j = first; j < last; j++) {
+          long jj = mcMod(_babyIndices[j], g);
+          if (jj != 0 && !precon[jj]) {
+            std::shared_ptr<Ctxt> p = 
+                precon[0]->automorph(zMStar.genToPow(dim, jj));
+            precon[jj] = std::make_shared<BasicAutomorphPrecon>(*p);
+          }
+        }
+        NTL_EXEC_RANGE_END
+      }
     }
-    NTL_EXEC_RANGE_END
   }
 
+  // NOTE: we need to add an extra method to access precon[0] (or precon[i]?) to
+  // enable automorphism in other dimensions (e.g., frobenius) the `const`
+  // modifier is removed for lazy computation
   std::shared_ptr<Ctxt> automorph(long i) const override
   {
     assertInRange(i, 0l, D, "Automorphism index i is not in [0, D)");
     long j = i % g;
     long k = i / g;
     // i == j + g*k
-    return precon[k]->automorph(zMStar.genToPow(dim, j));
+    if (!isSwap) {
+      assertTrue(giantIndices.empty() || giantIndices.count(k),
+                "Aut: Giant step index k out of provided indices");
+      return precon[k]->automorph(zMStar.genToPow(dim, j));
+    } else {
+      assertTrue(babyIndices.empty() || babyIndices.count(j),
+        "Aut: Baby step index j out of provided indices");
+      return precon[j]->automorph(zMStar.genToPow(dim, g * k));
+    }
   }
 };
 
@@ -333,7 +402,8 @@ struct ConstMultiplier_DoubleCRT : ConstMultiplier
 
   ConstMultiplier_DoubleCRT(const DoubleCRT& _data, double _sz) :
       data(_data), sz(_sz)
-  {}
+  {
+  }
 
   void mul(Ctxt& ctxt) const override { ctxt.multByConstant(data, sz); }
 
@@ -579,6 +649,22 @@ struct MatMul1D_derived_impl
   }
 };
 
+template <typename type>
+const std::vector<long>& MatMul1D_partial<type>::nonzeroDiagnoals() const
+{
+  return _vec;
+}
+
+template <typename type>
+int MatMul1D_partial<type>::multiDimInfo() const {
+  return 0;
+}
+
+template <typename type>
+const NTL::Mat<typename type::RX>& MatMul1D_partial<type>::getPo2MultiDimMat() const {
+  return _mat;
+}
+
 template <typename type>
 void MatMul1D_derived<type>::processDiagonal(
     RX& poly,
@@ -608,51 +694,176 @@ struct MatMul1DExec_construct
 
   static void apply(const EncryptedArrayDerived<type>& ea,
                     const MatMul1D& mat_basetype,
-                    std::vector<std::shared_ptr<ConstMultiplier>>& vec,
-                    std::vector<std::shared_ptr<ConstMultiplier>>& vec1,
-                    long g)
+                    MatMul1DExec& mat_exec
+                    // std::vector<std::shared_ptr<ConstMultiplier>>& vec,
+                    // std::vector<std::shared_ptr<ConstMultiplier>>& vec1,
+                    // long g
+  )
   {
+    std::vector<std::shared_ptr<ConstMultiplier>> &vec =
+        mat_exec.cache.multiplier, &vec1 = mat_exec.cache1.multiplier,
+        &vecX = mat_exec.cacheX.multiplier, &vecX1 = mat_exec.cacheX1.multiplier;
+    long g = mat_exec.g;
     const MatMul1D_partial<type>& mat =
         dynamic_cast<const MatMul1D_partial<type>&>(mat_basetype);
+    mat_exec.multiDim = mat.multiDimInfo() != 0;
 
     long dim = mat.getDim();
     long D = dimSz(ea, dim);
-    bool native = dimNative(ea, dim);
+    bool native = mat_exec.dummy || dimNative(ea, dim);
+
+    // init diag-related variables in MatMul1DExec
+    mat_exec.diag_indices.assign(mat.nonzeroDiagnoals().begin(),
+                                 mat.nonzeroDiagnoals().end());
+    if (mat_exec.diag_indices.empty()) {
+      // fill `diag_indices` with [0..D-1]
+      mat_exec.diag_indices.resize(D);
+      std::iota(mat_exec.diag_indices.begin(), mat_exec.diag_indices.end(), 0);
+    }
+    for (long& diag_idx : mat_exec.diag_indices)
+      diag_idx = mcMod(diag_idx, D); // reduce into [0..D)
+    std::sort(mat_exec.diag_indices.begin(), mat_exec.diag_indices.end());
+    if (g) {
+      // mat_exec.giant_step_divides_gap = true;
+      std::set<long> giant_step_indices_set;
+      std::set<long> baby_indices_set;
+      for (long diag_index : mat_exec.diag_indices) {
+        // if ((diag_index % g) != 0)
+        //   mat_exec.giant_step_divides_gap = false;
+        long giant_idx = diag_index / g;
+        if (giant_step_indices_set.insert(giant_idx).second)
+          mat_exec.giant_step_indices.push_back(giant_idx);
+        long baby_idx = diag_index % g;
+        if (baby_indices_set.insert(baby_idx).second)
+          mat_exec.baby_indices.push_back(baby_idx);
+      }
+    }
+
+    // if baby & giant is swapped: k'(j+gk)=rho^{-j}k(j+gk)
+    // this is only valid when g > 0
+    mat_exec.swap_baby_giant = mat_exec.giant_step_indices.size() >
+      mat_exec.baby_indices.size();
+    bool swap_baby_giant = mat_exec.swap_baby_giant;
 
     RBak bak;
     bak.save();
     ea.getTab().restoreContext();
 
+    const auto &multiDimMat = mat.getPo2MultiDimMat();
+    std::vector<RX> slots;
+    // RX u, v, psi_v, cyclo;
+    RX u, v, cyclo;
+    cyclo = NTL::conv<RX>(ea.getPAlgebra().getPhimX());
+    if(mat.multiDimInfo()){
+      assertTrue(dim == 1 && ea.getContext().getNSlots() == 2*D, 
+            "sancheck failed when constructing multi-dim matmul1d");
+      slots.resize(2*D);
+      for(long i = 0; i < D; i++) {
+        slots[i] = multiDimMat[0][0];
+        slots[i+D] = multiDimMat[1][1];
+      }
+      ea.encode(u, slots);
+      for(long i = 0; i < D; i++) {
+        slots[i] = multiDimMat[0][1];
+        slots[i+D] = multiDimMat[1][0];
+      }
+      ea.encode(v, slots);
+      // plaintextAutomorph(psi_v, v, 0, 1, ea);
+
+      vecX.resize(D);
+      if (!native)
+        vecX1.resize(D);
+    }
     if (native) {
 
       vec.resize(D);
 
-      for (long i : range(D)) {
+      for (long i : mat_exec.diag_indices) {
         // i == j + g * k (where j = (g != 0) ? i % g : i)
-        long k;
+        long k, j;
 
         if (g) {
           k = i / g;
+          j = i % g;
         } else {
-          k = 1;
+          k = 1; // g = 0 in case, so g*k = 0 regardless of k
+          j = 0;
         }
 
         RX poly;
         mat.processDiagonal(poly, i, ea);
-        vec[i] = build_ConstMultiplier(poly, dim, -g * k, ea);
+        if(mat.multiDimInfo() == 0){
+          vec[i] = build_ConstMultiplier(poly, dim, swap_baby_giant ? (-j) : (-g*k), ea);
+          continue;
+        }
+        if(NTL::IsZero(poly))
+          continue;
+        // NOTE: multi-dim transform
+        /**                  | a b |      | a   |      | b   |
+         * Let multiDimMat = | c d |, u = |   d |, v = |   c |
+         *                                 | A0    |
+         * we have computed k(i)'s for A = |    A1 |
+         * # CASE 1 (IFFT)
+         *                   | A0    |   | a b |   | a*A0 b*A0 |
+         * for IFFT, we want |    A1 | * | c d | = | c*A1 d*A1 |
+         *   | a*A0      |   |      b*A0 |
+         * = |      d*A1 | + | c*A1      |
+         *       |xxx|                           | b*A0      |
+         * x^T * |xxx| = x^T * A * u + psi(x^T * |      c*A1 |)
+         * = x^T * A * u + psi(x^T * A * v)
+         * = sum_i(u*k(i) * rho^i(x)) + sum_i(psi(v*k(i)) * rho^i(psi(x)))  # psi(v) style
+         * = sum_i(u*k(i) * rho^i(x)) + psi(sum_i(v*k(i) * rho^i(x)))       # outer-psi style
+         * # CASE 2 (FFT)
+         *                  | a b |   | A0    |   | a*A0 b*A1 |
+         * for FFT, we want | c d | * |    A1 | = | c*A0 d*A1 |
+         *   | a*A0      |   |      b*A1 |
+         * = |      d*A1 | + | c*A0      |
+         *       |xxx|                            | c*A0      |
+         * x^T * |xxx| = x^T * A * u + psi(x^T) * |      b*A1 |
+         * = x^T * A * u + psi(x^T) * A * psi(v)
+         * = sum_i(u*k(i) * rho^i(x)) + sum_i(psi(v)*k(i) * rho^i(psi(x)))  # psi(v) style
+         * = sum_i(u*k(i) * rho^i(x)) + psi(sum_i(v*psi(k(i)) * rho^i(x)))  # outer-psi style
+         * 
+         * BSGS for native dimension uses
+         *  k'(j+gk) = rho^{-gk}(k(j+gk))
+         * if baby & giant are swapped:
+         *  k'(j+gk) = rho^{-j}(k(j+gk))
+        */
+        if(mat.multiDimInfo() == 1) { // IFFT
+          vec[i] = build_ConstMultiplier(NTL::MulMod(poly, u, cyclo), dim, 
+            swap_baby_giant ? (-j) : (-g*k), ea);
+          // RX poly1; // poly1 = psi(v*k(i))
+          // plaintextAutomorph(poly1, NTL::MulMod(poly, v, cyclo), 0, 1, ea);
+          // vecX[i] = build_ConstMultiplier(poly1, dim, -g*k, ea);
+          // outer-psi style
+          vecX[i] = build_ConstMultiplier(NTL::MulMod(poly, v, cyclo), dim,
+            swap_baby_giant ? (-j) : (-g*k), ea);
+        } else { // FFT
+          // non-BSGS case (g=0) is also included
+          vec[i] = build_ConstMultiplier(NTL::MulMod(poly, u, cyclo), dim, 
+            swap_baby_giant ? (-j) : (-g*k), ea);
+          // vecX[i] = build_ConstMultiplier(NTL::MulMod(poly, psi_v, cyclo), dim, -g*k, ea);
+          // outer-psi style
+          RX poly1; // poly1 = psi(k(i))
+          plaintextAutomorph(poly1, poly, 0, 1, ea);
+          vecX[i] = build_ConstMultiplier(NTL::MulMod(poly1, v, cyclo), dim, 
+            swap_baby_giant ? (-j) : (-g*k), ea);
+        }
       }
-    } else {
+    } else { // non-native
       vec.resize(D);
       vec1.resize(D);
 
-      for (long i : range(D)) {
+      for (long i : mat_exec.diag_indices) {
         // i == j + g * k (where j = (g != 0) ? i % g : i)
-        long k;
+        long k, j;
 
         if (g) {
           k = i / g;
+          j = i % g;
         } else {
           k = 1;
+          j = 0;
         }
 
         RX poly;
@@ -674,16 +885,74 @@ struct MatMul1DExec_construct
         // poly1 = poly w/ first i slots zeroed out
         // poly2 = poly w/ last D-i slots zeroed out
 
-        vec[i] = build_ConstMultiplier(poly1, dim, -g * k, ea);
+        if(mat.multiDimInfo() == 0){
+          vec[i] = build_ConstMultiplier(poly1, dim, swap_baby_giant ? (-j) : (-g*k), ea);
 
 #if (ALT_MATMUL)
-        long DD = D;
-        if (g)
-          DD = 0;
-        vec1[i] = build_ConstMultiplier(poly2, dim, DD - g * k, ea);
+          long DD = D;
+          if (g)
+            DD = 0;
+          vec1[i] = build_ConstMultiplier(poly2, dim, DD + (swap_baby_giant ? (-j) : (-g*k)), ea);
 #else
-        vec1[i] = build_ConstMultiplier(poly2, dim, D - g * k, ea);
+          vec1[i] = build_ConstMultiplier(poly2, dim, D - g * k, ea); // unreachable case
 #endif
+          continue;
+        }
+        if(NTL::IsZero(poly))
+          continue;
+        // we use ALT_MATMUL by default
+        static_assert(ALT_MATMUL, "ALT_MATMUL is required for multi-dim map");
+        long DD = 0;
+        if (g)
+          DD = 0;
+        /** NOTE: multi-dim transform
+         * # CASE 1 (IFFT)
+         *   sum_i(u*k(i) * rho^i(x)) + sum_i(psi(v*k(i)) * rho^i(psi(x)))
+         * = sum_i(u*k(i) * rho^i(x)) + psi(sum_i(v*k(i) * rho^i(x)))
+         * # CASE 2 (FFT)
+         *   sum_i(u*k(i) * rho^i(x)) + sum_i(psi(v)*k(i) * rho^i(psi(x)))
+         * = sum_i(u*k(i) * rho^i(x)) + psi(sum_i(v*psi(k(i)) * rho^i(x)))
+         * BSGS for non-native dim uses
+         *  k'(j+gk)=theta^{-gk}(mu(j+gk)*k(j+gk))
+         *  k''(j+gk)=theta^{DD-gk}(mu'(j+gk)*k(j+gk))
+         * or if giant & baby are swapped:
+         *  k'(j+gk)=theta^{-j}(mu(j+gk)*k(j+gk))
+         *  k''(j+gk)=theta^{DD-j}(mu'(j+gk)*k(j+gk))
+         * also note that psi(mu) = mu and psi(mu') = psi(mu')
+        */
+        if(mat.multiDimInfo() == 1) { // IFFT
+          vec[i] = build_ConstMultiplier(NTL::MulMod(poly1, u, cyclo), dim, 
+            swap_baby_giant ? (-j) : (-g*k), ea);
+          vec1[i] = build_ConstMultiplier(NTL::MulMod(poly2, u, cyclo), dim, 
+            DD + (swap_baby_giant ? (-j) : (-g*k)), ea);
+          // RX poly_tmp; // poly_tmp = mu(i)*psi(v*k(i))
+          // plaintextAutomorph(poly_tmp, NTL::MulMod(poly1, v, cyclo), 0, 1, ea);
+          // vecX[i] = build_ConstMultiplier(poly_tmp, dim, -g*k, ea);
+          // // poly_tmp = mu'(i)*psi(v*k(i))
+          // plaintextAutomorph(poly_tmp, NTL::MulMod(poly2, v, cyclo), 0, 1, ea);
+          // vecX1[i] = build_ConstMultiplier(poly_tmp, dim, DD-g*k, ea);
+          // outer-psi
+          vecX[i] = build_ConstMultiplier(NTL::MulMod(poly1, v, cyclo), dim,
+            swap_baby_giant ? (-j) : (-g*k), ea);
+          vecX1[i] = build_ConstMultiplier(NTL::MulMod(poly2, v, cyclo), dim,
+            DD + (swap_baby_giant ? (-j) : (-g*k)), ea);
+        } else { // FFT
+          vec[i] = build_ConstMultiplier(NTL::MulMod(poly1, u, cyclo), dim,
+            swap_baby_giant ? (-j) : (-g*k), ea);
+          vec1[i] = build_ConstMultiplier(NTL::MulMod(poly2, u, cyclo), dim, 
+            DD + (swap_baby_giant ? (-j) : (-g*k)), ea);
+          // vecX[i] = build_ConstMultiplier(NTL::MulMod(poly1, psi_v, cyclo), dim, -g*k, ea);
+          // vecX1[i] = build_ConstMultiplier(NTL::MulMod(poly2, psi_v, cyclo), dim, DD-g*k, ea);
+          // outer-psi
+          RX poly_tmp; // poly_tmp = mu(i)*psi(k(i))
+          plaintextAutomorph(poly_tmp, poly1, 0, 1, ea);
+          vecX[i] = build_ConstMultiplier(NTL::MulMod(poly_tmp, v, cyclo), dim,
+            swap_baby_giant ? (-j) : (-g*k), ea);
+          // poly_tmp = mu'(i)*psi(k(i))
+          plaintextAutomorph(poly_tmp, poly2, 0, 1, ea);
+          vecX1[i] = build_ConstMultiplier(NTL::MulMod(poly_tmp, v, cyclo), dim,
+            DD + (swap_baby_giant ? (-j) : (-g*k)), ea);
+        }
       }
     }
   }
@@ -842,8 +1111,8 @@ static void MatMul1DExec_construct_CKKS(
 //    set to 1 to always use BSGS
 //    set to infty to never use BSGS
 
-MatMul1DExec::MatMul1DExec(const MatMul1D& mat, bool _minimal) :
-    ea(mat.getEA()), minimal(_minimal)
+MatMul1DExec::MatMul1DExec(const MatMul1D& mat, bool _minimal, bool _dummy) :
+    ea(mat.getEA()), minimal(_minimal), dummy(_dummy)
 {
   HELIB_NTIMER_START(MatMul1DExec);
 
@@ -861,7 +1130,7 @@ MatMul1DExec::MatMul1DExec(const MatMul1D& mat, bool _minimal) :
   // if (dim == ea.dimension()) std::cerr << "*** MatMul1DExec: big dim\n";
 
   D = dimSz(ea, dim);
-  native = dimNative(ea, dim);
+  native = dummy || dimNative(ea, dim);
 
   bool bsgs = comp_bsgs(D > HELIB_BSGS_MUL_THRESH ||
                         (minimal && D > HELIB_KEYSWITCH_MIN_THRESH));
@@ -874,10 +1143,11 @@ MatMul1DExec::MatMul1DExec(const MatMul1D& mat, bool _minimal) :
   if (ea.getTag() == PA_cx_tag) {
     MatMul1DExec_construct_CKKS(ea.getCx(), mat, cache.multiplier, g);
   } else {
-    ea.dispatch<MatMul1DExec_construct>(mat,
-                                        cache.multiplier,
-                                        cache1.multiplier,
-                                        g);
+    ea.dispatch<MatMul1DExec_construct>(mat, *this
+                                        // cache.multiplier,
+                                        // cache1.multiplier,
+                                        // g
+    );
   }
 }
 
@@ -924,55 +1194,105 @@ So putting it all together
 
 ***************************************************************************/
 
-void GenBabySteps(std::vector<std::shared_ptr<Ctxt>>& v,
+// baby_list specifies the baby indices to generate
+// it is useful in Po2 BTS where baby_list is sparse
+std::shared_ptr<BasicAutomorphPrecon> GenBabySteps(std::vector<std::shared_ptr<Ctxt>>& v,
                   const Ctxt& ctxt,
                   long dim,
-                  bool clean)
+                  bool clean,
+                  const std::vector<long>& baby_list = {},
+                  bool need_ret = false, // set to true to always return a non-empty precon
+                  long amp_ratio = 1) // for generating giant steps
 {
   long n = v.size();
   assertTrue<InvalidArgument>(n > 0, "Empty vector v");
 
-  if (n == 1) {
+  if (n == 1 || (baby_list.size() == 1 && baby_list[0] == 0)) {
     v[0] = std::make_shared<Ctxt>(ctxt);
     if (clean)
       v[0]->cleanUp();
-    return;
+    return need_ret ? std::make_shared<BasicAutomorphPrecon>(ctxt) : nullptr;
   }
 
   const PAlgebra& zMStar = ctxt.getContext().getZMStar();
 
   // std::cerr << "*** STRATEGY FOR dim " << dim << " = " <<
   // ctxt.getPubKey().getKSStrategy(dim) << "\n";
+  std::shared_ptr<BasicAutomorphPrecon> precon_ptr;
+  if (baby_list.empty()) {
+    if (fhe_test_force_hoist >= 0 &&
+        ctxt.getPubKey().getKSStrategy(dim) != HELIB_KSS_UNKNOWN) {
+      precon_ptr = std::make_shared<BasicAutomorphPrecon>(ctxt);
+      auto &precon = *precon_ptr;
+
+      NTL_EXEC_RANGE(n, first, last)
+      for (long j : range(first, last)) {
+        v[j] = precon.automorph(zMStar.genToPow(dim, j * amp_ratio));
+        if (clean)
+          v[j]->cleanUp();
+      }
+      NTL_EXEC_RANGE_END
+    } else {
+      Ctxt ctxt0(ctxt);
+      ctxt0.cleanUp();
 
-  if (fhe_test_force_hoist >= 0 &&
-      ctxt.getPubKey().getKSStrategy(dim) != HELIB_KSS_UNKNOWN) {
-    BasicAutomorphPrecon precon(ctxt);
-
-    NTL_EXEC_RANGE(n, first, last)
-    for (long j : range(first, last)) {
-      v[j] = precon.automorph(zMStar.genToPow(dim, j));
-      if (clean)
-        v[j]->cleanUp();
+      NTL_EXEC_RANGE(n, first, last)
+      for (long j : range(first, last)) {
+        v[j] = std::make_shared<Ctxt>(ctxt0);
+        v[j]->smartAutomorph(zMStar.genToPow(dim, j * amp_ratio));
+        if (clean)
+          v[j]->cleanUp();
+      }
+      NTL_EXEC_RANGE_END
     }
-    NTL_EXEC_RANGE_END
-  } else {
-    Ctxt ctxt0(ctxt);
-    ctxt0.cleanUp();
-
-    NTL_EXEC_RANGE(n, first, last)
-    for (long j : range(first, last)) {
-      v[j] = std::make_shared<Ctxt>(ctxt0);
-      v[j]->smartAutomorph(zMStar.genToPow(dim, j));
-      if (clean)
-        v[j]->cleanUp();
+  } else { // baby_list nonempty
+    if (fhe_test_force_hoist >= 0 &&
+        ctxt.getPubKey().getKSStrategy(dim) != HELIB_KSS_UNKNOWN) {
+      precon_ptr = std::make_shared<BasicAutomorphPrecon>(ctxt);
+      auto &precon = *precon_ptr;
+
+      NTL_EXEC_RANGE(baby_list.size(), first, last)
+      for (long j : range(first, last)) {
+        v[baby_list[j]] = precon.automorph(zMStar.genToPow(dim, baby_list[j] * amp_ratio));
+        if (clean)
+          v[baby_list[j]]->cleanUp();
+      }
+      NTL_EXEC_RANGE_END
+    } else {
+      // XXX: I don't think this will happen in our test
+      assertTrue(
+          false,
+          "non-hoisting GenBabySteps unimplemented for non-empty babyList");
+
+      Ctxt ctxt0(ctxt);
+      ctxt0.cleanUp();
+
+      NTL_EXEC_RANGE(n, first, last)
+      for (long j : range(first, last)) {
+        v[j] = std::make_shared<Ctxt>(ctxt0);
+        v[j]->smartAutomorph(zMStar.genToPow(dim, j));
+        if (clean)
+          v[j]->cleanUp();
+      }
+      NTL_EXEC_RANGE_END
     }
-    NTL_EXEC_RANGE_END
   }
+  return precon_ptr;
 }
 
 void MatMul1DExec::mul(Ctxt& ctxt) const
 {
   HELIB_NTIMER_START(mul_MatMul1DExec);
+  double start_cap = ctxt.capacity();
+  double start_time = NTL::GetTime();
+
+  std::cout << "baby step indices = ";
+  for(long i : baby_indices)
+    std::cout << i << " ";
+  std::cout << "\ngiant step indices = ";
+  for(long i : giant_step_indices)
+    std::cout << i << " ";
+  std::cout << "\n";
 
   assertEq(&ea.getContext(),
            &ctxt.getContext(),
@@ -986,12 +1306,21 @@ void MatMul1DExec::mul(Ctxt& ctxt) const
   if (ctxt.getPubKey().getKSStrategy(dim) == HELIB_KSS_MIN)
     iterative = true;
 
+  std::printf("In MatMul1D, D = %ld, g = %ld, native = %d, iterative = %d\n",
+              D,
+              g,
+              native,
+              iterative);
+
   if (g != 0) {
     // baby-step / giant-step
 
     if (native) {
 
       if (iterative) {
+        // XXX: I don't want to handle this case
+        //  it seems unlikely to happen
+        assertTrue(false, "iterative case unimplemented in MatMul1D");
 
         std::vector<Ctxt> baby_steps(g, Ctxt(ZeroCtxtLike, ctxt));
         baby_steps[0] = ctxt;
@@ -1019,45 +1348,179 @@ void MatMul1DExec::mul(Ctxt& ctxt) const
 
         ctxt = sum;
 
-      } else {
-
-        long h = divc(D, g);
-        std::vector<std::shared_ptr<Ctxt>> baby_steps(g);
-        GenBabySteps(baby_steps, ctxt, dim, true);
-
-        NTL::PartitionInfo pinfo(h);
-        long cnt = pinfo.NumIntervals();
-
-        std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
-
-        // parallel for loop: k in [0..h)
-        NTL_EXEC_INDEX(cnt, index)
-        long first, last;
-        pinfo.interval(first, last, index);
+      } else { // native, non-iterative
+        if(multiDim) { // NOTE: multi-dim
+          if (!swap_baby_giant) { // regular baby-giant; this should usually be the case
+            std::vector<std::shared_ptr<Ctxt>> baby_steps(g);
+            GenBabySteps( // precon{ctxt}
+              baby_steps, ctxt, dim, true, baby_indices);
+            
+            NTL::PartitionInfo pinfo(giant_step_indices.size());
+            long cnt = pinfo.NumIntervals();
+
+            std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+            std::vector<Ctxt> accX(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+            // parallel for loop: k in [0..giant_step_indices.size())
+            NTL_EXEC_INDEX(cnt, index)
+            long first, last;
+            pinfo.interval(first, last, index);
+
+            for(long _k : range(first, last)) {
+              long k = giant_step_indices[_k];
+              Ctxt acc_inner(ZeroCtxtLike, ctxt);
+              Ctxt acc_innerX(ZeroCtxtLike, ctxt);
+
+              for(long j : baby_indices) {
+                long i = j + g * k;
+                if (i >= D)
+                  break;
+                MulAdd(acc_inner, cache.multiplier[i], *baby_steps[j]);
+                MulAdd(acc_innerX, cacheX.multiplier[i], *baby_steps[j]);
+              }
+
+              if (k > 0){
+                acc_inner.smartAutomorph(zMStar.genToPow(dim, g * k));
+                acc_innerX.smartAutomorph(zMStar.genToPow(dim, g * k));
+              }
+              acc[index] += acc_inner;
+              accX[index] += acc_innerX;
+            }
+            NTL_EXEC_INDEX_END
 
-        for (long k : range(first, last)) {
-          Ctxt acc_inner(ZeroCtxtLike, ctxt);
+            for (long i : range(1, cnt)){
+              acc[0] += acc[i];
+              accX[0] += accX[i];
+            }
+            ctxt = accX[0];
+            ctxt.smartAutomorph(zMStar.genToPow(0, 1));
+            ctxt += acc[0];
+          } else { // swap baby & giant
+            long h = divc(D, g);
+            std::vector<std::shared_ptr<Ctxt>> giant_steps(h);
+            GenBabySteps( // precon{ctxt}
+              giant_steps, ctxt, dim, true, giant_step_indices, false, g);
+            
+            NTL::PartitionInfo pinfo(baby_indices.size());
+            long cnt = pinfo.NumIntervals();
+
+            std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+            std::vector<Ctxt> accX(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+            // parallel for loop: j in [0..baby_indices.size())
+            NTL_EXEC_INDEX(cnt, index)
+            long first, last;
+            pinfo.interval(first, last, index);
+
+            for(long _j : range(first, last)) {
+              long j = baby_indices[_j];
+              Ctxt acc_inner(ZeroCtxtLike, ctxt);
+              Ctxt acc_innerX(ZeroCtxtLike, ctxt);
+
+              for(long k : giant_step_indices) {
+                long i = j + g * k;
+                if (i >= D)
+                  break;
+                MulAdd(acc_inner, cache.multiplier[i], *giant_steps[k]);
+                MulAdd(acc_innerX, cacheX.multiplier[i], *giant_steps[k]);
+              }
+
+              if (j > 0){
+                acc_inner.smartAutomorph(zMStar.genToPow(dim, j));
+                acc_innerX.smartAutomorph(zMStar.genToPow(dim, j));
+              }
+              acc[index] += acc_inner;
+              accX[index] += acc_innerX;
+            }
+            NTL_EXEC_INDEX_END
 
-          for (long j : range(g)) {
-            long i = j + g * k;
-            if (i >= D)
-              break;
-            MulAdd(acc_inner, cache.multiplier[i], *baby_steps[j]);
+            for (long i : range(1, cnt)){
+              acc[0] += acc[i];
+              accX[0] += accX[i];
+            }
+            ctxt = accX[0];
+            ctxt.smartAutomorph(zMStar.genToPow(0, 1));
+            ctxt += acc[0];
           }
-
-          if (k > 0)
-            acc_inner.smartAutomorph(zMStar.genToPow(dim, g * k));
-          acc[index] += acc_inner;
         }
-        NTL_EXEC_INDEX_END
+        else { // non-multidim
+          if (!swap_baby_giant) {
+            // long h = divc(D, g);
+            std::vector<std::shared_ptr<Ctxt>> baby_steps(g);
+            GenBabySteps(baby_steps, ctxt, dim, true, baby_indices);
+
+            NTL::PartitionInfo pinfo(giant_step_indices.size());
+            long cnt = pinfo.NumIntervals();
+
+            std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+            // parallel for loop: k in [0..giant_step_indices.size())
+            NTL_EXEC_INDEX(cnt, index)
+            long first, last;
+            pinfo.interval(first, last, index);
+
+            for (long _k : range(first, last)) {
+              long k = giant_step_indices[_k];
+              Ctxt acc_inner(ZeroCtxtLike, ctxt);
+
+              for (long j : baby_indices) {
+                long i = j + g * k;
+                if (i >= D)
+                  break;
+                MulAdd(acc_inner, cache.multiplier[i], *baby_steps[j]);
+              }
+
+              if (k > 0)
+                acc_inner.smartAutomorph(zMStar.genToPow(dim, g * k));
+              acc[index] += acc_inner;
+            }
+            NTL_EXEC_INDEX_END
+
+            ctxt = acc[0];
+            for (long i : range(1, cnt))
+              ctxt += acc[i];
+          } else { // swap baby & giant
+            long h = divc(D, g);
+            std::vector<std::shared_ptr<Ctxt>> giant_steps(h);
+            GenBabySteps(giant_steps, ctxt, dim, true, giant_step_indices, false, g);
+
+            NTL::PartitionInfo pinfo(baby_indices.size());
+            long cnt = pinfo.NumIntervals();
+
+            std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+            // parallel for loop: j in [0..baby_indices.size())
+            NTL_EXEC_INDEX(cnt, index)
+            long first, last;
+            pinfo.interval(first, last, index);
+
+            for (long _j : range(first, last)) {
+              long j = baby_indices[_j];
+              Ctxt acc_inner(ZeroCtxtLike, ctxt);
+
+              for (long k : giant_step_indices) {
+                long i = j + g * k;
+                if (i >= D)
+                  break;
+                MulAdd(acc_inner, cache.multiplier[i], *giant_steps[k]);
+              }
+
+              if (j > 0)
+                acc_inner.smartAutomorph(zMStar.genToPow(dim, j));
+              acc[index] += acc_inner;
+            }
+            NTL_EXEC_INDEX_END
 
-        ctxt = acc[0];
-        for (long i : range(1, cnt))
-          ctxt += acc[i];
+            ctxt = acc[0];
+            for (long i : range(1, cnt))
+              ctxt += acc[i];
+          }
+        }
       }
-    } else {
-#if (ALT_MATMUL)
-      if (iterative) {
+    } else {           // non-native
+#if (ALT_MATMUL)       // Revised BSGS logic in Section 6.4, enabled by default
+      if (iterative) { // XXX: we skip the iterative case again
+        assertTrue(false, "iterative case unimplemented in MatMul1D");
 
         std::vector<Ctxt> baby_steps(g, Ctxt(ZeroCtxtLike, ctxt));
         baby_steps[0] = ctxt;
@@ -1094,53 +1557,217 @@ void MatMul1DExec::mul(Ctxt& ctxt) const
           }
         }
         ctxt = sum;
-      } else {
-        long h = divc(D, g);
-        std::vector<std::shared_ptr<Ctxt>> baby_steps(g);
-        std::vector<std::shared_ptr<Ctxt>> baby_steps1(g);
+      } else { // non-native, non-iterative, BSGS
+        if (multiDim) { // NOTE: multidim
+          if (!swap_baby_giant) { // regular baby & giant
+            std::vector<std::shared_ptr<Ctxt>> baby_steps(g), baby_steps1(g);
+            
+            // precon(ctxt)
+            auto precon = GenBabySteps(baby_steps, ctxt, dim, false, baby_indices, true);
+            // precon(rho^{-D}(ctxt))
+            GenBabySteps(baby_steps1,
+              *precon->automorph(zMStar.genToPow(dim, -D)), dim, false, baby_indices);
+            
+            NTL::PartitionInfo pinfo(giant_step_indices.size());
+            long cnt = pinfo.NumIntervals();
+
+            std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+            std::vector<Ctxt> accX(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+            // parallel for loop: k in [0..giant_indices.size())
+            NTL_EXEC_INDEX(cnt, index)
+
+            long first, last;
+            pinfo.interval(first, last, index);
+
+            for (long _k : range(first, last)) {
+              long k = giant_step_indices[_k];
+              Ctxt acc_inner(ZeroCtxtLike, ctxt);
+              Ctxt acc_innerX(ZeroCtxtLike, ctxt);
+
+              for(long j : baby_indices) {
+                long i = j + g * k;
+                if (i >= D)
+                  break;
+                MulAdd(acc_inner, cache.multiplier[i], *baby_steps[j]);
+                MulAdd(acc_inner, cache1.multiplier[i], *baby_steps1[j]);
+                MulAdd(acc_innerX, cacheX.multiplier[i], *baby_steps[j]);
+                MulAdd(acc_innerX, cacheX1.multiplier[i], *baby_steps1[j]);
+              }
+
+              if (k > 0) {
+                acc_inner.smartAutomorph(zMStar.genToPow(dim, g * k));
+                acc_innerX.smartAutomorph(zMStar.genToPow(dim, g * k));
+              }
+
+              acc[index] += acc_inner;
+              accX[index] += acc_innerX;
+            }
 
-        GenBabySteps(baby_steps, ctxt, dim, false);
+            NTL_EXEC_INDEX_END
 
-        Ctxt ctxt1(ctxt);
-        ctxt1.smartAutomorph(zMStar.genToPow(dim, -D));
-        GenBabySteps(baby_steps1, ctxt1, dim, false);
+            for (long i : range(1, cnt)){
+              acc[0] += acc[i];
+              accX[0] += accX[i];
+            }
+            ctxt = accX[0];
+            ctxt.smartAutomorph(zMStar.genToPow(0, 1));
+            ctxt += acc[0];
+          } else { // swap baby & giant
+            long h = divc(D, g);
+            std::vector<std::shared_ptr<Ctxt>> giant_steps(h), giant_steps1(h);
+            
+            // precon(ctxt)
+            auto precon = GenBabySteps(giant_steps, ctxt, dim, false, giant_step_indices, true, g);
+            // precon(rho^{-D}(ctxt))
+            GenBabySteps(giant_steps1,
+              *precon->automorph(zMStar.genToPow(dim, -D)), dim, false, giant_step_indices, false, g);
+            
+            NTL::PartitionInfo pinfo(baby_indices.size());
+            long cnt = pinfo.NumIntervals();
+
+            std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+            std::vector<Ctxt> accX(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+            // parallel for loop: j in [0..baby_indices.size())
+            NTL_EXEC_INDEX(cnt, index)
+
+            long first, last;
+            pinfo.interval(first, last, index);
+
+            for (long _j : range(first, last)) {
+              long j = baby_indices[_j];
+              Ctxt acc_inner(ZeroCtxtLike, ctxt);
+              Ctxt acc_innerX(ZeroCtxtLike, ctxt);
+
+              for(long k : giant_step_indices) {
+                long i = j + g * k;
+                if (i >= D)
+                  break;
+                MulAdd(acc_inner, cache.multiplier[i], *giant_steps[k]);
+                MulAdd(acc_inner, cache1.multiplier[i], *giant_steps1[k]);
+                MulAdd(acc_innerX, cacheX.multiplier[i], *giant_steps[k]);
+                MulAdd(acc_innerX, cacheX1.multiplier[i], *giant_steps1[k]);
+              }
+
+              if (j > 0) {
+                acc_inner.smartAutomorph(zMStar.genToPow(dim, j));
+                acc_innerX.smartAutomorph(zMStar.genToPow(dim, j));
+              }
+
+              acc[index] += acc_inner;
+              accX[index] += acc_innerX;
+            }
 
-        NTL::PartitionInfo pinfo(h);
-        long cnt = pinfo.NumIntervals();
+            NTL_EXEC_INDEX_END
 
-        std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+            for (long i : range(1, cnt)){
+              acc[0] += acc[i];
+              accX[0] += accX[i];
+            }
+            ctxt = accX[0];
+            ctxt.smartAutomorph(zMStar.genToPow(0, 1));
+            ctxt += acc[0];
+          }
+        } else { // non-multidim
+          if (!swap_baby_giant) { // regular baby & giant
+            // long h = divc(D, g);
+            std::vector<std::shared_ptr<Ctxt>> baby_steps(g);
+            std::vector<std::shared_ptr<Ctxt>> baby_steps1(g);
 
-        // parallel for loop: k in [0..h)
-        NTL_EXEC_INDEX(cnt, index)
+            auto precon = GenBabySteps(baby_steps, ctxt, dim, false, baby_indices, true);
 
-        long first, last;
-        pinfo.interval(first, last, index);
+            // Ctxt ctxt1(ctxt);
+            // ctxt1.smartAutomorph(zMStar.genToPow(dim, -D));
+            GenBabySteps(baby_steps1, *precon->automorph(zMStar.genToPow(dim, -D)), 
+              dim, false, baby_indices);
 
-        for (long k : range(first, last)) {
-          Ctxt acc_inner(ZeroCtxtLike, ctxt);
+            NTL::PartitionInfo pinfo(giant_step_indices.size());
+            long cnt = pinfo.NumIntervals();
 
-          for (long j : range(g)) {
-            long i = j + g * k;
-            if (i >= D)
-              break;
-            MulAdd(acc_inner, cache.multiplier[i], *baby_steps[j]);
-            MulAdd(acc_inner, cache1.multiplier[i], *baby_steps1[j]);
-          }
+            std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
 
-          if (k > 0) {
-            acc_inner.smartAutomorph(zMStar.genToPow(dim, g * k));
-          }
+            // parallel for loop: k in giant_step_indices
+            NTL_EXEC_INDEX(cnt, index)
 
-          acc[index] += acc_inner;
-        }
+            long first, last;
+            pinfo.interval(first, last, index);
 
-        NTL_EXEC_INDEX_END
+            for (long _k : range(first, last)) {
+              long k = giant_step_indices[_k];
+              Ctxt acc_inner(ZeroCtxtLike, ctxt);
 
-        for (long i : range(1, cnt))
-          acc[0] += acc[i];
-        ctxt = acc[0];
+              for (long j : baby_indices) {
+                long i = j + g * k;
+                if (i >= D)
+                  break;
+                MulAdd(acc_inner, cache.multiplier[i], *baby_steps[j]);
+                MulAdd(acc_inner, cache1.multiplier[i], *baby_steps1[j]);
+              }
+
+              if (k > 0) {
+                acc_inner.smartAutomorph(zMStar.genToPow(dim, g * k));
+              }
+
+              acc[index] += acc_inner;
+            }
+
+            NTL_EXEC_INDEX_END
+
+            for (long i : range(1, cnt))
+              acc[0] += acc[i];
+            ctxt = acc[0];
+          } else { // swap baby & giant
+            long h = divc(D, g);
+            std::vector<std::shared_ptr<Ctxt>> giant_steps(h);
+            std::vector<std::shared_ptr<Ctxt>> giant_steps1(h);
+
+            auto precon = GenBabySteps(giant_steps, ctxt, dim, false, giant_step_indices, true, g);
+
+            // Ctxt ctxt1(ctxt);
+            // ctxt1.smartAutomorph(zMStar.genToPow(dim, -D));
+            GenBabySteps(giant_steps1, *precon->automorph(zMStar.genToPow(dim, -D)),
+              dim, false, giant_step_indices, false, g);
+
+            NTL::PartitionInfo pinfo(baby_indices.size());
+            long cnt = pinfo.NumIntervals();
+
+            std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+            // parallel for loop: j in baby_indices.size()
+            NTL_EXEC_INDEX(cnt, index)
+
+            long first, last;
+            pinfo.interval(first, last, index);
+
+            for (long _j : range(first, last)) {
+              long j = baby_indices[_j];
+              Ctxt acc_inner(ZeroCtxtLike, ctxt);
+
+              for (long k : giant_step_indices) {
+                long i = j + g * k;
+                if (i >= D)
+                  break;
+                MulAdd(acc_inner, cache.multiplier[i], *giant_steps[k]);
+                MulAdd(acc_inner, cache1.multiplier[i], *giant_steps1[k]);
+              }
+
+              if (j > 0) {
+                acc_inner.smartAutomorph(zMStar.genToPow(dim, j));
+              }
+
+              acc[index] += acc_inner;
+            }
+
+            NTL_EXEC_INDEX_END
+
+            for (long i : range(1, cnt))
+              acc[0] += acc[i];
+            ctxt = acc[0];
+          }
+        }
       }
-#else
+#else // Alternative revised BSGS logic in Section 6.5, disabled by default
       if (iterative) {
 
         std::vector<Ctxt> baby_steps(g, Ctxt(ZeroCtxtLike, ctxt));
@@ -1223,22 +1850,100 @@ void MatMul1DExec::mul(Ctxt& ctxt) const
       }
 #endif
     }
-  } else if (!iterative) {
-    if (native) {
+  } /* non-BSGS */ else if (!iterative) {
+    if (multiDim) {
+      BasicAutomorphPrecon v_precon(ctxt); // precon{v}
+      // BasicAutomorphPrecon psiv_precon( // precon{psi(v)}
+        // *v_precon.automorph(zMStar.genToPow(0, 1)));
+      NTL::PartitionInfo pinfo(diag_indices.size());
+      long cnt = pinfo.NumIntervals();
+      if (native) { // native, multidim
+        std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+        std::vector<Ctxt> accX(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+        // parallel for loop: i in [0..diag_indices.size())
+        NTL_EXEC_INDEX(cnt, index)
+        long first, last;
+        pinfo.interval(first, last, index);
+
+        for(long _i : range(first, last)) {
+          long i = diag_indices[_i];
+          if (cache.multiplier[i]) {
+            std::shared_ptr<Ctxt> tmp =
+             v_precon.automorph(zMStar.genToPow(dim, i));
+            DestMulAdd(acc[index], cache.multiplier[i], *tmp);
+          }
+          if (cacheX.multiplier[i]) {
+            std::shared_ptr<Ctxt> tmpX = 
+              v_precon.automorph(zMStar.genToPow(dim, i));
+            DestMulAdd(accX[index], cacheX.multiplier[i], *tmpX);
+          }
+        }
+        NTL_EXEC_RANGE_END
+
+        for (long i : range(1, cnt)) {
+          acc[0] += acc[i];
+          accX[0] += accX[i];
+        }
+        ctxt = accX[0];
+        ctxt.smartAutomorph(zMStar.genToPow(0, 1));
+        ctxt += acc[0];
+      } else { // non-native, multidim
+        std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
+        std::vector<Ctxt> acc1(cnt, Ctxt(ZeroCtxtLike, ctxt));
+        std::vector<Ctxt> accX(cnt, Ctxt(ZeroCtxtLike, ctxt));
+        std::vector<Ctxt> accX1(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+        // parallel for loop: i in [0..diag_indices.size())
+        NTL_EXEC_INDEX(cnt, index)
+        long first, last;
+        pinfo.interval(first, last, index);
+
+        for(long _i : range(first, last)) {
+          long i = diag_indices[_i];
+          if (cache.multiplier[i] || cache1.multiplier[i] || 
+            cacheX.multiplier[i] || cacheX1.multiplier[i]) {
+            auto tmp = v_precon.automorph(zMStar.genToPow(dim, i));
+            MulAdd(acc[index], cache.multiplier[i], *tmp);
+            MulAdd(acc1[index], cache1.multiplier[i], *tmp);
+            MulAdd(accX[index], cacheX.multiplier[i], *tmp);
+            DestMulAdd(accX1[index], cacheX1.multiplier[i], *tmp);
+          }
+        }
+        NTL_EXEC_INDEX_END
+
+        for (long i : range(1, cnt)){
+          acc[0] += acc[i];
+          acc1[0] += acc1[i];
+          accX[0] += accX[i];
+          accX1[0] += accX1[i];
+        }
+
+        acc1[0].smartAutomorph(zMStar.genToPow(dim, -D));
+        accX1[0].smartAutomorph(zMStar.genToPow(dim, -D));
+        acc[0] += acc1[0];
+        accX[0] += accX1[0];
+        ctxt = accX[0];
+        ctxt.smartAutomorph(zMStar.genToPow(0, 1));
+        ctxt += acc[0];
+      }
+    } else /* not multi-dim */ if (native) {
+      // this should always be a non-BSGS precon
       std::shared_ptr<GeneralAutomorphPrecon> precon =
           buildGeneralAutomorphPrecon(ctxt, dim, ea);
 
-      NTL::PartitionInfo pinfo(D);
+      NTL::PartitionInfo pinfo(diag_indices.size());
       long cnt = pinfo.NumIntervals();
 
       std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
 
-      // parallel for loop: i in [0..D)
+      // parallel for loop: i in [0..diag_indices.size())
       NTL_EXEC_INDEX(cnt, index)
       long first, last;
       pinfo.interval(first, last, index);
 
-      for (long i : range(first, last)) {
+      for (long _i : range(first, last)) {
+        long i = diag_indices[_i];
         if (cache.multiplier[i]) {
           std::shared_ptr<Ctxt> tmp = precon->automorph(i);
           DestMulAdd(acc[index], cache.multiplier[i], *tmp);
@@ -1250,22 +1955,23 @@ void MatMul1DExec::mul(Ctxt& ctxt) const
       for (long i : range(1, cnt)) {
         ctxt += acc[i];
       }
-    } else {
+    } else { // non-native
       std::shared_ptr<GeneralAutomorphPrecon> precon =
           buildGeneralAutomorphPrecon(ctxt, dim, ea);
 
-      NTL::PartitionInfo pinfo(D);
+      NTL::PartitionInfo pinfo(diag_indices.size());
       long cnt = pinfo.NumIntervals();
 
       std::vector<Ctxt> acc(cnt, Ctxt(ZeroCtxtLike, ctxt));
       std::vector<Ctxt> acc1(cnt, Ctxt(ZeroCtxtLike, ctxt));
 
-      // parallel for loop: i in [0..D)
+      // parallel for loop: i in [0..diag_indices.size())
       NTL_EXEC_INDEX(cnt, index)
       long first, last;
       pinfo.interval(first, last, index);
 
-      for (long i : range(first, last)) {
+      for (long _i : range(first, last)) {
+        long i = diag_indices[_i];
         if (cache.multiplier[i] || cache1.multiplier[i]) {
           std::shared_ptr<Ctxt> tmp = precon->automorph(i);
           MulAdd(acc[index], cache.multiplier[i], *tmp);
@@ -1283,7 +1989,8 @@ void MatMul1DExec::mul(Ctxt& ctxt) const
       acc[0] += acc1[0];
       ctxt = acc[0];
     }
-  } else /* iterative */ {
+  } else /* iterative */ { // NOTE: we skip the iterative case
+    assertTrue(false, "iterative unimplemented in MatMul1D");
     if (native) {
       Ctxt acc(ZeroCtxtLike, ctxt);
       Ctxt sh_ctxt(ctxt);
@@ -1316,6 +2023,10 @@ void MatMul1DExec::mul(Ctxt& ctxt) const
       ctxt = acc;
     }
   }
+
+  double end_cap = ctxt.capacity();
+  double end_time = NTL::GetTime();
+  printf("MatMul1D, time: %f, cap: %f\n\n", end_time - start_time, start_cap - end_cap);
 }
 
 // ========================== BlockMatMul1D stuff =====================
@@ -1325,6 +2036,44 @@ struct BlockMatMul1D_derived_impl
 {
   PA_INJECT(type)
 
+  
+  // a subfield version of buildLinPolyCoeffs
+  // to avoid override problems
+  static void buildLinPolyCoeffs_subfield(
+      const EncryptedArrayDerived<type>& ea,
+      std::vector<RX>& C,
+      const std::vector<RX>& L) {
+    RBak bak;
+    bak.save();
+    ea.restoreContext(); // the NTL context for mod p^r
+    REBak ebak;
+    ebak.save();
+    ea.restoreContextForG(); // The NTL context for mod G
+  
+    long p = ea.getPAlgebra().getP();
+    long r = ea.getTab().getR();
+
+    NTL::Mat<RE> M1;
+    // subfield = true : build 2 x 2 matrix, basis = (1, X^{d/2})
+    buildLinPolyMatrix(M1, p, true);
+    NTL::Mat<RE> M2;
+    ppInvert(M2, M1, p, r); // invert modulo prime-power p^r
+
+    NTL::Vec<RE> CC, LL;
+    long d = NTL::deg(ea.getG());
+    LL.SetLength(2);
+    NTL::conv(LL[0], L[0]);
+    NTL::conv(LL[1], L[d/2]);
+    NTL::mul(CC, LL, M2);
+    C.resize(d);
+    // rho^0 and rho^1
+    NTL::conv(C[0], CC[0]);
+    NTL::conv(C[1], CC[1]);
+  }
+
+  // NOTE: k(i,j) is multiplied with frob^j(rho^i(v))
+  // it encodes the i-th diagonal with the first slot (on this hypercolumn) 
+  //  encoding the leftmost entry (colID=0)
   // return true if zero
   static bool processDiagonal1(std::vector<RX>& poly,
                                long i,
@@ -1342,6 +2091,8 @@ struct BlockMatMul1D_derived_impl
     mat_R entry(NTL::INIT_SIZE, d, d);
     std::vector<RX> entry1(d);
     std::vector<std::vector<RX>> tmpDiag(D);
+    // NOTE: tmpDiag[j][0..d-1] stores the coeffs of the linearized polynomial 
+    // representing the j-th entry in current diagonal
 
     std::vector<std::vector<RX>> diag(nslots);
 
@@ -1349,7 +2100,9 @@ struct BlockMatMul1D_derived_impl
     for (long j : range(D)) { // process entry j
       bool zEntry =
           mat.get(entry, mcMod(j - i, D), j, 0); // entry [j-i mod D, j]
-      // get(...) returns true if the entry is empty, false otherwise
+      // NOTE: process entries from left to right; the sub-diagonal above
+      // diagonal is indexed as +1; get(...) returns true if the entry is empty,
+      // false otherwise
 
       if (!zEntry && IsZero(entry))
         zEntry = true; // zero is an empty entry too
@@ -1368,9 +2121,16 @@ struct BlockMatMul1D_derived_impl
         // recode entry as a vector of polynomials
         for (long k : range(d))
           conv(entry1[k], entry[k]);
+        // NOTE: entry is a d x d matrix over Zp, the represented Zp-linear
+        // transform is v^T (in power basis) -> v^T * entry, i.e., x^k is mapped
+        // to entry[k,:] = entry[k]
 
         // compute the linearized polynomial coefficients
-        ea.buildLinPolyCoeffs(tmpDiag[j], entry1);
+        // NOTE: we may compute on a degree-2 subfield
+        if (!mat.isSubField())
+          ea.buildLinPolyCoeffs(tmpDiag[j], entry1);
+        else
+          buildLinPolyCoeffs_subfield(ea, tmpDiag[j], entry1);
       }
     }
     if (zDiag)
@@ -1384,7 +2144,12 @@ struct BlockMatMul1D_derived_impl
     if (D == 1)
       diag.assign(nslots, tmpDiag[0]); // dimension of size one
     else {
+      // NOTE: processDiagonal1 applies identical transforms to each hypercolumn
+      // (as needed in the original bootstrap)
+      //  processDiagnomal2 applies different transforms to each hypercolumn
       for (long j : range(nslots))
+        // NOTE: find the index of the j-th slot on this dimension
+        //  the slot should contain the `index`-th coeff of the diagonal
         diag[j] = tmpDiag[ea.coordinate(dim, j)];
       // rearrange the indexes based on the current dimension
     }
@@ -1397,6 +2162,8 @@ struct BlockMatMul1D_derived_impl
       for (long j : range(nslots))
         slots[j] = diag[j][i];
       ea.encode(poly[i], slots);
+      // NOTE: poly[i] is the i-th encoded coefficient for the linearized
+      // polynomial
     }
 
     return false; // a nonzero diagonal
@@ -1490,6 +2257,18 @@ struct BlockMatMul1D_derived_impl
   }
 };
 
+template <typename type>
+const std::vector<long>& BlockMatMul1D_partial<type>::nonzeroDiagnoals() const
+{
+  return _vec;
+}
+
+template <typename type>
+bool BlockMatMul1D_partial<type>::isSubField() const
+{
+  return false;
+}
+
 template <typename type>
 bool BlockMatMul1D_derived<type>::processDiagonal(
     std::vector<RX>& poly,
@@ -1533,40 +2312,79 @@ struct BlockMatMul1DExec_construct
 
   // strategy == +1 : factor \sigma
   // strategy == -1 : factor \rho
-
+  // XXX: the code can be modified for better efficiency in the case of sparse
+  // matrix
+  //  however, it is not necessary
   static void apply(const EncryptedArrayDerived<type>& ea,
                     const BlockMatMul1D& mat_basetype,
-                    std::vector<std::shared_ptr<ConstMultiplier>>& vec,
-                    std::vector<std::shared_ptr<ConstMultiplier>>& vec1,
-                    long strategy)
+                    BlockMatMul1DExec& mat_exec
+                    // std::vector<std::shared_ptr<ConstMultiplier>>& vec,
+                    // std::vector<std::shared_ptr<ConstMultiplier>>& vec1,
+                    // long strategy
+  )
   {
     const BlockMatMul1D_partial<type>& mat =
         dynamic_cast<const BlockMatMul1D_partial<type>&>(mat_basetype);
 
+    std::vector<std::shared_ptr<ConstMultiplier>>& vec =
+        mat_exec.cache.multiplier;
+    std::vector<std::shared_ptr<ConstMultiplier>>& vec1 =
+        mat_exec.cache1.multiplier;
+    long strategy = mat_exec.strategy;
+
     long dim = mat.getDim();
     long D = dimSz(ea, dim);
     long d = ea.getDegree();
     bool native = dimNative(ea, dim);
 
+    // init diag-related variables in BlockMatMul1DExec
+    mat_exec.diag_indices.assign(mat.nonzeroDiagnoals().begin(),
+                                 mat.nonzeroDiagnoals().end());
+    if (mat_exec.diag_indices.empty()) {
+      // fill `diag_indices` with [0..D-1]
+      mat_exec.diag_indices.resize(D);
+      std::iota(mat_exec.diag_indices.begin(), mat_exec.diag_indices.end(), 0);
+    }
+    for (long& diag_idx : mat_exec.diag_indices)
+      diag_idx = mcMod(diag_idx, D); // reduce into [0..D)
+    std::sort(mat_exec.diag_indices.begin(), mat_exec.diag_indices.end());
+    long g = KSGiantStepSize(D);
+    std::set<long> giant_step_indices_set;
+    std::set<long> baby_step_indices_set;
+    for (long diag_index : mat_exec.diag_indices) {
+      long baby_idx = diag_index % g;
+      long giant_idx = diag_index / g;
+      if (giant_step_indices_set.insert(giant_idx).second)
+        mat_exec.giant_step_indices.push_back(giant_idx);
+      if (baby_step_indices_set.insert(baby_idx).second)
+        mat_exec.baby_step_indices.push_back(baby_idx);
+    }
+
     RBak bak;
     bak.save();
     ea.getTab().restoreContext();
 
     std::vector<RX> poly;
+    std::set<long> frob_indices;
 
     switch (strategy) {
-    case +1: // factor \sigma
+    case +1: // factor \sigma, d1 = d
 
       if (native) {
         vec.resize(D * d);
         for (long i : range(D)) {
+          // poly[i] is the (encoded) coeff of sigma^i
           bool zero = mat.processDiagonal(poly, i, ea);
           if (zero) {
             for (long j : range(d))
               vec[i * d + j] = nullptr;
           } else {
             for (long j : range(d)) {
+              // frobenius X^{p^-j}
+              // k'(i,j) = rho^{-j}(k(i,j))
               vec[i * d + j] = build_ConstMultiplier(poly[j], -1, -j, ea);
+              if (vec[i * d + j])
+                frob_indices.insert(j);
             }
           }
         }
@@ -1592,12 +2410,18 @@ struct BlockMatMul1DExec_construct
                      poly[j],
                      mask,
                      F); // poly[j] w/ first i slots zeroed out
+              // k'(i,j) = sigma^{-j}(k(i,j))*mu(i)
               vec[i * d + j] = build_ConstMultiplier(poly1);
 
               sub(poly1,
                   poly[j],
                   poly1); // poly[j] w/ last D-i slots zeroed out
+              // k''(i,j) = theta^D(sigma^{-j}(k(i,j))*(1-mu(j))) =
+              // theta^D(sigma^{-j}(k(i,j)) - k'(i,j))
               vec1[i * d + j] = build_ConstMultiplier(poly1, dim, D, ea);
+
+              if(vec[i * d + j] || vec1[i * d + j])
+                frob_indices.insert(j);
             }
           }
         }
@@ -1615,7 +2439,10 @@ struct BlockMatMul1DExec_construct
               vec[i + j * D] = nullptr;
           } else {
             for (long j : range(d)) {
+              // k'(i,j) = theta^{-i}(k(i,j))
               vec[i + j * D] = build_ConstMultiplier(poly[j], dim, -i, ea);
+              if(vec[i + j * D])
+                frob_indices.insert(j);
             }
           }
         }
@@ -1645,6 +2472,9 @@ struct BlockMatMul1DExec_construct
 
               vec[i + j * D] = build_ConstMultiplier(poly1, dim, -i, ea);
               vec1[i + j * D] = build_ConstMultiplier(poly2, dim, D - i, ea);
+
+              if(vec[i + j * D] || vec1[i + j * D])
+                frob_indices.insert(j);
             }
           }
         }
@@ -1655,6 +2485,14 @@ struct BlockMatMul1DExec_construct
     default:
       throw InvalidArgument("Unknown strategy");
     }
+    // XXX: debug
+    std::cout << "frob indices = ";
+    for(long fid : frob_indices)
+      std::cout << fid << " ";
+    std::cout << "\n";
+    // end debug
+    mat_exec.frob_indices.assign(frob_indices.begin(), frob_indices.end());
+    std::sort(mat_exec.frob_indices.begin(), mat_exec.frob_indices.end());
   }
 };
 
@@ -1683,20 +2521,36 @@ BlockMatMul1DExec::BlockMatMul1DExec(const BlockMatMul1D& mat,
   d = ea.getDegree();
   native = dimNative(ea, dim);
 
+  // TODO: this criteria can be modified for better performance
+  //  do we need to modify this...?
+  //  for our test cases strategy is always +1
   if (D >= d)
     strategy = +1;
   else
     strategy = -1;
 
-  ea.dispatch<BlockMatMul1DExec_construct>(mat,
-                                           cache.multiplier,
-                                           cache1.multiplier,
-                                           strategy);
+  // FIXME: move into the code below
+  // giant_step_divides_gap = false;
+  // giant_step_indices = {};
+  // diag_indices.resize(D);
+  // std::iota(diag_indices.begin(),
+  //           diag_indices.end(),
+  //           0); // fill `diag_indices` with [0..D-1]
+  // build the k(i,j)'s neede by BlockMatMul1D::mul
+  ea.dispatch<BlockMatMul1DExec_construct>(mat, *this
+                                           //  cache.multiplier,
+                                           //  cache1.multiplier,
+                                           //  strategy
+  );
 }
 
+// TODO: the case of sparse frobenius (e.g., Po2 BTS, p=3 mod 4, thin bts)
+//  possible implementation: add frob_indices / discard zero frob coeffs
 void BlockMatMul1DExec::mul(Ctxt& ctxt) const
 {
   HELIB_NTIMER_START(mul_BlockMatMul1DExec);
+  double start_cap = ctxt.capacity();
+  double start_time = NTL::GetTime();
   assertEq(&ea.getContext(),
            &ctxt.getContext(),
            "Cannot multiply ciphertexts with context different to "
@@ -1705,6 +2559,7 @@ void BlockMatMul1DExec::mul(Ctxt& ctxt) const
 
   ctxt.cleanUp();
 
+  // NOTE: it seems this will never happen
   if (strategy == 0) {
     // assumes minimal KS matrices present
 
@@ -1751,18 +2606,24 @@ void BlockMatMul1DExec::mul(Ctxt& ctxt) const
     return;
   }
 
-  long d0, d1;
+  // long d0; // NOTE: d0 will be replaced by n_diags or n_frob
+  long d1;
   long dim0, dim1;
+  long n_diags = diag_indices.size();
+  long n_frob = frob_indices.size();
 
+  // NOTE: dimension of index dim<i> has order d<i>
+  //  dim0 is the dimension to be computed with hoisting or BSGS on the same
+  //  input. strategy = 1 means D>=d, -1 mean D<d
   if (strategy == +1) {
-    d0 = D;
+    // d0 = D;
     dim0 = dim;
     d1 = d;
     dim1 = -1;
   } else {
     d1 = D;
     dim1 = dim;
-    d0 = d;
+    // d0 = d;
     dim0 = -1;
   }
 
@@ -1772,6 +2633,8 @@ void BlockMatMul1DExec::mul(Ctxt& ctxt) const
   if (ctxt.getPubKey().getKSStrategy(dim0) == HELIB_KSS_MIN)
     iterative0 = true;
 
+  // NOTE: iterative1 = false iff (KSS is not MIN) and (KSS is FULL and multiple
+  // threads are available in NTL)
   bool iterative1 = false;
   if (ctxt.getPubKey().getKSStrategy(dim1) == HELIB_KSS_MIN)
     iterative1 = true;
@@ -1779,200 +2642,472 @@ void BlockMatMul1DExec::mul(Ctxt& ctxt) const
       NTL::AvailableThreads() == 1)
     iterative1 = true;
 
-  if (native) {
+  std::cout << "baby step indices = ";
+  for (long _ : baby_step_indices)
+    std::cout << _ << " ";
+  std::cout << "\ngiant step indices = ";
+  for (long _ : giant_step_indices)
+    std::cout << _ << " ";
+  std::cout << "\n";
+
+  printf("In BlockMatMul1DExec, dim = %ld, D = %ld, native = %d, strategy = "
+         "%ld, iter0 = %d, iter1 = %d\n",
+         dim,
+         D,
+         native,
+         strategy,
+         iterative0,
+         iterative1);
+
+  // NOTE: `i` is always associated with rho (size D), while `j` is always
+  // associated with theta (size d) cache.multiplier[i * d1 + j] stores k'(i,j)
+  // d1 is the size of the outer summation
+  if (native) { // native case
 
     std::vector<Ctxt> acc(d1, Ctxt(ZeroCtxtLike, ctxt));
 
+    // prepare the accumulators
     if (iterative0) {
-      Ctxt sh_ctxt(ctxt);
-
-      for (long i : range(d0)) {
-        if (i > 0) {
-          sh_ctxt.smartAutomorph(zMStar.genToPow(dim0, 1));
-          sh_ctxt.cleanUp();
+      if (dim0 != -1) { // first dim not frobenius
+        Ctxt sh_ctxt(ctxt);
+        long cur_pow = 0;
+        for (long i :
+             diag_indices) {    // NOTE: diag_indices needs to be ascending
+          while (cur_pow < i) {
+            // we cannot use diag_indices[i] - diag_indices[i-1]
+            // because only one KSK is available
+            sh_ctxt.smartAutomorph(zMStar.genToPow(dim0, 1));
+            sh_ctxt.cleanUp();
+            cur_pow++;
+          }
+          for (long j : frob_indices) {
+            MulAdd(acc[j], cache.multiplier[i * d1 + j], sh_ctxt);
+          }
         }
-        for (long j : range(d1)) {
-          MulAdd(acc[j], cache.multiplier[i * d1 + j], sh_ctxt);
+      } else { // second dim not frobenius
+        Ctxt sh_ctxt(ctxt);
+
+        long cur_pow = 0;
+        for (long i : frob_indices) {
+          while (cur_pow < i) {
+            sh_ctxt.smartAutomorph(zMStar.genToPow(dim0, 1));
+            sh_ctxt.cleanUp();
+            cur_pow++;
+          }
+          for (long j : diag_indices) {
+            MulAdd(acc[j], cache.multiplier[i * d1 + j], sh_ctxt);
+          }
         }
       }
     } else {
 
-      std::shared_ptr<GeneralAutomorphPrecon> precon =
-          buildGeneralAutomorphPrecon(ctxt, dim0, ea);
+      // NOTE: if the automorphism indices are always multiples of g, we can
+      // instantiate a BasicAutomorphPrecon to save some computation
+      //  specifically, the permutations per automorphism can be reduced by C
+      //  times, where C is the number of digits
+      std::shared_ptr<GeneralAutomorphPrecon> precon;
+      // first dim not frobenius && KSS is BSGS
+      if (dim0 != -1 &&
+          ctxt.getPubKey().getKSStrategy(dim0) == HELIB_KSS_BSGS) {
+        precon =
+            std::make_shared<GeneralAutomorphPrecon_BSGS>(ctxt,
+                                                          dim0,
+                                                          ea,
+                                                          giant_step_indices,
+                                                          baby_step_indices);
+      } else
+        precon = buildGeneralAutomorphPrecon(ctxt, dim0, ea);
+
+      if (dim0 != -1) { // first dim not frobenius
+        long par_buf_sz = 1;
+        if (NTL::AvailableThreads() > 1)
+          par_buf_sz = std::min(n_diags, par_buf_max);
+
+        std::vector<std::shared_ptr<Ctxt>> par_buf(par_buf_sz);
+
+        for (long first_i = 0; first_i < n_diags; first_i += par_buf_sz) {
+          long last_i = std::min(first_i + par_buf_sz, n_diags);
+
+          // for i in [first_i..last_i), generate automorphism diag_indices[i]
+          // and store in par_buf[i-first_i]
+
+          NTL_EXEC_RANGE(last_i - first_i, first, last)
+
+          for (long idx : range(first, last)) {
+            long i = idx + first_i;
+            par_buf[idx] = precon->automorph(diag_indices[i]);
+          }
 
-      long par_buf_sz = 1;
-      if (NTL::AvailableThreads() > 1)
-        par_buf_sz = std::min(d0, par_buf_max);
+          NTL_EXEC_RANGE_END
 
-      std::vector<std::shared_ptr<Ctxt>> par_buf(par_buf_sz);
+          NTL_EXEC_RANGE(n_frob, first, last)
 
-      for (long first_i = 0; first_i < d0; first_i += par_buf_sz) {
-        long last_i = std::min(first_i + par_buf_sz, d0);
+          for (long _j : range(first, last)) {
+            long j = frob_indices[_j];
+            for (long i : range(first_i, last_i)) {
+              MulAdd(acc[j],
+                     cache.multiplier[diag_indices[i] * d1 + j],
+                     *par_buf[i - first_i]);
+            }
+          }
 
-        // for i in [first_i..last_i), generate automorphism i and store
-        // in par_buf[i-first_i]
+          NTL_EXEC_RANGE_END
+        }
+      } else { // second dim not frobenius
+        long par_buf_sz = 1;
+        if (NTL::AvailableThreads() > 1)
+          par_buf_sz = std::min(n_frob, par_buf_max);
 
-        NTL_EXEC_RANGE(last_i - first_i, first, last)
+        std::vector<std::shared_ptr<Ctxt>> par_buf(par_buf_sz);
 
-        for (long idx : range(first, last)) {
-          long i = idx + first_i;
-          par_buf[idx] = precon->automorph(i);
-        }
+        for (long first_i = 0; first_i < n_frob; first_i += par_buf_sz) {
+          long last_i = std::min(first_i + par_buf_sz, n_frob);
 
-        NTL_EXEC_RANGE_END
+          // for i in [first_i..last_i), generate automorphism i and store
+          // in par_buf[i-first_i]
 
-        NTL_EXEC_RANGE(d1, first, last)
+          NTL_EXEC_RANGE(last_i - first_i, first, last)
 
-        for (long j : range(first, last)) {
-          for (long i : range(first_i, last_i)) {
-            MulAdd(acc[j], cache.multiplier[i * d1 + j], *par_buf[i - first_i]);
+          for (long idx : range(first, last)) {
+            long i = idx + first_i;
+            par_buf[idx] = precon->automorph(frob_indices[i]);
           }
-        }
 
-        NTL_EXEC_RANGE_END
+          NTL_EXEC_RANGE_END
+
+          NTL_EXEC_RANGE(n_diags, first, last)
+
+          for (long j : range(first, last)) {
+            for (long i : range(first_i, last_i)) {
+              MulAdd(acc[diag_indices[j]],
+                     cache.multiplier[frob_indices[i] * d1 + diag_indices[j]],
+                     *par_buf[i - first_i]);
+            }
+          }
+
+          NTL_EXEC_RANGE_END
+        }
       }
     }
 
+    // assemble the accumulators
     if (iterative1) {
+      if (dim1 != -1) { // second dim not frobenius
+        Ctxt sum(acc[diag_indices[n_diags - 1]]);
+        for (long j = n_diags - 2; j >= 0; j--) {
+          sum.smartAutomorph( // NOTE: diag_indices needs to be ascending and
+                              // positive
+              zMStar.genToPow(dim1, diag_indices[j + 1] - diag_indices[j]));
+          sum.cleanUp();
+          sum += acc[diag_indices[j]];
+        }
+        if (diag_indices[0] != 0) {
+          sum.smartAutomorph(zMStar.genToPow(dim1, diag_indices[0]));
+          sum.cleanUp();
+        }
 
-      Ctxt sum(acc[d1 - 1]);
-      for (long j = d1 - 2; j >= 0; j--) {
-        sum.smartAutomorph(zMStar.genToPow(dim1, 1));
-        sum.cleanUp();
-        sum += acc[j];
-      }
+        ctxt = sum;
+      } else { // second dim is frobenius
+        Ctxt sum(acc[frob_indices[n_frob - 1]]);
+        for (long j = n_frob - 2; j >= 0; j--) {
+          sum.smartAutomorph(zMStar.genToPow(dim1, frob_indices[j+1] - frob_indices[j]));
+          sum.cleanUp();
+          sum += acc[frob_indices[j]];
+        }
+        if (frob_indices[0] != 0) {
+          sum.smartAutomorph(zMStar.genToPow(dim1, frob_indices[0]));
+          sum.cleanUp();
+        }
 
-      ctxt = sum;
+        ctxt = sum;
+      }
 
     } else {
+      if (dim1 != -1) { // second dim not frobenius
+        NTL::PartitionInfo pinfo(n_diags);
+        long cnt = pinfo.NumIntervals();
 
-      NTL::PartitionInfo pinfo(d1);
-      long cnt = pinfo.NumIntervals();
+        std::vector<Ctxt> sum(cnt, Ctxt(ZeroCtxtLike, ctxt));
 
-      std::vector<Ctxt> sum(cnt, Ctxt(ZeroCtxtLike, ctxt));
+        // for j in [0..n_diags)
+        NTL_EXEC_INDEX(cnt, index)
+        long first, last;
+        pinfo.interval(first, last, index);
+        for (long j : range(first, last)) {
+          if (diag_indices[j] > 0)
+            acc[diag_indices[j]].smartAutomorph(
+                zMStar.genToPow(dim1, diag_indices[j]));
+          sum[index] += acc[diag_indices[j]];
+        }
+        NTL_EXEC_INDEX_END
 
-      // for j in [0..d1)
-      NTL_EXEC_INDEX(cnt, index)
-      long first, last;
-      pinfo.interval(first, last, index);
-      for (long j : range(first, last)) {
-        if (j > 0)
-          acc[j].smartAutomorph(zMStar.genToPow(dim1, j));
-        sum[index] += acc[j];
-      }
-      NTL_EXEC_INDEX_END
+        ctxt = sum[0];
+        for (long i : range(1, cnt))
+          ctxt += sum[i];
+      } else { // second dim is frobenius
+        NTL::PartitionInfo pinfo(n_frob);
+        long cnt = pinfo.NumIntervals();
 
-      ctxt = sum[0];
-      for (long i : range(1, cnt))
-        ctxt += sum[i];
+        std::vector<Ctxt> sum(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+        // for j in [0..n_frob)
+        NTL_EXEC_INDEX(cnt, index)
+        long first, last;
+        pinfo.interval(first, last, index);
+        for (long j : range(first, last)) {
+          if (frob_indices[j] > 0)
+            acc[frob_indices[j]].smartAutomorph(zMStar.genToPow(dim1, frob_indices[j]));
+          sum[index] += acc[frob_indices[j]];
+        }
+        NTL_EXEC_INDEX_END
+
+        ctxt = sum[0];
+        for (long i : range(1, cnt))
+          ctxt += sum[i];
+      }
     }
-  } else {
+  } else { // NOTE: non-native case
 
     std::vector<Ctxt> acc(d1, Ctxt(ZeroCtxtLike, ctxt));
     std::vector<Ctxt> acc1(d1, Ctxt(ZeroCtxtLike, ctxt));
 
+    // prepare the accumulators
     if (iterative0) {
-      Ctxt sh_ctxt(ctxt);
-
-      for (long i : range(d0)) {
-        if (i > 0) {
-          sh_ctxt.smartAutomorph(zMStar.genToPow(dim0, 1));
-          sh_ctxt.cleanUp();
+      if (dim0 != -1) { // first dim not frobenius
+        Ctxt sh_ctxt(ctxt);
+        long cur_pow = 0;
+        for (long i : diag_indices) {
+          while (cur_pow < i) {
+            sh_ctxt.smartAutomorph(zMStar.genToPow(dim0, 1));
+            sh_ctxt.cleanUp();
+            cur_pow++;
+          }
+          for (long j : frob_indices) {
+            MulAdd(acc[j], cache.multiplier[i * d1 + j], sh_ctxt);
+            MulAdd(acc1[j], cache1.multiplier[i * d1 + j], sh_ctxt);
+          }
         }
-        for (long j : range(d1)) {
-          MulAdd(acc[j], cache.multiplier[i * d1 + j], sh_ctxt);
-          MulAdd(acc1[j], cache1.multiplier[i * d1 + j], sh_ctxt);
+      } else { // second dim not frobenius
+        Ctxt sh_ctxt(ctxt);
+
+        long cur_pow = 0;
+        for (long i : frob_indices) {
+          while (cur_pow < i) {
+            sh_ctxt.smartAutomorph(zMStar.genToPow(dim0, 1));
+            sh_ctxt.cleanUp();
+            cur_pow++;
+          }
+          for (long j : diag_indices) {
+            MulAdd(acc[j], cache.multiplier[i * d1 + j], sh_ctxt);
+            MulAdd(acc1[j], cache1.multiplier[i * d1 + j], sh_ctxt);
+          }
         }
       }
-    } else {
+    } else { // non-iterative0
+      // NOTE: same change here
+      std::shared_ptr<GeneralAutomorphPrecon> precon;
+      // first dim not frobenius && KSS is BSGS
+      if (dim0 != -1 &&
+          ctxt.getPubKey().getKSStrategy(dim0) == HELIB_KSS_BSGS) {
+        precon =
+            std::make_shared<GeneralAutomorphPrecon_BSGS>(ctxt,
+                                                          dim0,
+                                                          ea,
+                                                          giant_step_indices,
+                                                          baby_step_indices);
+      } else
+        precon = buildGeneralAutomorphPrecon(ctxt, dim0, ea);
+
+      if (dim0 != -1) { // first dim not frobenius
+        long par_buf_sz = 1;
+        if (NTL::AvailableThreads() > 1)
+          par_buf_sz = std::min(n_diags, par_buf_max);
+
+        std::vector<std::shared_ptr<Ctxt>> par_buf(par_buf_sz);
+
+        for (long first_i = 0; first_i < n_diags; first_i += par_buf_sz) {
+          long last_i = std::min(first_i + par_buf_sz, n_diags);
+
+          // for i in [first_i..last_i), generate automorphism diag_indices[i]
+          // and store in par_buf[i-first_i]
+
+          NTL_EXEC_RANGE(last_i - first_i, first, last)
+
+          for (long idx : range(first, last)) {
+            long i = idx + first_i;
+            par_buf[idx] = precon->automorph(diag_indices[i]);
+          }
 
-      std::shared_ptr<GeneralAutomorphPrecon> precon =
-          buildGeneralAutomorphPrecon(ctxt, dim0, ea);
+          NTL_EXEC_RANGE_END
+
+          NTL_EXEC_RANGE(n_frob, first, last)
+
+          for (long _j : range(first, last)) {
+            long j = frob_indices[_j];
+            for (long i : range(first_i, last_i)) {
+              MulAdd(acc[j],
+                     cache.multiplier[diag_indices[i] * d1 + j],
+                     *par_buf[i - first_i]);
+              MulAdd(acc1[j],
+                     cache1.multiplier[diag_indices[i] * d1 + j],
+                     *par_buf[i - first_i]);
+            }
+          }
 
-      long par_buf_sz = 1;
-      if (NTL::AvailableThreads() > 1)
-        par_buf_sz = std::min(d0, par_buf_max);
+          NTL_EXEC_RANGE_END
+        }
+      } else { // second dim not frobenius
+        long par_buf_sz = 1;
+        if (NTL::AvailableThreads() > 1)
+          par_buf_sz = std::min(n_frob, par_buf_max);
 
-      std::vector<std::shared_ptr<Ctxt>> par_buf(par_buf_sz);
+        std::vector<std::shared_ptr<Ctxt>> par_buf(par_buf_sz);
 
-      for (long first_i = 0; first_i < d0; first_i += par_buf_sz) {
-        long last_i = std::min(first_i + par_buf_sz, d0);
+        for (long first_i = 0; first_i < n_frob; first_i += par_buf_sz) {
+          long last_i = std::min(first_i + par_buf_sz, n_frob);
 
-        // for i in [first_i..last_i), generate automorphism i and store
-        // in par_buf[i-first_i]
+          // for i in [first_i..last_i), generate automorphism diag_indices[i]
+          // and store in par_buf[i-first_i]
 
-        NTL_EXEC_RANGE(last_i - first_i, first, last)
+          NTL_EXEC_RANGE(last_i - first_i, first, last)
 
-        for (long idx : range(first, last)) {
-          long i = idx + first_i;
-          par_buf[idx] = precon->automorph(i);
-        }
+          for (long idx : range(first, last)) {
+            long i = idx + first_i;
+            par_buf[idx] = precon->automorph(frob_indices[i]);
+          }
 
-        NTL_EXEC_RANGE_END
+          NTL_EXEC_RANGE_END
 
-        NTL_EXEC_RANGE(d1, first, last)
+          NTL_EXEC_RANGE(n_diags, first, last)
 
-        for (long j : range(first, last)) {
-          for (long i : range(first_i, last_i)) {
-            MulAdd(acc[j], cache.multiplier[i * d1 + j], *par_buf[i - first_i]);
-            MulAdd(acc1[j],
-                   cache1.multiplier[i * d1 + j],
-                   *par_buf[i - first_i]);
+          for (long j : range(first, last)) {
+            for (long i : range(first_i, last_i)) {
+              MulAdd(acc[diag_indices[j]],
+                     cache.multiplier[frob_indices[i] * d1 + diag_indices[j]],
+                     *par_buf[i - first_i]);
+              MulAdd(acc1[j],
+                     cache1.multiplier[frob_indices[i] * d1 + diag_indices[j]],
+                     *par_buf[i - first_i]);
+            }
           }
-        }
 
-        NTL_EXEC_RANGE_END
+          NTL_EXEC_RANGE_END
+        }
       }
     }
 
+    // assemble the accumulators
     if (iterative1) {
+      if (dim1 != -1) { // second dim not frobenius
+        Ctxt sum(acc[diag_indices[n_diags - 1]]);
+        Ctxt sum1(acc1[diag_indices[n_diags - 1]]);
+
+        for (long j = n_diags - 2; j >= 0; j--) {
+          sum.smartAutomorph(
+              zMStar.genToPow(dim1, diag_indices[j + 1] - diag_indices[j]));
+          sum.cleanUp();
+          sum += acc[diag_indices[j]];
+          sum1.smartAutomorph(
+              zMStar.genToPow(dim1, diag_indices[j + 1] - diag_indices[j]));
+          sum1.cleanUp();
+          sum1 += acc1[diag_indices[j]];
+        }
+        if (diag_indices[0] != 0) {
+          sum.smartAutomorph(zMStar.genToPow(dim1, diag_indices[0]));
+          sum1.smartAutomorph(zMStar.genToPow(dim1, diag_indices[0]));
+        }
 
-      Ctxt sum(acc[d1 - 1]);
-      Ctxt sum1(acc1[d1 - 1]);
+        sum1.smartAutomorph(zMStar.genToPow(dim, -D));
+        ctxt = sum;
+        ctxt += sum1;
+      } else { // second dim is frobenius
+        Ctxt sum(acc[frob_indices[n_frob - 1]]);
+        Ctxt sum1(acc1[frob_indices[n_frob - 1]]);
+
+        for (long j = n_frob - 2; j >= 0; j--) {
+          sum.smartAutomorph(zMStar.genToPow(dim1, frob_indices[j+1] - frob_indices[j]));
+          sum.cleanUp();
+          sum += acc[frob_indices[j]];
+          sum1.smartAutomorph(zMStar.genToPow(dim1, frob_indices[j+1] - frob_indices[j]));
+          sum1.cleanUp();
+          sum1 += acc1[frob_indices[j]];
+        }
+        if (frob_indices[0] != 0) {
+          sum.smartAutomorph(zMStar.genToPow(dim1, frob_indices[0]));
+          sum1.smartAutomorph(zMStar.genToPow(dim1, frob_indices[0]));
+        }
 
-      for (long j = d1 - 2; j >= 0; j--) {
-        sum.smartAutomorph(zMStar.genToPow(dim1, 1));
-        sum.cleanUp();
-        sum += acc[j];
-        sum1.smartAutomorph(zMStar.genToPow(dim1, 1));
-        sum1.cleanUp();
-        sum1 += acc1[j];
+        sum1.smartAutomorph(zMStar.genToPow(dim, -D));
+        ctxt = sum;
+        ctxt += sum1;
       }
+    } else { // non-iterative1
+      if (dim1 != -1) { // second dim not frobenius
+        NTL::PartitionInfo pinfo(n_diags);
+        long cnt = pinfo.NumIntervals();
 
-      sum1.smartAutomorph(zMStar.genToPow(dim, -D));
-      ctxt = sum;
-      ctxt += sum1;
-    } else {
+        std::vector<Ctxt> sum(cnt, Ctxt(ZeroCtxtLike, ctxt));
+        std::vector<Ctxt> sum1(cnt, Ctxt(ZeroCtxtLike, ctxt));
 
-      NTL::PartitionInfo pinfo(d1);
-      long cnt = pinfo.NumIntervals();
+        // for j in [0..n_diags)
+        NTL_EXEC_INDEX(cnt, index)
+        long first, last;
+        pinfo.interval(first, last, index);
+        for (long j : range(first, last)) {
+          if (diag_indices[j] > 0) {
+            acc[diag_indices[j]].smartAutomorph(
+                zMStar.genToPow(dim1, diag_indices[j]));
+            acc1[diag_indices[j]].smartAutomorph(
+                zMStar.genToPow(dim1, diag_indices[j]));
+          }
+          sum[index] += acc[diag_indices[j]];
+          sum1[index] += acc1[diag_indices[j]];
+        }
+        NTL_EXEC_INDEX_END
 
-      std::vector<Ctxt> sum(cnt, Ctxt(ZeroCtxtLike, ctxt));
-      std::vector<Ctxt> sum1(cnt, Ctxt(ZeroCtxtLike, ctxt));
+        for (long i : range(1, cnt))
+          sum[0] += sum[i];
+        for (long i : range(1, cnt))
+          sum1[0] += sum1[i];
+        sum1[0].smartAutomorph(zMStar.genToPow(dim, -D));
+        ctxt = sum[0];
+        ctxt += sum1[0];
+      } else { // second dim is frobenius
+        NTL::PartitionInfo pinfo(n_frob);
+        long cnt = pinfo.NumIntervals();
 
-      // for j in [0..d1)
-      NTL_EXEC_INDEX(cnt, index)
-      long first, last;
-      pinfo.interval(first, last, index);
-      for (long j : range(first, last)) {
-        if (j > 0) {
-          acc[j].smartAutomorph(zMStar.genToPow(dim1, j));
-          acc1[j].smartAutomorph(zMStar.genToPow(dim1, j));
+        std::vector<Ctxt> sum(cnt, Ctxt(ZeroCtxtLike, ctxt));
+        std::vector<Ctxt> sum1(cnt, Ctxt(ZeroCtxtLike, ctxt));
+
+        // for j in [0..d1)
+        NTL_EXEC_INDEX(cnt, index)
+        long first, last;
+        pinfo.interval(first, last, index);
+        for (long _j : range(first, last)) {
+          long j = frob_indices[_j];
+          if (j > 0) {
+            acc[j].smartAutomorph(zMStar.genToPow(dim1, j));
+            acc1[j].smartAutomorph(zMStar.genToPow(dim1, j));
+          }
+          sum[index] += acc[j];
+          sum1[index] += acc1[j];
         }
-        sum[index] += acc[j];
-        sum1[index] += acc1[j];
-      }
-      NTL_EXEC_INDEX_END
+        NTL_EXEC_INDEX_END
 
-      for (long i : range(1, cnt))
-        sum[0] += sum[i];
-      for (long i : range(1, cnt))
-        sum1[0] += sum1[i];
-      sum1[0].smartAutomorph(zMStar.genToPow(dim, -D));
-      ctxt = sum[0];
-      ctxt += sum1[0];
+        for (long i : range(1, cnt))
+          sum[0] += sum[i];
+        for (long i : range(1, cnt))
+          sum1[0] += sum1[i];
+        sum1[0].smartAutomorph(zMStar.genToPow(dim, -D));
+        ctxt = sum[0];
+        ctxt += sum1[0];
+      }
     }
   }
+
+  double end_cap = ctxt.capacity();
+  double end_time = NTL::GetTime();
+  printf("BlockMatMul1D time: %f, cap: %f\n", end_time - start_time, start_cap - end_cap);
 }
 
 // ===================== MatMulFull stuff ==================
@@ -1993,7 +3128,8 @@ public:
                    const std::vector<long>& _init_idxes,
                    long _dim) :
       ea_basetype(_ea_basetype), mat(_mat), init_idxes(_init_idxes), dim(_dim)
-  {}
+  {
+  }
 
   void processDiagonal(RX& epmat,
                        long offset,
@@ -2293,7 +3429,8 @@ public:
                         const std::vector<long>& _init_idxes,
                         long _dim) :
       ea_basetype(_ea_basetype), mat(_mat), init_idxes(_init_idxes), dim(_dim)
-  {}
+  {
+  }
 
   bool processDiagonal(std::vector<RX>& poly,
                        long offset,
diff --git a/src/polyEval.cpp b/src/polyEval.cpp
index 07387f4..8675cab 100644
--- a/src/polyEval.cpp
+++ b/src/polyEval.cpp
@@ -55,6 +55,12 @@ static void recursivePolyEval(Ctxt& ret,
                               long nCoeffs,
                               const NTL::Vec<Ctxt>& powers);
 
+static void recursivePolyEvalNew(Ctxt& ret,
+                                 const NTL::ZZX& poly,
+                                 long k,
+                                 DynamicCtxtPowers& babyStep,
+                                 std::vector<Ctxt>& giantStep);
+
 // Main entry point: Evaluate an encrypted polynomial on an encrypted input
 // return in ret = sum_i poly[i] * x^i
 void polyEval(Ctxt& ret, const NTL::Vec<Ctxt>& poly, const Ctxt& x)
@@ -219,6 +225,96 @@ void polyEval(Ctxt& ret, NTL::ZZX poly, const Ctxt& x, long k)
   }
 }
 
+// inputs are always relined, outputs are not
+long cost_n_leaves(long n) {
+  long cost = 0;
+  if(n <= 2)
+    return 0;  
+  long prevPo2 = NTL::NextPowerOfTwo(n);
+  if(1L << prevPo2 > n)
+    prevPo2 -= 1;
+  prevPo2 = 1 << prevPo2;
+  // a subtree of size 2^k has a cost of 2^(k-1)-2
+  if(prevPo2 == n)
+    return prevPo2 / 2 - 1;
+  // 1 = relin the one the inputs
+  cost += 1 + cost_n_leaves(n - prevPo2) + prevPo2 / 2 - 1;
+  return cost;
+}
+
+void polyEvalNew(std::vector<Ctxt*>& ret,
+                 NTL::vec_ZZX polys,
+                 const Ctxt& x,
+                 long k)
+{
+  std::vector<long> polyDegs(polys.length());
+  long max_degree = 0;
+  // make these polys odd
+  for (long _ = 0; _ < polys.length(); _++) {
+    auto& poly = polys[_];
+    // note: moved to buildBtsPolys in extractDigits.cpp
+    // for (long i = 0; i <= deg(poly); i+=2) {
+    //   NTL::SetCoeff(poly, i, 0L);
+    // }
+    // poly.normalize();
+    polyDegs[_] = deg(poly);
+    max_degree = std::max(max_degree, deg(poly));
+  }
+  // compute the baby step size k, defaults to sqrt(max_degree)
+  k = round(sqrt(max_degree + 1));
+  // find the k with lowest cost
+  long hi = 1L << NTL::NextPowerOfTwo(k);
+  long lo = std::max(2L, hi >> 2);
+  std::vector<long> minDepths(polyDegs.size());
+  for (size_t i = 0; i < polyDegs.size(); i++)
+    minDepths[i] = ceil(log(polyDegs[i]) / log(2));
+  long minCost = max_degree * polyDegs.size();
+  for (long kk = lo; kk <= hi; kk += 2) { // only search for even k
+    bool depthOk = true;
+    // shared computation, building the basis
+    long cost = kk / 2 + ceil(log(max_degree + 1) / log(2.0));
+    for (size_t j = 0; j < polyDegs.size(); j++) {
+      long l = ceil(log(double(polyDegs[j] + 1) / kk) / log(2));
+      long depth = l + ceil(log(kk) / log(2));
+      if (minDepths[j] < depth) {
+        depthOk = false;
+        break; // we want optimal depth
+      }
+      long n_leaves = (polyDegs[j] + 1 + kk - 1) / kk;
+      cost += cost_n_leaves(n_leaves);
+    }
+    if (!depthOk)
+      continue;
+    if (cost < minCost) {
+      minCost = cost;
+      k = kk;
+    }
+  }
+#ifdef HELIB_DEBUG
+  std::cerr << "  k=" << k;
+#endif
+
+  // now start the bsgs computation
+  // first precompute the baby-step and giant-step polynomials
+  long l = ceil(log(double(max_degree + 1) / k) / log(2));
+  DynamicCtxtPowers babyStep(x, k);
+  const Ctxt& x2k = babyStep.getPower(k);
+  std::vector<Ctxt> x2kPow2(
+      l,
+      Ctxt(x.getPubKey(),
+           x.getPtxtSpace())); // x^(2^i*k), for i = 0, 1, ..., l-1
+  x2kPow2[0] = x2k;
+  for (long i = 1; i < l; i++) {
+    x2kPow2[i] = x2kPow2[i - 1];
+    x2kPow2[i].square();
+  }
+  // now recurse
+  for (long i = 0; i < polys.length(); i++) {
+    recursivePolyEvalNew(*ret[i], polys[i], k, babyStep, x2kPow2);
+    ret[i]->reLinearize();
+  }
+}
+
 // Simple evaluation sum f_i * X^i, assuming that babyStep has enough powers
 static void simplePolyEval(Ctxt& ret,
                            const NTL::ZZX& poly,
@@ -388,6 +484,34 @@ static void recursivePolyEval(Ctxt& ret,
   ret += tmp;
 }
 
+static void recursivePolyEvalNew(Ctxt& ret,
+                                 const NTL::ZZX& poly,
+                                 long k,
+                                 DynamicCtxtPowers& babyStep,
+                                 std::vector<Ctxt>& giantStep)
+{
+  if (deg(poly) <= babyStep.size()) {
+    simplePolyEval(ret, poly, babyStep);
+    return;
+  }
+  long polyDeg = deg(poly);
+  // find minimum i s.t. 2^(i+1)*k >= polyDeg + 1, then degSplit = 2^i*k
+  // i = ceil(log_2((polyDeg + 1) / k)) - 1
+  long i = long(ceil(log(double(polyDeg + 1) / k) / log(2))) - 1;
+  long degSplit = k << i;
+  NTL::ZZX lowerHalf = trunc(poly, degSplit);
+  NTL::ZZX higherHalf = RightShift(poly, degSplit);
+  Ctxt tmp(babyStep.getPower(1).getPubKey(),
+           babyStep.getPower(1).getPtxtSpace());
+  recursivePolyEvalNew(tmp, lowerHalf, k, babyStep, giantStep);
+  recursivePolyEvalNew(ret, higherHalf, k, babyStep, giantStep);
+  // only relinearize before mult
+  // the total number of relin is 2^(l-1)
+  ret.reLinearize();
+  ret.multLowLvl(giantStep[i]);
+  ret += tmp;
+}
+
 // raise ciphertext to some power
 void Ctxt::power(long e)
 {
diff --git a/src/recryption.cpp b/src/recryption.cpp
index 57efffa..23c9e5c 100644
--- a/src/recryption.cpp
+++ b/src/recryption.cpp
@@ -22,6 +22,12 @@
 #include <helib/debugging.h>
 #include <helib/fhe_stats.h>
 #include <helib/log.h>
+#include <helib/keys.h>
+#include <chrono>
+
+using std::chrono::steady_clock;
+using std::chrono::duration;
+using std::chrono::duration_cast;
 
 #ifdef HELIB_DEBUG
 
@@ -135,6 +141,60 @@ static void newMakeDivisible(NTL::ZZX& poly,
 #endif
 }
 
+/**
+ * store the scaled-up poly inside zzParts
+ * store the overflow part inside I_part
+ */
+static void multAndGetOverflowPart(std::vector<NTL::ZZX>& zzParts,
+                                   std::vector<NTL::ZZX>& I_part,
+                                   const Context& context)
+{
+  assertTrue(zzParts.size() == 2, "expecting a two-part ctxt");
+  long aux = context.getAux();
+  // long eNew = context.getENew();
+  // long p = context.getP();
+  long qKS = context.ithPrime(context.getIndexQks());
+
+  const RecryptData& rcData = context.getRcData();
+  const PowerfulDCRT& p2d_conv = *rcData.p2dConv;
+
+  NTL::Vec<NTL::ZZ> pwfl, pwfl_mod;
+  I_part.resize(2);
+
+  long halfQKS = (qKS + 1) >> 1;
+  long halfAux = (aux + 1) >> 1;
+
+  for (size_t i = 0; i < zzParts.size(); i++) {
+    p2d_conv.ZZXtoPowerful(pwfl, zzParts[i]);
+    long length = pwfl.length();
+    pwfl_mod.SetLength(length);
+    vecRed(pwfl, pwfl, qKS, false);
+    for (int j = 0; j < length; j++) {
+      pwfl[j] *= aux;
+      // divide pwfl[i] by qKS, store the quotient in pwfl[i]
+      // the remainder in pwfl_mod[i]
+      pwfl_mod[j] = NTL::DivRem(pwfl[j], pwfl[j], qKS);
+      if (pwfl_mod[j] >= halfQKS) { // reduce pwfl_mod mod qKS
+        pwfl_mod[j] -= qKS;
+        pwfl[j] += 1;
+      }
+      // aux*a = t*q + [aux*a]_q, t in pwfl and [*]_q in pwfl_mod
+      // we actually want -t instead of t
+      pwfl[j] = -pwfl[j];
+      if (pwfl[j] >= halfAux) // reduce pwfl mod aux
+        pwfl[j] -= aux;
+    }
+    // now pwfl_mod stores the multiplied & qKS-reduced powerful rep
+    // pwfl stores the aux-reduced overflow part
+    p2d_conv.powerfulToZZX(zzParts[i], pwfl_mod);
+    p2d_conv.powerfulToZZX(I_part[i], pwfl);
+    // NOTE: actually we should mod-up on the powerful basis
+    //  i.e., mod-up pwfl_mod instead of zzParts
+    //  but since the modulus is huge, this is still ok
+  }
+  // Ctxt will be constructed in PubKey::reCrypt, not here
+}
+
 /*********************************************************************/
 /*********************************************************************/
 
@@ -197,7 +257,7 @@ static double compute_fudge(long p2ePrime, long p2e)
   return 1 + eps;
 }
 
-void RecryptData::setAE(long& e, long& ePrime, const Context& context)
+double RecryptData::setAE(long& e, long& ePrime, const Context& context)
 {
   double coeff_bound = context.boundForRecryption();
   // coeff_bound is ultimately a high prob bound on |w0+w1*s|,
@@ -248,11 +308,263 @@ void RecryptData::setAE(long& e, long& ePrime, const Context& context)
 
     ePrimeTry++;
   }
+  // set minCapacity
+  double minCapacity = log(HELIB_MIN_CAP_FRAC * p2r * coeff_bound /
+                           double(NTL::power_long(p, e) + 1) /
+                           context.getZMStar().getNormBnd()) /
+                       log(2.0);
 
 #ifdef HELIB_DEBUG
   std::cerr << "RecryptData::setAE(): e=" << e << ", e'=" << ePrime
             << std::endl;
 #endif
+  return minCapacity;
+}
+
+double RecryptData::setEncapAE(long& e,
+                               long& ePrime,
+                               long& qks,
+                               long& R,
+                               long nDgtsBTS,
+                               const Context& context)
+{
+  double coeff_bound = context.boundForRecryption();
+  // coeff_bound is ultimately a high prob bound on |w0+w1*s|,
+  // the coeffs of w0, w1 are chosen uniformly on [-1/2,1/2]
+
+  long p = context.getP();
+  long p2r = context.getAlMod().getPPowR();
+  long r = context.getAlMod().getR();
+  long frstTerm = 2 * p2r + 2;
+
+  long e_bnd = 0;
+  long p2e_bnd = 1;
+
+  // while (p2e_bnd <= ((1L << 30) - 2) / p) { // NOTE: this avoids overflow
+  //   e_bnd++;
+  //   p2e_bnd *= p;
+  // }
+  while (p2e_bnd <=
+         ((1L << NTL_SP_NBITS) - 2) / p) { // NOTE: this avoids overflow
+    e_bnd++;
+    p2e_bnd *= p;
+  }
+  // e_bnd is largest e such that p^e+1 < 2^30
+
+  // Start with the smallest e s.t. p^e/2 >= frstTerm*coeff_bound
+  ePrime = 0;
+  e = r + 1;
+  while (e <= e_bnd && NTL::power_long(p, e) < frstTerm * coeff_bound * 2)
+    e++;
+
+  //  if (e > e_bnd) Error("setAE: cannot find suitable e");
+  assertFalse<RuntimeError>(e > e_bnd, "setAE: cannot find suitable e");
+
+  // long ePrimeTry = r+1;
+  long ePrimeTry = 1;
+
+  while (ePrimeTry <= e_bnd) {
+    long p2ePrimeTry = NTL::power_long(p, ePrimeTry);
+    // long eTry = ePrimeTry+1;
+    long eTry = std::max(r + 1, ePrimeTry + 1);
+    while (eTry <= e_bnd && eTry - ePrimeTry < e - ePrime) {
+      long p2eTry = NTL::power_long(p, eTry);
+      double fudge = compute_fudge(p2ePrimeTry, p2eTry);
+      if (p2eTry >= (p2ePrimeTry * fudge + frstTerm) * coeff_bound * 2)
+        break;
+
+      eTry++;
+    }
+
+    if (eTry <= e_bnd && eTry - ePrimeTry < e - ePrime) {
+      e = eTry;
+      ePrime = ePrimeTry;
+    }
+
+    ePrimeTry++;
+  }
+
+// #ifdef HELIB_DEBUG
+  std::cerr << "RecryptData::setEncapAE(): e=" << e << ", e'=" << ePrime
+            << std::endl;
+// #endif
+
+  // the logic for setting e and ePrime is the same,
+  // the only difference is that we set qKS and R here
+  // TODO: avoid copying the code of setAE
+  double scale = context.getScale();
+  long m = context.getZMStar().getM();
+  long phim = context.getZMStar().getPhiM();
+  long skHwt = context.getHwt();
+  double mfac =
+      context.getZMStar()
+          .getNormBnd(); // Dm, the ratio between pwfl and canonical bound
+  long q = NTL::power_long(p, e) + 1;
+  double stdev = NTL::conv<double>(context.getStdev());
+
+  // the "scaled noise" should be bounded by 2/3* p^r*(B*+0.5) (powerful)
+  // still assuming the input ctxt before key-switching has a canonical noise
+  // beta then after KS, noise is 2*beta*q/qKS (canonical) i.e.,
+  // 2*beta*q/qKS*mfac < 2/3 * p^r(B*+0.5) or qKS > 2*beta*q*mfac / (2/3 *
+  // p^r*(B*+0.5))
+  double beta =
+      p2r * (scale * sqrt(double(phim) / 12.0) *
+                 (sqrt(double(skHwt) * log(double(phim))) + 1) +
+             0.5); // beta is the canonical bound for the message after ms
+  qks = ceil(2 * beta * q * mfac / (HELIB_MIN_CAP_FRAC * p2r * coeff_bound));
+  printf("log2(qks) >= %f", log(double(qks)) / log(2.0));
+  // now find the smallest qks with an m-th order primitive root of unity.
+  // we only test for qks == 1 mod m
+  long tmp = qks % m;
+  if (tmp <= 1)
+    qks += 1 - tmp;
+  else
+    qks += m + 1 - (qks % m);
+  while (!NTL::ProbPrime(qks, 60))
+    qks += m;
+  printf(", final log2(qks) = %f\n", log(double(qks)) / log(2.0));
+  // set the minimum capacity
+  double minCapacity = log(qks / beta) / log(2.0);
+
+  // finally, we choose R >= alpha / beta, where alpha is the bound on the
+  // ks-added noise. for power-of-2 m, we have:
+  // alpha = qKS^(1/c)*c*phim*sqrt(ln(phim))*P*sigma*k/sqrt(12)
+  double alpha = pow(double(qks), 1.0 / nDgtsBTS) * phim *
+                 sqrt(log(double(phim)) / 12.0) * p2r * scale * nDgtsBTS *
+                 stdev;
+  if (!is2power(m)) // alpha is larger for non-power-of-2 m
+    alpha *= double(m) / sqrt(double(phim));
+  R = ceil(alpha / beta);
+  printf("log2(R) >= %f", log(double(R)) / log(2.0));
+  // again, search for the next prime >= R with m-th root
+  tmp = R % m;
+  if (tmp <= 1)
+    R += 1 - tmp;
+  else
+    R += m + 1 - tmp;
+  while (!NTL::ProbPrime(R, 60))
+    R += m;
+  printf(", final log2(R) = %f\n", log(double(R)) / log(2.0));
+
+  return minCapacity;
+}
+
+double RecryptData::setNewBootAE(long& eNew,
+                                 long& t,
+                                 long& aux,
+                                 long& qks,
+                                 long& R,
+                                 long& numExtract,
+                                 long nDgtsBTS,
+                                 const Context& context)
+{
+  long p = context.getP();
+  long p2r = context.getAlMod().getPPowR();
+  long r = context.getAlMod().getR();
+  double scale = context.getScale();
+  long skHwt = context.getHwt();
+  long encapSkHwt = context.getEncapHwt();
+  long m = context.getZMStar().getM();
+  long phim = context.getZMStar().getPhiM();
+  double mfac =
+      context.getZMStar()
+          .getNormBnd(); // Dm, the ratio between pwfl and canonical bound
+  long nfactors = context.getZMStar().getNFactors();
+  double stdev = NTL::conv<double>(context.getStdev());
+
+  // first,  we check the validity of t and set eNew & aux based on t
+  double I_bound =
+      context.boundForRecryption(); // B is the powerful bound for the overflow
+                                    // part & ms-added noise (using the
+                                    // encapsulated sparse key)
+                                    // this implicitly use btsScale
+  long I_range = 2 * long(ceil(I_bound)) + 1;
+  // sanity check, no more than 2 digits to be extracted
+  // TODO: maybe consider more than 2 digits later?
+  assertTrue(I_range < p * p,
+             "new bootstrap procedure supports extraction of at most 2 digits");
+  if (t < 0) { // use non-power-of-p aux
+    assertTrue(I_range * I_range < p,
+               "non-power-of-p aux: p too small to hold the overflow part");
+    aux = 2 * ceil(I_bound) + 1;
+    if (NTL::GCD(aux, p) > 1)
+      aux += 1;
+    eNew = r;
+    numExtract = 1;
+  } else if (t == 0) { // deduce the value of t
+    // we require p^t > I_range
+    long tmp = 1;
+    while (tmp <= I_range) {
+      tmp *= p;
+      t++;
+    }
+    eNew = r + t;
+    aux = NTL::power_long(p, t);
+    numExtract = t;
+  } else { // check the validity of t
+    assertTrue(
+        NTL::power_long(p, t) > I_range,
+        "preset power-of-p aux: p^t too small to hold the overflow part");
+    eNew = r + t;
+    aux = NTL::power_long(p, t);
+    numExtract = ceil(log(I_range) / log(p) + 0.00001);
+  }
+  printf("\nt = %ld\n", t);
+  printf("bound on I = %f\n", I_bound);
+  printf("log2(aux) = %f\n", log(aux) / log(2));
+
+  // second, we choose q
+  // beta = P*(k*sqrt(phim/12)*(1 + sqrt(h*ln(phim))) + 0.5),
+  // the canonical bound on the modulus switching noise
+  double beta =
+      p2r * (scale * sqrt(double(phim) / 12.0) *
+                 (sqrt(double(skHwt) * log(double(phim))) + 1) +
+             0.5); // beta is the canonical bound for the message after ms
+  printf("log2(beta) = %f\n", log(beta) / log(2.0));
+  // this is the pwfl bound on the modulus switching noise
+  // 0.5 + k*2^(nfactors/2)/sqrt(12)*sqrt(encap_h)*sqrt(phim/m)
+  double ms_bound =
+      0.5 + scale *
+                sqrt(double(phim) / double(m) * double(encapSkHwt) *
+                     double(1L << nfactors) / 3.0) *
+                0.5;
+  // can2pwfl(2 * beta) + ms_pwfl_bound < q / (2 * aux)
+  qks = ceil(aux * 2 * (mfac * 2 * beta + ms_bound * p2r + 2));
+  printf("log2(qks) >= %f", log(double(qks)) / log(2.0));
+  // now find the smallest qks with an m-th order primitive root of unity.
+  // we only test for qks == 1 mod m
+  long tmp = qks % m;
+  if (tmp <= 1)
+    qks += 1 - tmp;
+  else
+    qks += m + 1 - (qks % m);
+  while (!NTL::ProbPrime(qks, 60))
+    qks += m;
+  printf(", final log2(qks) = %f\n", log(double(qks)) / log(2.0));
+  // set min capacity
+  double minCapacity = log(qks / beta) / log(2.0);
+
+  // finally, we choose R >= alpha / beta, where alpha is the bound on the
+  // ks-added noise. for power-of-2 m, we have:
+  // alpha = qKS^(1/c)*c*phim*sqrt(ln(phim))*P*sigma*k/sqrt(12)
+  double alpha = pow(double(qks), 1.0 / nDgtsBTS) * phim *
+                 sqrt(log(double(phim)) / 12.0) * p2r * scale * nDgtsBTS *
+                 stdev;
+  if (!is2power(m)) // alpha is larger for non-power-of-2 m
+    alpha *= double(m) / sqrt(double(phim));
+  R = ceil(alpha / beta);
+  printf("log2(R) >= %f", log(double(R)) / log(2.0));
+  // again, search for the next prime >= R with m-th root
+  tmp = R % m;
+  if (tmp <= 1)
+    R += 1 - tmp;
+  else
+    R += m + 1 - tmp;
+  while (!NTL::ProbPrime(R, 60))
+    R += m;
+  printf(", final log2(R) = %f\n", log(double(R)) / log(2.0));
+
+  return minCapacity;
 }
 
 bool RecryptData::operator==(const RecryptData& other) const
@@ -267,6 +579,7 @@ bool RecryptData::operator==(const RecryptData& other) const
 }
 
 // The main method
+// TODO: collapsed FFT for power-of-2 full-SIMD parameters
 void RecryptData::init(const Context& context,
                        const NTL::Vec<long>& mvec_,
                        bool enableThick,
@@ -300,19 +613,30 @@ void RecryptData::init(const Context& context,
     Warning("prime power factorization recommended for bootstrapping");
   }
 
-  skHwt = context.getHwt();
+  skHwt = context.getEncapHwt();
   e = context.getE();
   ePrime = context.getEPrime();
+  // new bts
+  eNew = context.getENew();
+  t = context.getT();
+  newBtsFlag = context.getNewBTSFlag();
 
   long r = context.getAlMod().getR();
 
   // First part of Bootstrapping works wrt plaintext space p^{r'}
-  alMod = std::make_shared<PAlgebraMod>(context.getZMStar(), e - ePrime + r);
+  long new_hensel_lifting =
+      newBtsFlag
+          ? eNew
+          : (e - ePrime +
+             r); // NOTE: is it necessary to create a new AlMod when eNew == r?
+  alMod =
+      std::make_shared<PAlgebraMod>(context.getZMStar(), new_hensel_lifting);
   ea = std::make_shared<EncryptedArray>(context, *alMod);
   // Polynomial defaults to F0, PAlgebraMod explicitly given
 
   p2dConv = std::make_shared<PowerfulDCRT>(context, mvec);
 
+  isPo2 = is2power(context.getM());
   if (!enableThick)
     return;
 
@@ -323,6 +647,11 @@ void RecryptData::init(const Context& context,
   long nslots = ea->size();
   long d = ea->getDegree();
 
+  // NOTE:
+  // normalBasisMatrix: mapping from norm basis to power basis (represent normal basis in power basis), v_N^T * M = v_P
+  // normalBasisMatrixInverse: mapping from power basis to normal basis, v_P^T * M^-1 = v_N^T
+  // then, the unpacking map that extracts the first normal basis coefficient
+  // acts on the power basis vector v_P^T as v_P^T * M^-1 * E_{0,0}, which explains the values of LM[i]
   const NTL::Mat<NTL::zz_p>& CBi =
       ea->getDerived(PA_zz_p()).getNormalBasisMatrixInverse();
 
@@ -335,43 +664,60 @@ void RecryptData::init(const Context& context,
   ea->buildLinPolyCoeffs(C, LM); // "build" the linear polynomial
 
   unpackSlotEncoding.resize(d); // encode the coefficients
-
+  // NOTE: the coefficients above acts on a single slot, we need to make them SIMD
   for (long j = 0; j < d; j++) {
     std::vector<NTL::ZZX> v(nslots);
     for (long k = 0; k < nslots; k++)
       v[k] = C[j];
     ea->encode(unpackSlotEncoding[j], v);
   }
-  firstMap = std::make_shared<EvalMap>(*ea, minimal, mvec, true, build_cache);
-  secondMap = std::make_shared<EvalMap>(context.getEA(),
-                                        minimal,
-                                        mvec,
-                                        false,
-                                        build_cache);
+  if (!isPo2) {
+    firstMap = std::make_shared<EvalMap>(*ea, minimal, mvec, true, build_cache);
+    // for the case of t<0 in new BTS, the secondMap is still performed modulo
+    // p^new_hensel_lifting
+    secondMap = std::make_shared<EvalMap>((newBtsFlag && t < 0) ? *ea : context.getEA(),
+                                          minimal,
+                                          mvec,
+                                          false,
+                                          build_cache);
+  } else {
+    bool forceRadix2 = context.getForceRadix2();
+    const auto& partition = context.getFFTPartition();
+    firstPo2Map = std::make_shared<Po2IFFT>(*ea, false, partition, forceRadix2, build_cache);
+    secondPo2Map = std::make_shared<Po2IFFT>((newBtsFlag && t < 0) ? *ea : context.getEA(), 
+                                            true, partition, forceRadix2, build_cache);
+  }
 }
 
 /********************************************************************/
 /********************************************************************/
 
 // Extract digits from fully packed slots
-void extractDigitsPacked(Ctxt& ctxt,
+// this is pre-declaration
+// thin-refine: true = extract higher digits, false = extract lower digits
+BootBench extractDigitsPacked(Ctxt& ctxt,
                          long botHigh,
                          long r,
                          long ePrime,
-                         const std::vector<NTL::ZZX>& unpackSlotEncoding);
+                         const std::vector<NTL::ZZX>& unpackSlotEncoding,
+                         bool thinRefine);
 
 // Extract digits from unpacked slots
-void extractDigitsThin(Ctxt& ctxt, long botHigh, long r, long ePrime);
+void extractDigitsThin(Ctxt& ctxt, long botHigh, long r, long ePrime, bool thinRefine=false);
+
+// #define HELIB_DEBUG // XXX
 
 // bootstrap a ciphertext to reduce noise
-void PubKey::reCrypt(Ctxt& ctxt) const
+BootBench PubKey::reCrypt(Ctxt& ctxt) const
 {
+  BootBench benchmarker;
+  auto time_boot_start = steady_clock::now();
   HELIB_TIMER_START;
 
   // Some sanity checks for dummy ciphertext
   long ptxtSpace = ctxt.getPtxtSpace();
   if (ctxt.isEmpty())
-    return;
+    return benchmarker;
   if (ctxt.parts.size() == 1 && ctxt.parts[0].skHandle.isOne()) {
     // Dummy encryption, just ensure that it is reduced mod p
     NTL::ZZX poly = to_ZZX(ctxt.parts[0]);
@@ -379,7 +725,7 @@ void PubKey::reCrypt(Ctxt& ctxt) const
       poly[i] = NTL::to_ZZ(rem(poly[i], ptxtSpace));
     poly.normalize();
     ctxt.DummyEncrypt(poly);
-    return;
+    return benchmarker;
   }
 
   // check that we have bootstrapping data
@@ -397,7 +743,18 @@ void PubKey::reCrypt(Ctxt& ctxt) const
   long ePrime = rcData.ePrime;
   long p2ePrime = NTL::power_long(p, ePrime);
   long q = NTL::power_long(p, e) + 1;
-  assertTrue(e >= r, "rcData.e must be at least alMod.r");
+  // new bts
+  // TODO: remove the duplicate members in rcData to avoid possible mistakes?
+  long eNew = rcData.eNew;
+  long t = rcData.t;
+  long aux = context.getAux();
+  long p2eNew = NTL::power_long(p, eNew);
+  bool newBtsFlag = context.getNewBTSFlag();
+  bool newKSFlag = context.getNewKSFlag();
+  if (!newBtsFlag)
+    assertTrue(e >= r, "rcData.e must be at least alMod.r");
+  if (newBtsFlag)
+    q = context.ithPrime(context.getIndexQks());
 
 #ifdef HELIB_DEBUG
   std::cerr << "reCrypt: p=" << p << ", r=" << r << ", e=" << e
@@ -408,10 +765,15 @@ void PubKey::reCrypt(Ctxt& ctxt) const
   // can only bootstrap ciphertext with plaintext-space dividing p^r
   assertEq(p2r % ptxtSpace, 0l, "ptxtSpace must divide p^r when bootstrapping");
 
+#ifdef HELIB_DEBUG
+  NTL::ZZX poly_input;
+  dbgKey->Decrypt(poly_input, ctxt);
+#endif
+
   ctxt.dropSmallAndSpecialPrimes();
 
 #ifdef HELIB_DEBUG
-  CheckCtxt(ctxt, "after mod down");
+  CheckCtxt(ctxt, "after drop small and special primes");
 #endif
 
   HELIB_NTIMER_START(AAA_preProcess);
@@ -423,29 +785,68 @@ void PubKey::reCrypt(Ctxt& ctxt) const
   // Mod-switch down if needed
   IndexSet s = ctxt.getPrimeSet() / context.getSpecialPrimes();
   assertTrue(s <= context.getCtxtPrimes(), "prime set is messed up");
-  if (s.card() > 3) { // leave only first three ciphertext primes
-    long first = s.first();
-    IndexSet s3(first, first + 2);
-    s.retain(s3);
+  if (newKSFlag) { // since the decomposition is independent of the RNS
+                   // representation, we do not need to keep 3 primes
+    s.clear();
+    s.insert(context.getIndexQks());
+    ctxt.bringToSet(s);
+    // TODO: check the error bound of ctxt and warn on large noise?
+    //  the budget in ctxt should be larger than the budget in the
+    //  assumed-post-ms-pre-ks-ctxt (whose noise bound is beta) by one or two
+    //  bits
+  } else {
+    if (s.card() > 3) { // leave only first three ciphertext primes
+      long first = s.first();
+      IndexSet s3(first, first + 2);
+      s.retain(s3);
+    }
+    ctxt.modDownToSet(s);
   }
-  ctxt.modDownToSet(s);
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after mod down to KS modulus");
+
+  NTL::ZZX poly_before;
+  dbgKey->Decrypt(poly_before, ctxt);
+  assertEq(poly_input, poly_before, "something wrong with mod-down");
+#endif
 
   // key-switch to the bootstrapping key
-  ctxt.reLinearize(recryptKeyID);
+  // > this is problematic... because the qKS will be dropped by
+  // dropSmallAndSpecialPrimes
+  // also, the decomposition algorithm needs to change
+  ctxt.reLinearize(recryptKeyID, newKSFlag);
 
 #ifdef HELIB_DEBUG
   CheckCtxt(ctxt, "after key switching");
+
+  NTL::ZZX poly_after;
+  dbgKey->Decrypt(poly_after, ctxt);
+  assertEq(poly_before, poly_after, "something wrong with key switching");
 #endif
 
   // "raw mod-switch" to the bootstrapping modulus q=p^e+1.
   std::vector<NTL::ZZX> zzParts; // the mod-switched parts, in ZZX format
 
   double mfac = ctxt.getContext().getZMStar().getNormBnd();
-  double noise_est = ctxt.rawModSwitch(zzParts, q) * mfac;
+  // NOTE: rawModSwitch assumes the current ctxt modulus is coprime to q
+  // however, this is not the case for the new bootstrap,
+  // where ctxt modulus is qKS * R, while q = qKS
+  double noise_est;
+  if (newBtsFlag)
+    noise_est = ctxt.rawModSwitchNew(zzParts, q) * mfac; // q = qKS
+  else
+    noise_est = ctxt.rawModSwitch(zzParts, q) * mfac; // q = p^e+1
   // noise_est is an upper bound on the L-infty norm of the scaled noise
   // in the pwrfl basis
-  double noise_bnd =
-      HELIB_MIN_CAP_FRAC * p2r * ctxt.getContext().boundForRecryption();
+  long phim = context.getZMStar().getPhiM();
+  double beta =
+      p2r * (context.getScale() * sqrt(double(phim) / 12.0) *
+                 (sqrt(double(context.getHwt()) * log(double(phim))) + 1) +
+             0.5);
+  double noise_bnd = newBtsFlag ? 2 * beta * mfac
+                                : HELIB_MIN_CAP_FRAC * p2r *
+                                      ctxt.getContext().boundForRecryption();
   // noise_bnd is the bound assumed in selecting the parameters
   double noise_rat = noise_est / noise_bnd;
 
@@ -467,50 +868,253 @@ void PubKey::reCrypt(Ctxt& ctxt) const
            "Exactly 2 parts required for mod-switching in thin bootstrapping");
 
 #ifdef HELIB_DEBUG
-  if (dbgKey) {
+  const PowerfulDCRT& p2d_conv = *rcData.p2dConv;
+  if (dbgKey && !newBtsFlag) {
     checkRecryptBounds(zzParts, dbgKey->getRecryptKey(), ctxt.getContext(), q);
   }
+  // after raw mod-swtich, poly_after has a stored intFactor of
+  // `intFactor`, and an implied intFactor of `intFactor * [q]_p2r`
+  NTL::ZZX poly_after_rawmod;
+  NTL::vec_ZZ pwfl_after_rawmod;
+  if (newBtsFlag) { // NOTE: this is pure debug
+    rawDecrypt(poly_after_rawmod, zzParts, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(pwfl_after_rawmod, poly_after_rawmod);
+    vecRed(pwfl_after_rawmod, pwfl_after_rawmod, q, false);
+    p2d_conv.powerfulToZZX(poly_after_rawmod, pwfl_after_rawmod);
+    // and may output incorrect results for out-of-range inputs
+    long impliedIntFactor = NTL::MulMod(intFactor, q % p2r, p2r);
+    long invImplied = NTL::InvMod(impliedIntFactor, p2r);
+    // set abs=True to be consistent with the Decryption function
+    poly_after_rawmod = helib::MulMod(poly_after_rawmod, invImplied, p2r, true);
+    assertEq(poly_after,
+             poly_after_rawmod,
+             "something wrong with raw modswitch");
+  }
 #endif
 
   std::vector<NTL::ZZX> v;
   v.resize(2);
 
-  // Add multiples of q to make the zzParts divisible by p^{e'}
-  for (long i : range(2)) {
-    // make divisible by p^{e'}
+  // this ctxt will be
+  //  (a) modulus switched down to the ctxtPrimes (b) key-switched to
+  //  the normal sk (c) substracted by the digit extraction results
+  Ctxt modUpCtxt(ctxt.getPubKey(), p2eNew);
+  std::vector<NTL::ZZX> I_part;
+
+  // the debug polys
+  NTL::ZZX poly_before_mod;
+  NTL::vec_ZZ pwfl_before_mod;
+  NTL::ZZX poly_after_mod, I_poly;
+  NTL::vec_ZZ pwfl_after_mod, pwfl_diff;
+  NTL::ZZX modUpPoly;
+  NTL::vec_ZZ modUpPwfl, I_part_pwfl;
+  if (!newBtsFlag)
+    // Add multiples of q to make the zzParts divisible by p^{e'}
+    for (long i : range(2)) {
+      // make divisible by p^{e'}
+      newMakeDivisible(zzParts[i], p2ePrime, q, ctxt.getContext(), v[i]);
+    }
+  else {
+    // XXX: modding up or down & relin should not affect the stored intFactor...
+    assertTrue(intFactor == ctxt.intFactor, "why the intFactors do not match?");
+
+#ifdef HELIB_DEBUG
+    rawDecrypt(poly_before_mod, zzParts, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(pwfl_before_mod, poly_before_mod);
+    vecRed(pwfl_before_mod, pwfl_before_mod, q, false);
+    double largePwflBefore = NTL::conv<double>(largestCoeff(pwfl_before_mod));
+    printf("pwfl capacity before = %f\n",
+           log(double(q) / 2.0 / largePwflBefore / double(aux)) / log(2.0));
+    assertTrue(largePwflBefore * aux < double(q) / 2.0,
+               "not enough capacity before scaleUp");
+#endif
+
+    // > (1) mult by aux,
+    // (2) extract the overflow part, and store them as ZZXs -> feed into digit
+    // extraction (3) mod-up the ctxt after mult to the highest modulus (with an
+    // extra prime modulus) note that the mod-up ctxt decrypts w.r.t. encapSk
+    multAndGetOverflowPart(zzParts, I_part, ctxt.getContext());
+
+#ifdef HELIB_DEBUG
+    rawDecrypt(poly_after_mod, zzParts, dbgKey->getRecryptKey());
+    // check the overflow part
+    rawDecrypt(I_poly, I_part, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(I_part_pwfl, I_poly);
+    vecRed(I_part_pwfl, I_part_pwfl, aux, false);
+    p2d_conv.powerfulToZZX(I_poly, I_part_pwfl);
+
+    p2d_conv.ZZXtoPowerful(pwfl_diff, poly_after_mod - I_poly * q);
+    // vecRed(pwfl_diff, pwfl_diff, NTL::ZZ(aux) * NTL::ZZ(q), false);
+    for (long i = 0; i < phim; i++) {
+      assertTrue(bool(NTL::abs(pwfl_diff[i]) <= (q / 2)),
+                 "overflow part wrong?");
+    }
+    // assertTrue(NTL::to_long(largestCoeff(pwfl_diff)) <= (q / 2),
+    //            "overflow part wrong?");
+    // check the relationship between pwfl_before_mod and pwfl_after_mod
+    // now check if the bound on I is valid
+    p2d_conv.ZZXtoPowerful(pwfl_after_mod, poly_after_mod);
+    NTL::xdouble actualBoundI =
+        NTL::conv<NTL::xdouble>(largestCoeff(pwfl_after_mod)) / NTL::xdouble(q);
+    std::cerr << "actual bound on I is " << actualBoundI << "\n";
+    assertTrue(
+        bool(NTL::floor(actualBoundI) <= ceil(context.boundForRecryption())),
+        "bound on I exceeded");
+    vecRed(pwfl_after_mod, pwfl_after_mod, q, false);
+    if (t < 0) {
+      for (long i = 0; i < phim; i++) {
+        long before = NTL::rem(pwfl_before_mod[i], p2r);
+        before = NTL::MulMod(before, aux % p2r, p2r);
+        long after = NTL::rem(pwfl_after_mod[i], p2r);
+        assertEq(before,
+                 after,
+                 "something wrong with upscaling, non-power-of-p aux");
+      }
+    } else {
+      for (long i = 0; i < phim; i++) {
+        long before = NTL::rem(pwfl_before_mod[i], p2r);
+        long after = NTL::rem(pwfl_after_mod[i], p2eNew);
+        assertEq(before * aux,
+                 after,
+                 "something wrong with upscaling, power-of-p aux");
+      }
+    }
+#endif
+
+    // now handle the mod-up ctxt
+    modUpCtxt.ptxtSpace = p2eNew;
+    modUpCtxt.primeSet = context.getCtxtPrimes() | context.getModUpPrimes();
+    long QmodP = 1;
+    // be careful with single-precision modular arithmetic...
+    for (auto i : modUpCtxt.primeSet)
+      QmodP = NTL::MulMod(QmodP, context.ithPrime(i) % p2eNew, p2eNew);
+    // we pretend the IMPLIED INTFACTOR of m* mod P is 1
+    // (i.e., zzParts after raw-ms decrypts to m*)
+    // which is actually intFactor * [q]_{p^r}
+    // we want the mult-by-aux and modded-up ctxt to have
+    // an implied intfactor of aux (decrypts to m*+...)
+    if (t < 0) // gcd(aux, p) = 1, stored intFactor = aux * [Q^-1]_P
+      modUpCtxt.intFactor =
+          NTL::MulMod(aux, NTL::InvMod(QmodP, p2eNew), p2eNew);
+    else // aux = p^t, stored intFactor = [Q^-1]_P
+      modUpCtxt.intFactor = NTL::InvMod(QmodP, p2eNew);
+    modUpCtxt.noiseBound = context.boundForRecryption() * q;
+    for (int i = 0; i < 2; i++)
+      modUpCtxt.addPart(DoubleCRT(zzParts[i], context, modUpCtxt.primeSet),
+                        ctxt.parts[i].skHandle);
+    // discard the mod-up primes
+    modUpCtxt.modDownToSet(context.getCtxtPrimes());
+
+    // switch to the normal sk (keyID = 0)
+    modUpCtxt.reLinearize();
 
-    newMakeDivisible(zzParts[i], p2ePrime, q, ctxt.getContext(), v[i]);
+#ifdef HELIB_DEBUG
+    dbgKey->Decrypt(modUpPoly, modUpCtxt);
+    p2d_conv.ZZXtoPowerful(modUpPwfl, modUpPoly);
+    vecRed(modUpPwfl, modUpPwfl, p2eNew, false);
+    p2d_conv.ZZXtoPowerful(I_part_pwfl, I_poly);
+    vecRed(I_part_pwfl, I_part_pwfl, aux, false);
+
+    p2d_conv.ZZXtoPowerful(pwfl_after_mod, poly_after_mod);
+    vecRed(pwfl_after_mod, pwfl_after_mod, q, false);
+
+    // for aux = p^t
+    // the message in zzParts befure "multAndGetOverflowPart" is m' mod p2r
+    // after that, the scaled message becomes p^t*m' mod p2eNew
+    // by modding up, the message becomes p^t*m' + [q]_p2eNew*I
+    // setting the modUpCtxt.intFactor = [Q^-1]_p2eNew ensures
+    // modUpCtxt decrypts to p^t*m' + [q]_p2eNew*I
+    for (long i = 0; i < phim; i++) {
+      if (t > 0) {
+        assertEq(NTL::rem(modUpPwfl[i] - I_part_pwfl[i] * (q % p2eNew) -
+                              pwfl_after_mod[i],
+                          p2eNew),
+                 0L,
+                 "something wrong with assembly...? power-of-p aux");
+      } else {
+        // aux is not a power of p
+        // old message: m' mod p2r
+        // scaled message: aux*m' mod p2r (= pwfl_after_mod)
+        // modding up: aux*m' + [q]_p2r*I
+        // by setting stored intFactor to aux*[Q]_p2r:
+        //  m' + [q*aux^-1]_p2r*I
+        assertEq(NTL::rem(aux * modUpPwfl[i] - I_part_pwfl[i] * (q % p2r) -
+                              pwfl_after_mod[i],
+                          p2r),
+                 0L,
+                 "something wrong with assembly...? non-power-of-p aux");
+      }
+    }
+#endif
   }
 
 #ifdef HELIB_DEBUG
   if (dbgKey) {
-    checkRecryptBounds_v(v, dbgKey->getRecryptKey(), ctxt.getContext(), q);
-    checkCriticalValue(zzParts,
-                       dbgKey->getRecryptKey(),
-                       ctxt.getContext().getRcData(),
-                       q);
+    if (!newBtsFlag) {
+      checkRecryptBounds_v(v, dbgKey->getRecryptKey(), ctxt.getContext(), q);
+      checkCriticalValue(zzParts,
+                         dbgKey->getRecryptKey(),
+                         ctxt.getContext().getRcData(),
+                         q);
+    }
   }
 #endif
-
-  for (long i : range(zzParts.size())) {
-    zzParts[i] /= p2ePrime; // divide by p^{e'}
-  }
+  if (!newBtsFlag)
+    for (long i : range(zzParts.size())) {
+      zzParts[i] /= p2ePrime; // divide by p^{e'}
+    }
 
   // NOTE: here we lose the intFactor associated with ctxt.
   // We will restore it below.
   ctxt = recryptEkey;
 
-  ctxt.multByConstant(zzParts[1]);
-  ctxt.addConstant(zzParts[0]);
-
+  // XXX: debug variables
+  NTL::ZZX I_poly_new;
+  NTL::vec_ZZ I_poly_new_pwfl;
+  if (!newBtsFlag) {
+    ctxt.multByConstant(zzParts[1]);
+    ctxt.addConstant(zzParts[0]);
+    benchmarker.bits_after_inner_prod = ctxt.capacity();
+  } else {
+    // this is ok, ctxt still decrypts to I + aux*I'
+    // ctxt = modUpCtxt;
+    ctxt.multByConstant(I_part[1]);
+    ctxt.addConstant(I_part[0]);
+    benchmarker.bits_after_inner_prod = ctxt.capacity();
+#ifdef HELIB_DEBUG
+    // NOTE-debug: check ctxt here, see if it matches I_part
+    dbgKey->Decrypt(I_poly_new, ctxt);
+    p2d_conv.ZZXtoPowerful(I_poly_new_pwfl, I_poly_new);
+    vecRed(I_poly_new_pwfl, I_poly_new_pwfl, p2eNew, false);
+    for (long i = 0; i < phim; i++) {
+      assertTrue(bool(NTL::rem(I_poly_new_pwfl[i] - I_part_pwfl[i], aux) == 0),
+                 "something wrong with linear dec");
+    }
+#endif
+  }
 #ifdef HELIB_DEBUG
   CheckCtxt(ctxt, "after preProcess");
 #endif
   HELIB_NTIMER_STOP(AAA_preProcess);
 
+#ifdef HELIB_DEBUG
+  NTL::ZZX before_map;
+  NTL::vec_ZZ before_map_pwfl;
+  dbgKey->Decrypt(before_map, ctxt);
+  p2d_conv.ZZXtoPowerful(before_map_pwfl, before_map);
+  vecRed(before_map_pwfl, before_map_pwfl, p2eNew, false);
+#endif
+
   // Move the powerful-basis coefficients to the plaintext slots
   HELIB_NTIMER_START(AAA_LinearTransform1);
-  ctxt.getContext().getRcData().firstMap->apply(ctxt);
+  auto bits_down_linear1 = ctxt.capacity();
+  auto time_linear1_start = steady_clock::now();
+  if (!ctxt.getContext().getRcData().isPo2)
+    ctxt.getContext().getRcData().firstMap->apply(ctxt);
+  else
+    ctxt.getContext().getRcData().firstPo2Map->apply(ctxt);
+  auto time_linear1_end = steady_clock::now();
+  bits_down_linear1 -= ctxt.capacity();
   HELIB_NTIMER_STOP(AAA_LinearTransform1);
 
 #ifdef HELIB_DEBUG
@@ -519,11 +1123,17 @@ void PubKey::reCrypt(Ctxt& ctxt) const
 
   // Extract the digits e-e'+r-1,...,e-e' (from fully packed slots)
   HELIB_NTIMER_START(AAA_extractDigitsPacked);
-  extractDigitsPacked(ctxt,
+  // > well, this needs to be heavily modified...
+  // the case of new BTS is handled within the function, not here
+  // auto bits_down_extract = ctxt.capacity();
+  // auto time_extract_start = steady_clock::now();
+  auto subBench = extractDigitsPacked(ctxt,
                       e - ePrime,
                       r,
                       ePrime,
-                      context.getRcData().unpackSlotEncoding);
+                      context.getRcData().unpackSlotEncoding, false);
+  // auto time_extract_end = steady_clock::now();
+  // bits_down_extract -= ctxt.capacity();
   HELIB_NTIMER_STOP(AAA_extractDigitsPacked);
 
 #ifdef HELIB_DEBUG
@@ -532,126 +1142,822 @@ void PubKey::reCrypt(Ctxt& ctxt) const
 
   // Move the slots back to powerful-basis coefficients
   HELIB_NTIMER_START(AAA_LinearTransform2);
-  ctxt.getContext().getRcData().secondMap->apply(ctxt);
+  auto bits_down_linear2 = ctxt.capacity();
+  auto time_linear2_start = steady_clock::now();
+  if(!ctxt.getContext().getRcData().isPo2)
+    ctxt.getContext().getRcData().secondMap->apply(ctxt);
+  else
+    ctxt.getContext().getRcData().secondPo2Map->apply(ctxt);
+  auto time_linear2_end = steady_clock::now();
+  bits_down_linear2 -= ctxt.capacity();
   HELIB_NTIMER_STOP(AAA_LinearTransform2);
 
 #ifdef HELIB_DEBUG
   CheckCtxt(ctxt, "after linearTransform2");
+  NTL::ZZX after_map;
+  NTL::vec_ZZ after_map_pwfl;
+  if (newBtsFlag) {
+    dbgKey->Decrypt(after_map, ctxt);
+    p2d_conv.ZZXtoPowerful(after_map_pwfl, after_map);
+    vecRed(after_map_pwfl, after_map_pwfl, p2eNew, false);
+    for (long i = 0; i < phim; i++) {
+      assertEq(NTL::rem(before_map_pwfl[i] - after_map_pwfl[i], aux),
+               0L,
+               "ext step congruence failed");
+      assertEq(after_map_pwfl[i], I_part_pwfl[i], "ext step reduction failed");
+    }
+  }
 #endif
 
   // restore intFactor
-  if (intFactor != 1)
+  if (newBtsFlag) {
+#ifdef HELIB_DEBUG
+    { // XXX: debug, perform raw assemly
+      // input message
+      NTL::vec_ZZ input_pwfl;
+      p2d_conv.ZZXtoPowerful(input_pwfl, poly_input);
+      vecRed(input_pwfl, input_pwfl, p2r, false);
+      // modUp message = modUpPwfl
+      // afterMap message = after_map_pwfl
+      if (t > 0) {
+        for (long i = 0; i < phim; i++) {
+          // NTL::ZZ p2eNewZZ(p2eNew);
+          long tmp = NTL::rem(after_map_pwfl[i], p2eNew);
+          tmp = NTL::MulMod(q % p2eNew, tmp, p2eNew);
+          tmp = NTL::SubMod(NTL::rem(modUpPwfl[i], p2eNew), tmp, p2eNew);
+          assertEq(tmp % aux, 0L, "not divisible by aux?");
+          tmp /= aux;
+          tmp %= p2r;
+          long factorDiv = intFactor;
+          factorDiv = NTL::MulMod(factorDiv % p2r, q % p2r, p2r);
+          assertEq(tmp,
+                   NTL::MulMod(NTL::rem(input_pwfl[i], p2r), factorDiv, p2r),
+                   "not matching, p^t");
+        }
+      } else {
+        assertEq(p2eNew, p2r, "??????");
+        for (long i = 0; i < phim; i++) {
+          long tmp = NTL::rem(after_map_pwfl[i], p2r);
+          long mul_fac = NTL::MulMod(q % p2r, NTL::InvMod(aux % p2r, p2r), p2r);
+          tmp = NTL::MulMod(tmp, mul_fac, p2r);
+          tmp = NTL::SubMod(NTL::rem(modUpPwfl[i], p2r), tmp, p2r);
+
+          long factorDiv = intFactor;
+          factorDiv = NTL::MulMod(factorDiv % p2r, q % p2r, p2r);
+          assertEq(tmp,
+                   NTL::MulMod(NTL::rem(input_pwfl[i], p2r), factorDiv, p2r),
+                   "not matching, delta_0");
+        }
+      }
+    }
+#endif
+    // > assemble the ctxts and adjust the intFactors
+    // after modding-up, the message encrypted becomes
+    //  m + [q]_P*I, P = p^eNew, for power-of-p aux
+    //  m + [q*aux^-1]_P*I, P = p^r, for non-power-of-p aux
+
+    long adjust_factor = q % p2eNew;
+    if (t < 0)
+      adjust_factor = NTL::MulMod(q % p2r, NTL::InvMod(aux % p2r, p2r), p2r);
+    ctxt *= adjust_factor;
+    ctxt -= modUpCtxt;
+    ctxt.negate(); // modUpCtxt - ctxt = Enc(m)
+    // remove the extra p^t, if any
+    for (long i = 0; i < t; i++)
+      ctxt.divideByP();
+    // now correct the intFactor
+    // NOTE: for old bts, since q=p^e+1, [q]_p^r==1
+    ctxt.intFactor =
+        NTL::MulMod(ctxt.intFactor,
+                    NTL::MulMod(intFactor, q % ptxtSpace, ptxtSpace),
+                    ptxtSpace);
+  } else if (intFactor != 1)
     ctxt.intFactor = NTL::MulMod(ctxt.intFactor, intFactor, ptxtSpace);
+  auto time_boot_end = steady_clock::now();
+  // benchmarker.bits_down_extract = bits_down_extract;
+  benchmarker.bits_down_linear_1 = bits_down_linear1;
+  benchmarker.bits_down_linear_2 = bits_down_linear2;
+  benchmarker.bits_final = ctxt.capacity();
+  benchmarker.time_linear_1 =
+      duration_cast<duration<double>>(time_linear1_end - time_linear1_start)
+          .count();
+  benchmarker.time_linear_2 =
+      duration_cast<duration<double>>(time_linear2_end - time_linear2_start)
+          .count();
+  // benchmarker.time_extract =
+  //     duration_cast<duration<double>>(time_extract_end - time_extract_start)
+  //         .count();
+  benchmarker.time_total =
+      duration_cast<duration<double>>(time_boot_end - time_boot_start).count();
+  benchmarker += subBench;
+  return benchmarker;
 }
 
-#ifdef HELIB_BOOT_THREADS
-
-// Extract digits from fully packed slots, multithreaded version
-void extractDigitsPacked(Ctxt& ctxt,
-                         long botHigh,
-                         long r,
-                         long ePrime,
-                         const std::vector<NTL::ZZX>& unpackSlotEncoding)
+// bootstrap a ciphertext to reduce noise
+BootBench PubKey::reCryptRefine(Ctxt& ctxt) const
 {
+  BootBench benchmarker;
+  auto time_boot_start = steady_clock::now();
   HELIB_TIMER_START;
 
-  // Step 1: unpack the slots of ctxt
-  HELIB_NTIMER_START(unpack);
-  ctxt.cleanUp();
+  // Some sanity checks for dummy ciphertext
+  long ptxtSpace = ctxt.getPtxtSpace();
+  if (ctxt.isEmpty())
+    return benchmarker;
+  if (ctxt.parts.size() == 1 && ctxt.parts[0].skHandle.isOne()) {
+    // Dummy encryption, just ensure that it is reduced mod p
+    NTL::ZZX poly = to_ZZX(ctxt.parts[0]);
+    for (long i = 0; i < poly.rep.length(); i++)
+      poly[i] = NTL::to_ZZ(rem(poly[i], ptxtSpace));
+    poly.normalize();
+    ctxt.DummyEncrypt(poly);
+    return benchmarker;
+  }
 
-  // Apply the d automorphisms and store them in scratch area
-  long d = ctxt.getContext().getOrdP();
+  // check that we have bootstrapping data
+  assertTrue(recryptKeyID >= 0l, "No bootstrapping data");
 
-  std::vector<Ctxt> unpacked(d, Ctxt(ZeroCtxtLike, ctxt));
-  { // explicit scope to force all temporaries to be released
-    std::vector<std::shared_ptr<DoubleCRT>> coeff_vector;
-    std::vector<double> coeff_vector_sz;
-    coeff_vector.resize(d);
-    coeff_vector_sz.resize(d);
+  long p = getContext().getP();
+  long r = getContext().getAlMod().getR();
+  long p2r = getContext().getAlMod().getPPowR();
 
-    HELIB_NTIMER_START(unpack1);
-    for (long i = 0; i < d; i++) {
-      coeff_vector[i] = std::make_shared<DoubleCRT>(unpackSlotEncoding[i],
-                                                    ctxt.getContext(),
-                                                    ctxt.getPrimeSet());
-      coeff_vector_sz[i] = NTL::conv<double>(
-          embeddingLargestCoeff(unpackSlotEncoding[i],
-                                ctxt.getContext().getZMStar()));
-    }
-    HELIB_NTIMER_STOP(unpack1);
+  long intFactor = ctxt.intFactor;
 
-    HELIB_NTIMER_START(unpack2);
-    std::vector<Ctxt> frob(d, Ctxt(ZeroCtxtLike, ctxt));
+  // the bootstrapping key is encrypted relative to plaintext space p^{e-e'+r}.
+  const RecryptData& rcData = getContext().getRcData();
+  long e = rcData.e;
+  long ePrime = rcData.ePrime;
+  long p2ePrime = NTL::power_long(p, ePrime);
+  long q = NTL::power_long(p, e) + 1;
+  // new bts
+  // TODO: remove the duplicate members in rcData to avoid possible mistakes?
+  long eNew = rcData.eNew;
+  long t = rcData.t;
+  // long aux = context.getAux();
+  long p2eNew = NTL::power_long(p, eNew);
+  bool newBtsFlag = context.getNewBTSFlag();
+  bool newKSFlag = context.getNewKSFlag();
+  bool s2cFirstFlag = context.getS2CFirstFlag();
+
+  assertTrue(t > 0, "fat bts without I applies only to Delta=p^t");
+  assertTrue(newBtsFlag, "recryptRefine expects new bts flag");
+  if (!newBtsFlag)
+    assertTrue(e >= r, "rcData.e must be at least alMod.r");
+  if (newBtsFlag)
+    q = context.ithPrime(context.getIndexQks());
 
-    NTL_EXEC_RANGE(d, first, last)
-    // FIXME: implement using hoisting!
-    for (long j = first; j < last; j++) { // process jth Frobenius
-      frob[j] = ctxt;
-      frob[j].frobeniusAutomorph(j);
-      frob[j].cleanUp();
-      // FIXME: not clear if we should call cleanUp here
-    }
-    NTL_EXEC_RANGE_END
+#ifdef HELIB_DEBUG
+  std::cerr << "reCrypt: p=" << p << ", r=" << r << ", e=" << e
+            << " ePrime=" << ePrime << ", q=" << q << std::endl;
+  CheckCtxt(ctxt, "init");
+#endif
 
-    HELIB_NTIMER_STOP(unpack2);
+  // can only bootstrap ciphertext with plaintext-space dividing p^r
+  assertEq(p2r % ptxtSpace, 0l, "ptxtSpace must divide p^r when bootstrapping");
 
-    HELIB_NTIMER_START(unpack3);
-    Ctxt tmp1(ZeroCtxtLike, ctxt);
-    for (long i = 0; i < d; i++) {
-      for (long j = 0; j < d; j++) {
-        tmp1 = frob[j];
-        tmp1.multByConstant(*coeff_vector[mcMod(i + j, d)],
-                            coeff_vector_sz[mcMod(i + j, d)]);
-        unpacked[i] += tmp1;
-      }
-    }
-    HELIB_NTIMER_STOP(unpack3);
-  }
-  HELIB_NTIMER_STOP(unpack);
+#ifdef HELIB_DEBUG
+  NTL::ZZX poly_input;
+  dbgKey->Decrypt(poly_input, ctxt);
+#endif
 
-  //#ifdef HELIB_DEBUG
-  //  CheckCtxt(unpacked[0], "after unpack");
-  //#endif
+  ctxt.dropSmallAndSpecialPrimes();
 
-  NTL_EXEC_RANGE(d, first, last)
-  for (long i = first; i < last; i++) {
-    extractDigitsThin(unpacked[i], botHigh, r, ePrime);
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after drop small and special primes");
+#endif
+
+  // XXX: firstMap = CoeffToSlot = linear1
+  //  secondMap = SlotToCoeff = linear2
+  //  even with s2cFirst = true
+  steady_clock::time_point time_linear1_start, time_linear1_end,
+  time_linear2_start, time_linear2_end;
+  double bits_down_linear1 = 0, bits_down_linear2 = 0;
+
+  if (s2cFirstFlag) {
+#define DROP_BEFORE_FAT_RECRYPT
+#define FAT_RECRYPT_NLEVELS (3)
+#ifdef DROP_BEFORE_FAT_RECRYPT
+  // experimental code...we should drop down to a reasonably low level
+  // before doing the first linear map.
+  long first = context.getCtxtPrimes().first();
+  long last = std::min(context.getCtxtPrimes().last(),
+                       first + FAT_RECRYPT_NLEVELS - 1);
+  ctxt.bringToSet(IndexSet(first, last));
+  // SlotToCoeff
+HELIB_NTIMER_START(AAA_slotToCoeff);
+  bits_down_linear2 = ctxt.capacity();
+  time_linear2_start = steady_clock::now();
+  // XXX: second map is SlotToCoeff
+  if (!rcData.isPo2)
+    rcData.secondMap->apply(ctxt); 
+  else
+    rcData.secondPo2Map->apply(ctxt);
+  time_linear2_end = steady_clock::now();
+  bits_down_linear2 -= ctxt.capacity();
+HELIB_NTIMER_STOP(AAA_slotToCoeff);
+#endif
   }
-  NTL_EXEC_RANGE_END
 
-  //#ifdef HELIB_DEBUG
-  // CheckCtxt(unpacked[0], "before repack");
-  //#endif
 
-  // Step 3: re-pack the slots
-  HELIB_NTIMER_START(repack);
-  const EncryptedArray& ea2 = ctxt.getContext().getEA();
-  NTL::ZZX xInSlots;
-  std::vector<NTL::ZZX> xVec(ea2.size());
-  ctxt = unpacked[0];
-  for (long i = 1; i < d; i++) {
-    x2iInSlots(xInSlots, i, xVec, ea2);
-    unpacked[i].multByConstant(xInSlots);
-    ctxt += unpacked[i];
+  HELIB_NTIMER_START(AAA_preProcess);
+
+  // Make sure that this ciphertext is in canonical form
+  if (!ctxt.inCanonicalForm())
+    ctxt.reLinearize();
+
+  // Mod-switch down if needed
+  IndexSet s = ctxt.getPrimeSet() / context.getSpecialPrimes();
+  assertTrue(s <= context.getCtxtPrimes(), "prime set is messed up");
+  if (newKSFlag) { // since the decomposition is independent of the RNS
+                   // representation, we do not need to keep 3 primes
+    s.clear();
+    s.insert(context.getIndexQks());
+    ctxt.bringToSet(s);
+    // TODO: check the error bound of ctxt and warn on large noise?
+    //  the budget in ctxt should be larger than the budget in the
+    //  assumed-post-ms-pre-ks-ctxt (whose noise bound is beta) by one or two
+    //  bits
+  } else {
+    if (s.card() > 3) { // leave only first three ciphertext primes
+      long first = s.first();
+      IndexSet s3(first, first + 2);
+      s.retain(s3);
+    }
+    ctxt.modDownToSet(s);
   }
-  HELIB_NTIMER_STOP(repack);
-  //#ifdef HELIB_DEBUG
-  // CheckCtxt(ctxt, "after repack");
-  //#endif
-}
 
-#else
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after mod down to KS modulus");
 
-// Extract digits from fully packed slots
-void extractDigitsPacked(Ctxt& ctxt,
+  NTL::ZZX poly_before;
+  dbgKey->Decrypt(poly_before, ctxt);
+  assertEq(poly_input, poly_before, "something wrong with mod-down");
+#endif
+
+  // key-switch to the bootstrapping key
+  // > this is problematic... because the qKS will be dropped by
+  // dropSmallAndSpecialPrimes
+  // also, the decomposition algorithm needs to change
+  ctxt.reLinearize(recryptKeyID, newKSFlag);
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after key switching");
+
+  NTL::ZZX poly_after;
+  dbgKey->Decrypt(poly_after, ctxt);
+  assertEq(poly_before, poly_after, "something wrong with key switching");
+#endif
+
+  // "raw mod-switch" to the bootstrapping modulus q=p^e+1.
+  std::vector<NTL::ZZX> zzParts; // the mod-switched parts, in ZZX format
+
+  double mfac = ctxt.getContext().getZMStar().getNormBnd();
+  // NOTE: rawModSwitch assumes the current ctxt modulus is coprime to q
+  // however, this is not the case for the new bootstrap,
+  // where ctxt modulus is qKS * R, while q = qKS
+  double noise_est;
+  if (newBtsFlag)
+    noise_est = ctxt.rawModSwitchNew(zzParts, q) * mfac; // q = qKS
+  else
+    noise_est = ctxt.rawModSwitch(zzParts, q) * mfac; // q = p^e+1
+  // noise_est is an upper bound on the L-infty norm of the scaled noise
+  // in the pwrfl basis
+  long phim = context.getZMStar().getPhiM();
+  double beta =
+      p2r * (context.getScale() * sqrt(double(phim) / 12.0) *
+                 (sqrt(double(context.getHwt()) * log(double(phim))) + 1) +
+             0.5);
+  double noise_bnd = newBtsFlag ? 2 * beta * mfac
+                                : HELIB_MIN_CAP_FRAC * p2r *
+                                      ctxt.getContext().boundForRecryption();
+  // noise_bnd is the bound assumed in selecting the parameters
+  double noise_rat = noise_est / noise_bnd;
+
+  HELIB_STATS_UPDATE("raw-mod-switch-noise", noise_rat);
+
+  if (noise_rat > 1) {
+    // TODO: Turn the following preprocessor logics into a warnOrThrow function
+    std::string message =
+        "rawModSwitch scaled noise exceeds bound: " + std::to_string(noise_rat);
+#ifdef HELIB_DEBUG
+    Warning(message);
+#else
+    throw LogicError(message);
+#endif
+  }
+
+  assertEq(zzParts.size(),
+           (std::size_t)2,
+           "Exactly 2 parts required for mod-switching in thin bootstrapping");
+
+#ifdef HELIB_DEBUG
+  const PowerfulDCRT& p2d_conv = *rcData.p2dConv;
+  if (dbgKey && !newBtsFlag) {
+    checkRecryptBounds(zzParts, dbgKey->getRecryptKey(), ctxt.getContext(), q);
+  }
+  // after raw mod-swtich, poly_after has a stored intFactor of
+  // `intFactor`, and an implied intFactor of `intFactor * [q]_p2r`
+  NTL::ZZX poly_after_rawmod;
+  NTL::vec_ZZ pwfl_after_rawmod;
+  if (newBtsFlag) { // NOTE: this is pure debug
+    rawDecrypt(poly_after_rawmod, zzParts, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(pwfl_after_rawmod, poly_after_rawmod);
+    vecRed(pwfl_after_rawmod, pwfl_after_rawmod, q, false);
+    p2d_conv.powerfulToZZX(poly_after_rawmod, pwfl_after_rawmod);
+    // and may output incorrect results for out-of-range inputs
+    long impliedIntFactor = NTL::MulMod(intFactor, q % p2r, p2r);
+    long invImplied = NTL::InvMod(impliedIntFactor, p2r);
+    // set abs=True to be consistent with the Decryption function
+    poly_after_rawmod = helib::MulMod(poly_after_rawmod, invImplied, p2r, true);
+    assertEq(poly_after,
+             poly_after_rawmod,
+             "something wrong with raw modswitch");
+  }
+#endif
+
+  std::vector<NTL::ZZX> v;
+  v.resize(2);
+
+  // this ctxt will be
+  //  (a) modulus switched down to the ctxtPrimes (b) key-switched to
+  //  the normal sk (c) substracted by the digit extraction results
+  Ctxt modUpCtxt(ctxt.getPubKey(), p2eNew);
+  std::vector<NTL::ZZX> I_part;
+
+  // the debug polys
+  NTL::ZZX poly_before_mod;
+  NTL::vec_ZZ pwfl_before_mod;
+  NTL::ZZX poly_after_mod, I_poly;
+  NTL::vec_ZZ pwfl_after_mod, pwfl_diff;
+  NTL::ZZX modUpPoly;
+  NTL::vec_ZZ modUpPwfl, I_part_pwfl;
+  if (!newBtsFlag)
+    // Add multiples of q to make the zzParts divisible by p^{e'}
+    for (long i : range(2)) {
+      // make divisible by p^{e'}
+      newMakeDivisible(zzParts[i], p2ePrime, q, ctxt.getContext(), v[i]);
+    }
+  else {
+    // XXX: modding up or down & relin should not affect the stored intFactor...
+    assertTrue(intFactor == ctxt.intFactor, "why the intFactors do not match?");
+
+#ifdef HELIB_DEBUG
+    rawDecrypt(poly_before_mod, zzParts, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(pwfl_before_mod, poly_before_mod);
+    vecRed(pwfl_before_mod, pwfl_before_mod, q, false);
+    double largePwflBefore = NTL::conv<double>(largestCoeff(pwfl_before_mod));
+    printf("pwfl capacity before = %f\n",
+           log(double(q) / 2.0 / largePwflBefore / double(aux)) / log(2.0));
+    assertTrue(largePwflBefore * aux < double(q) / 2.0,
+               "not enough capacity before scaleUp");
+#endif
+
+    // > (1) mult by aux,
+    // (2) extract the overflow part, and store them as ZZXs -> feed into digit
+    // extraction (3) mod-up the ctxt after mult to the highest modulus (with an
+    // extra prime modulus) note that the mod-up ctxt decrypts w.r.t. encapSk
+    multAndGetOverflowPart(zzParts, I_part, ctxt.getContext());
+
+#ifdef HELIB_DEBUG
+    rawDecrypt(poly_after_mod, zzParts, dbgKey->getRecryptKey());
+    // check the overflow part
+    rawDecrypt(I_poly, I_part, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(I_part_pwfl, I_poly);
+    vecRed(I_part_pwfl, I_part_pwfl, aux, false);
+    p2d_conv.powerfulToZZX(I_poly, I_part_pwfl);
+
+    p2d_conv.ZZXtoPowerful(pwfl_diff, poly_after_mod - I_poly * q);
+    // vecRed(pwfl_diff, pwfl_diff, NTL::ZZ(aux) * NTL::ZZ(q), false);
+    for (long i = 0; i < phim; i++) {
+      assertTrue(bool(NTL::abs(pwfl_diff[i]) <= (q / 2)),
+                 "overflow part wrong?");
+    }
+    // assertTrue(NTL::to_long(largestCoeff(pwfl_diff)) <= (q / 2),
+    //            "overflow part wrong?");
+    // check the relationship between pwfl_before_mod and pwfl_after_mod
+    // now check if the bound on I is valid
+    p2d_conv.ZZXtoPowerful(pwfl_after_mod, poly_after_mod);
+    NTL::xdouble actualBoundI =
+        NTL::conv<NTL::xdouble>(largestCoeff(pwfl_after_mod)) / NTL::xdouble(q);
+    std::cerr << "actual bound on I is " << actualBoundI << "\n";
+    assertTrue(
+        bool(NTL::floor(actualBoundI) <= ceil(context.boundForRecryption())),
+        "bound on I exceeded");
+    vecRed(pwfl_after_mod, pwfl_after_mod, q, false);
+    if (t < 0) {
+      for (long i = 0; i < phim; i++) {
+        long before = NTL::rem(pwfl_before_mod[i], p2r);
+        before = NTL::MulMod(before, aux % p2r, p2r);
+        long after = NTL::rem(pwfl_after_mod[i], p2r);
+        assertEq(before,
+                 after,
+                 "something wrong with upscaling, non-power-of-p aux");
+      }
+    } else {
+      for (long i = 0; i < phim; i++) {
+        long before = NTL::rem(pwfl_before_mod[i], p2r);
+        long after = NTL::rem(pwfl_after_mod[i], p2eNew);
+        assertEq(before * aux,
+                 after,
+                 "something wrong with upscaling, power-of-p aux");
+      }
+    }
+#endif
+
+    // now handle the mod-up ctxt
+    modUpCtxt.ptxtSpace = p2eNew;
+    modUpCtxt.primeSet = context.getCtxtPrimes() | context.getModUpPrimes();
+    long QmodP = 1;
+    // be careful with single-precision modular arithmetic...
+    for (auto i : modUpCtxt.primeSet)
+      QmodP = NTL::MulMod(QmodP, context.ithPrime(i) % p2eNew, p2eNew);
+    // we pretend the IMPLIED INTFACTOR of m* mod P is 1
+    // (i.e., zzParts after raw-ms decrypts to m*)
+    // which is actually intFactor * [q]_{p^r}
+    // we want the mult-by-aux and modded-up ctxt to have
+    // an implied intfactor of aux (decrypts to m*+...)
+    // aux = p^t, stored intFactor = [Q^-1]_P
+    modUpCtxt.intFactor = NTL::InvMod(QmodP, p2eNew);
+    // divide by [q]_p2eNew, so that the encrypted value is I+[q]^-1_{p2eNew}*p^t*m'
+    modUpCtxt.intFactor = NTL::MulMod(modUpCtxt.intFactor, q % p2eNew, p2eNew);
+    modUpCtxt.noiseBound = context.boundForRecryption() * q;
+    for (int i = 0; i < 2; i++)
+      modUpCtxt.addPart(DoubleCRT(zzParts[i], context, modUpCtxt.primeSet),
+                        ctxt.parts[i].skHandle);
+    // discard the mod-up primes
+    modUpCtxt.modDownToSet(context.getCtxtPrimes());
+
+    // switch to the normal sk (keyID = 0)
+    modUpCtxt.reLinearize();
+
+#ifdef HELIB_DEBUG
+    dbgKey->Decrypt(modUpPoly, modUpCtxt);
+    p2d_conv.ZZXtoPowerful(modUpPwfl, modUpPoly);
+    vecRed(modUpPwfl, modUpPwfl, p2eNew, false);
+    p2d_conv.ZZXtoPowerful(I_part_pwfl, I_poly);
+    vecRed(I_part_pwfl, I_part_pwfl, aux, false);
+
+    p2d_conv.ZZXtoPowerful(pwfl_after_mod, poly_after_mod);
+    vecRed(pwfl_after_mod, pwfl_after_mod, q, false);
+
+    // for aux = p^t
+    // the message in zzParts befure "multAndGetOverflowPart" is m' mod p2r
+    // after that, the scaled message becomes p^t*m' mod p2eNew
+    // by modding up, the message becomes p^t*m' + [q]_p2eNew*I
+    // setting the modUpCtxt.intFactor = [Q^-1]_p2eNew ensures
+    // modUpCtxt decrypts to p^t*m' + [q]_p2eNew*I
+    for (long i = 0; i < phim; i++) {
+      if (t > 0) {
+        assertEq(NTL::rem(modUpPwfl[i] - I_part_pwfl[i] * (q % p2eNew) -
+                              pwfl_after_mod[i],
+                          p2eNew),
+                 0L,
+                 "something wrong with assembly...? power-of-p aux");
+      } else {
+        // aux is not a power of p
+        // old message: m' mod p2r
+        // scaled message: aux*m' mod p2r (= pwfl_after_mod)
+        // modding up: aux*m' + [q]_p2r*I
+        // by setting stored intFactor to aux*[Q]_p2r:
+        //  m' + [q*aux^-1]_p2r*I
+        assertEq(NTL::rem(aux * modUpPwfl[i] - I_part_pwfl[i] * (q % p2r) -
+                              pwfl_after_mod[i],
+                          p2r),
+                 0L,
+                 "something wrong with assembly...? non-power-of-p aux");
+      }
+    }
+#endif
+  }
+
+#ifdef HELIB_DEBUG
+  if (dbgKey) {
+    if (!newBtsFlag) {
+      checkRecryptBounds_v(v, dbgKey->getRecryptKey(), ctxt.getContext(), q);
+      checkCriticalValue(zzParts,
+                         dbgKey->getRecryptKey(),
+                         ctxt.getContext().getRcData(),
+                         q);
+    }
+  }
+#endif
+  if (!newBtsFlag)
+    for (long i : range(zzParts.size())) {
+      zzParts[i] /= p2ePrime; // divide by p^{e'}
+    }
+
+  // NOTE: here we lose the intFactor associated with ctxt.
+  // We will restore it below.
+  ctxt = recryptEkey;
+
+  // XXX: debug variables
+  NTL::ZZX I_poly_new;
+  NTL::vec_ZZ I_poly_new_pwfl;
+  if (!newBtsFlag) {
+    ctxt.multByConstant(zzParts[1]);
+    ctxt.addConstant(zzParts[0]);
+    benchmarker.bits_after_inner_prod = ctxt.capacity();
+  } else {
+    // recryptRefine: execute digitRemoval on modUpCtxt directly to save some capacity during CoeffToSlot/SlotToCoeff
+    ctxt = modUpCtxt;
+    benchmarker.bits_after_inner_prod = ctxt.capacity();
+  }
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after preProcess");
+#endif
+  HELIB_NTIMER_STOP(AAA_preProcess);
+
+#ifdef HELIB_DEBUG
+  NTL::ZZX before_map;
+  NTL::vec_ZZ before_map_pwfl;
+  dbgKey->Decrypt(before_map, ctxt);
+  p2d_conv.ZZXtoPowerful(before_map_pwfl, before_map);
+  vecRed(before_map_pwfl, before_map_pwfl, p2eNew, false);
+#endif
+
+  // CoeffToSlot is always between dec-simplify and digit-removal
+  HELIB_NTIMER_START(AAA_LinearTransform1);
+  bits_down_linear1 = ctxt.capacity();
+  time_linear1_start = steady_clock::now();
+  if (!rcData.isPo2)
+    rcData.firstMap->apply(ctxt);
+  else
+    rcData.firstPo2Map->apply(ctxt);
+  time_linear1_end = steady_clock::now();
+  bits_down_linear1 -= ctxt.capacity();
+  HELIB_NTIMER_STOP(AAA_LinearTransform1);
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after LinearTransform1");
+#endif
+
+  // Extract the digits e-e'+r-1,...,e-e' (from fully packed slots)
+  HELIB_NTIMER_START(AAA_extractDigitsPacked);
+  // > well, this needs to be heavily modified...
+  // the case of new BTS is handled within the function, not here
+  // auto bits_down_extract = ctxt.capacity();
+  // auto time_extract_start = steady_clock::now();
+  auto subBench = extractDigitsPacked(ctxt,
+                      e - ePrime,
+                      r,
+                      ePrime,
+                      context.getRcData().unpackSlotEncoding, true);
+  // auto time_extract_end = steady_clock::now();
+  // bits_down_extract -= ctxt.capacity();
+  HELIB_NTIMER_STOP(AAA_extractDigitsPacked);
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after extractDigitsPacked");
+#endif
+
+  if (!s2cFirstFlag) {
+    // Move the slots back to powerful-basis coefficients
+    HELIB_NTIMER_START(AAA_LinearTransform2);
+    bits_down_linear2 = ctxt.capacity();
+    time_linear2_start = steady_clock::now();
+    if(!rcData.isPo2)
+      rcData.secondMap->apply(ctxt);
+    else
+      rcData.secondPo2Map->apply(ctxt);
+    time_linear2_end = steady_clock::now();
+    bits_down_linear2 -= ctxt.capacity();
+    HELIB_NTIMER_STOP(AAA_LinearTransform2);
+  }
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after linearTransform2");
+  NTL::ZZX after_map;
+  NTL::vec_ZZ after_map_pwfl;
+  if (newBtsFlag) {
+    dbgKey->Decrypt(after_map, ctxt);
+    p2d_conv.ZZXtoPowerful(after_map_pwfl, after_map);
+    vecRed(after_map_pwfl, after_map_pwfl, p2eNew, false);
+    for (long i = 0; i < phim; i++) {
+      assertEq(NTL::rem(before_map_pwfl[i] - after_map_pwfl[i], aux),
+               0L,
+               "ext step congruence failed");
+      assertEq(after_map_pwfl[i], I_part_pwfl[i], "ext step reduction failed");
+    }
+  }
+#endif
+
+  // restore intFactor
+  if (newBtsFlag) {
+#ifdef HELIB_DEBUG
+    { // XXX: debug, perform raw assemly
+      // input message
+      NTL::vec_ZZ input_pwfl;
+      p2d_conv.ZZXtoPowerful(input_pwfl, poly_input);
+      vecRed(input_pwfl, input_pwfl, p2r, false);
+      // modUp message = modUpPwfl
+      // afterMap message = after_map_pwfl
+      if (t > 0) {
+        for (long i = 0; i < phim; i++) {
+          // NTL::ZZ p2eNewZZ(p2eNew);
+          long tmp = NTL::rem(after_map_pwfl[i], p2eNew);
+          tmp = NTL::MulMod(q % p2eNew, tmp, p2eNew);
+          tmp = NTL::SubMod(NTL::rem(modUpPwfl[i], p2eNew), tmp, p2eNew);
+          assertEq(tmp % aux, 0L, "not divisible by aux?");
+          tmp /= aux;
+          tmp %= p2r;
+          long factorDiv = intFactor;
+          factorDiv = NTL::MulMod(factorDiv % p2r, q % p2r, p2r);
+          assertEq(tmp,
+                   NTL::MulMod(NTL::rem(input_pwfl[i], p2r), factorDiv, p2r),
+                   "not matching, p^t");
+        }
+      } else {
+        assertEq(p2eNew, p2r, "??????");
+        for (long i = 0; i < phim; i++) {
+          long tmp = NTL::rem(after_map_pwfl[i], p2r);
+          long mul_fac = NTL::MulMod(q % p2r, NTL::InvMod(aux % p2r, p2r), p2r);
+          tmp = NTL::MulMod(tmp, mul_fac, p2r);
+          tmp = NTL::SubMod(NTL::rem(modUpPwfl[i], p2r), tmp, p2r);
+
+          long factorDiv = intFactor;
+          factorDiv = NTL::MulMod(factorDiv % p2r, q % p2r, p2r);
+          assertEq(tmp,
+                   NTL::MulMod(NTL::rem(input_pwfl[i], p2r), factorDiv, p2r),
+                   "not matching, delta_0");
+        }
+      }
+    }
+#endif
+    // now the ctxt encrypts [q]^-1_p2r*m' mod p2r (see the construction of modUpCtxt)
+    ctxt *= q % p2r;
+    // now correct the intFactor
+    // multiply the current stored-intFactor by the old implied-intFactor
+    ctxt.intFactor =
+        NTL::MulMod(ctxt.intFactor,
+                    NTL::MulMod(intFactor, q % ptxtSpace, ptxtSpace),
+                    ptxtSpace);
+  } else if (intFactor != 1)
+    ctxt.intFactor = NTL::MulMod(ctxt.intFactor, intFactor, ptxtSpace);
+  auto time_boot_end = steady_clock::now();
+  // benchmarker.bits_down_extract = bits_down_extract;
+  benchmarker.bits_down_linear_1 = bits_down_linear1;
+  benchmarker.bits_down_linear_2 = bits_down_linear2;
+  benchmarker.bits_final = ctxt.capacity();
+  benchmarker.time_linear_1 =
+      duration_cast<duration<double>>(time_linear1_end - time_linear1_start)
+          .count();
+  benchmarker.time_linear_2 =
+      duration_cast<duration<double>>(time_linear2_end - time_linear2_start)
+          .count();
+  // benchmarker.time_extract =
+  //     duration_cast<duration<double>>(time_extract_end - time_extract_start)
+  //         .count();
+  benchmarker.time_total =
+      duration_cast<duration<double>>(time_boot_end - time_boot_start).count();
+  benchmarker += subBench;
+  return benchmarker;
+}
+
+#ifdef HELIB_BOOT_THREADS
+
+// Extract digits from fully packed slots, multithreaded version
+// NOTE: this is invoked if HELIB_BOOT_THREADS is defined
+BootBench extractDigitsPacked(Ctxt& ctxt,
+                         long botHigh,
+                         long r,
+                         long ePrime,
+                         const std::vector<NTL::ZZX>& unpackSlotEncoding,
+                         bool thinRefine)
+{
+  helib::BootBench benchmarker;
+  HELIB_TIMER_START;
+
+  // Step 1: unpack the slots of ctxt
+  auto time_unpack_start = steady_clock::now();
+  double cap_unpack_before = ctxt.capacity();
+  HELIB_NTIMER_START(unpack);
+  ctxt.cleanUp();
+
+  // Apply the d automorphisms and store them in scratch area
+  long d = ctxt.getContext().getOrdP();
+
+  std::vector<Ctxt> unpacked(d, Ctxt(ZeroCtxtLike, ctxt));
+  { // explicit scope to force all temporaries to be released
+    std::vector<std::shared_ptr<DoubleCRT>> coeff_vector;
+    std::vector<double> coeff_vector_sz;
+    coeff_vector.resize(d);
+    coeff_vector_sz.resize(d);
+
+    HELIB_NTIMER_START(unpack1);
+    for (long i = 0; i < d; i++) {
+      coeff_vector[i] = std::make_shared<DoubleCRT>(unpackSlotEncoding[i],
+                                                    ctxt.getContext(),
+                                                    ctxt.getPrimeSet());
+      coeff_vector_sz[i] = NTL::conv<double>(
+          embeddingLargestCoeff(unpackSlotEncoding[i],
+                                ctxt.getContext().getZMStar()));
+    }
+    HELIB_NTIMER_STOP(unpack1);
+
+    HELIB_NTIMER_START(unpack2);
+    std::vector<Ctxt> frob(d, Ctxt(ZeroCtxtLike, ctxt));
+
+    NTL_EXEC_RANGE(d, first, last)
+    // FIXME: implement using hoisting!
+    for (long j = first; j < last; j++) { // process jth Frobenius
+      frob[j] = ctxt;
+      frob[j].frobeniusAutomorph(j);
+      frob[j].cleanUp();
+      // FIXME: not clear if we should call cleanUp here
+    }
+    NTL_EXEC_RANGE_END
+
+    HELIB_NTIMER_STOP(unpack2);
+
+    HELIB_NTIMER_START(unpack3);
+    Ctxt tmp1(ZeroCtxtLike, ctxt);
+    for (long i = 0; i < d; i++) {
+      for (long j = 0; j < d; j++) {
+        tmp1 = frob[j];
+        tmp1.multByConstant(*coeff_vector[mcMod(i + j, d)],
+                            coeff_vector_sz[mcMod(i + j, d)]);
+        unpacked[i] += tmp1;
+      }
+    }
+    HELIB_NTIMER_STOP(unpack3);
+  }
+  HELIB_NTIMER_STOP(unpack);
+  auto time_unpack_end = steady_clock::now();
+  double cap_unpack_after = cap_unpack_before;
+  for (long i = 0; i < d; i++)
+    cap_unpack_after = std::min(cap_unpack_after, unpacked[i].capacity());
+
+  // #ifdef HELIB_DEBUG
+  //   CheckCtxt(unpacked[0], "after unpack");
+  // #endif
+
+  double cap_ext_before = cap_unpack_after;
+  auto time_ext_start = steady_clock::now();
+  NTL_EXEC_RANGE(d, first, last)
+  for (long i = first; i < last; i++) {
+    extractDigitsThin(unpacked[i], botHigh, r, ePrime, thinRefine);
+  }
+  NTL_EXEC_RANGE_END
+  auto time_ext_end = steady_clock::now();
+  double cap_ext_after = cap_ext_before;
+  for(long i = 0; i < d; i++)
+    cap_ext_after = std::min(cap_ext_after, unpacked[i].capacity());
+
+  // Step 3: re-pack the slots
+  double cap_repack_before = cap_ext_after;
+  auto time_repack_start = steady_clock::now();
+  HELIB_NTIMER_START(repack);
+  const EncryptedArray& ea2 = !thinRefine ? *ctxt.getContext().getRcData().ea
+                                         : ctxt.getContext().getEA();
+  NTL::ZZX xInSlots;
+  std::vector<NTL::ZZX> xVec(ea2.size());
+  ctxt = unpacked[0];
+  for (long i = 1; i < d; i++) {
+    x2iInSlots(xInSlots, i, xVec, ea2);
+    unpacked[i].multByConstant(xInSlots);
+    ctxt += unpacked[i];
+  }
+  HELIB_NTIMER_STOP(repack);
+  auto time_repack_end = steady_clock::now();
+  double cap_repack_after = ctxt.capacity();
+  // #ifdef HELIB_DEBUG
+  //  CheckCtxt(ctxt, "after repack");
+  // #endif
+  benchmarker.time_linear_1 = duration_cast<duration<double>>(time_unpack_end - time_unpack_start).count();
+  benchmarker.time_linear_2 = duration_cast<duration<double>>(time_repack_end - time_repack_start).count();
+  benchmarker.time_extract = duration_cast<duration<double>>(time_ext_end - time_ext_start).count();
+  benchmarker.bits_down_linear_1 = cap_unpack_before - cap_unpack_after;
+  benchmarker.bits_down_linear_2 = cap_repack_before - cap_repack_after;
+  benchmarker.bits_down_extract = cap_ext_before - cap_ext_after;
+  // XXX: including the time&capacity consumption of unpack/pack
+  //  into linear1/linear2 may cause trouble
+  //  when calculating the performance of thinBts or s2cFirst fatBts
+  //  They are now all counted into digit removal
+  benchmarker.time_linear_1 = benchmarker.time_linear_2 = 0;
+  benchmarker.bits_down_linear_1 = benchmarker.bits_down_linear_2 = 0;
+  benchmarker.time_extract = duration_cast<duration<double>>(time_repack_end - time_unpack_start).count();
+  benchmarker.bits_down_extract = cap_unpack_before - cap_repack_after;
+  return benchmarker;
+}
+
+#else
+
+// Extract digits from fully packed slots
+// NOTE: this is invoked when HELIB_BOOT_THREADS is undefined
+// botHigh = e - e' is the number of digits to discard
+// r is the number of digits to keep
+BootBench extractDigitsPacked(Ctxt& ctxt,
                          long botHigh,
                          long r,
                          long ePrime,
-                         const std::vector<NTL::ZZX>& unpackSlotEncoding)
+                         const std::vector<NTL::ZZX>& unpackSlotEncoding,
+                         bool thinRefine)
 {
+  helib::BootBench benchmarker;
   HELIB_TIMER_START;
 
   // Step 1: unpack the slots of ctxt
+  auto time_unpack_start = steady_clock::now();
+  double cap_unpack_before = ctxt.capacity();
   HELIB_NTIMER_START(unpack);
   ctxt.cleanUp();
 
@@ -692,22 +1998,33 @@ void extractDigitsPacked(Ctxt& ctxt,
     }
   }
   HELIB_NTIMER_STOP(unpack);
+  auto time_unpack_end = steady_clock::now();
+  double cap_unpack_after = cap_unpack_before;
+  for (long i = 0; i < d; i++)
+    cap_unpack_after = std::min(cap_unpack_after, unpacked[i].capacity());
 
-  //#ifdef HELIB_DEBUG
-  //  CheckCtxt(unpacked[0], "after unpack");
-  //#endif
+  // #ifdef HELIB_DEBUG
+  //   CheckCtxt(unpacked[0], "after unpack");
+  // #endif
 
+  double cap_ext_before = cap_unpack_after;
+  auto time_ext_start = steady_clock::now();
   for (long i = 0; i < (long)unpacked.size(); i++) {
-    extractDigitsThin(unpacked[i], botHigh, r, ePrime);
+    extractDigitsThin(unpacked[i], botHigh, r, ePrime, thinRefine);
   }
-
-  //#ifdef HELIB_DEBUG
-  //  CheckCtxt(unpacked[0], "before repack");
-  //#endif
+  auto time_ext_end = steady_clock::now();
+  double cap_ext_after = cap_ext_before;
+  for(long i = 0; i < d; i++)
+    cap_ext_after = std::min(cap_ext_after, unpacked[i].capacity());
 
   // Step 3: re-pack the slots
+  double cap_repack_before = cap_ext_after;
+  auto time_repack_start = steady_clock::now();
   HELIB_NTIMER_START(repack);
-  const EncryptedArray& ea2 = ctxt.getContext().getEA();
+  // NOTE: for newbts with t < 0,
+  //  the repacking still works on ptxt modulus p2eNew, not p2r
+  const EncryptedArray& ea2 = !thinRefine ? *ctxt.getContext().getRcData().ea
+                                         : ctxt.getContext().getEA();
   NTL::ZZX xInSlots;
   std::vector<NTL::ZZX> xVec(ea2.size());
   ctxt = unpacked[0];
@@ -717,6 +2034,24 @@ void extractDigitsPacked(Ctxt& ctxt,
     ctxt += unpacked[i];
   }
   HELIB_NTIMER_STOP(repack);
+  auto time_repack_end = steady_clock::now();
+  double cap_repack_after = ctxt.capacity();
+
+  benchmarker.time_linear_1 = duration_cast<duration<double>>(time_unpack_end - time_unpack_start).count();
+  benchmarker.time_linear_2 = duration_cast<duration<double>>(time_repack_end - time_repack_start).count();
+  benchmarker.time_extract = duration_cast<duration<double>>(time_ext_end - time_ext_start).count();
+  benchmarker.bits_down_linear_1 = cap_unpack_before - cap_unpack_after;
+  benchmarker.bits_down_linear_2 = cap_repack_before - cap_repack_after;
+  benchmarker.bits_down_extract = cap_ext_before - cap_ext_after;
+  // XXX: including the time&capacity consumption of unpack/pack
+  //  into linear1/linear2 may cause trouble
+  //  when calculating the performance of thinBts or s2cFirst fatBts
+  //  They are now all counted into digit removal
+  benchmarker.time_linear_1 = benchmarker.time_linear_2 = 0;
+  benchmarker.bits_down_linear_1 = benchmarker.bits_down_linear_2 = 0;
+  benchmarker.time_extract = duration_cast<duration<double>>(time_repack_end - time_unpack_start).count();
+  benchmarker.bits_down_extract = cap_unpack_before - cap_repack_after;
+  return benchmarker;
 }
 
 #endif
@@ -776,21 +2111,40 @@ void ThinRecryptData::init(const Context& context,
                            bool build_cache_,
                            bool minimal)
 {
+  assertTrue(!context.getDummy() || !alsoThick, "dummy -> thin");
   RecryptData::init(context, mvec_, alsoThick, build_cache_, minimal);
-  coeffToSlot =
-      std::make_shared<ThinEvalMap>(*ea, minimal, mvec, true, build_cache);
-  slotToCoeff = std::make_shared<ThinEvalMap>(context.getEA(),
-                                              minimal,
-                                              mvec,
-                                              false,
-                                              build_cache);
+  // NOTE: compute thin linear transform only when thick bts is disabled
+  //  to save some initialization time
+  if(!alsoThick) {
+    if (!RecryptData::isPo2) {
+      coeffToSlot =
+          std::make_shared<ThinEvalMap>(*ea, minimal, mvec, true, build_cache);
+      // for thin bootstrapping
+      // slotToCoeff takes place before I-part-extraction
+      // thus it has the ordinary plaintext modulus
+      slotToCoeff = std::make_shared<ThinEvalMap>(context.getEA(),
+                                                  minimal,
+                                                  mvec,
+                                                  false,
+                                                  build_cache);
+    } else {
+      bool forceRadix2 = context.getForceRadix2();
+      const auto& partition = context.getFFTPartition();
+      slotToCoeffPo2 = std::make_shared<ThinPo2IFFT>(context.getEA(), 
+          true, partition, forceRadix2, build_cache, context.getDummy());
+      coeffToSlotPo2 = std::make_shared<ThinPo2IFFT>(*ea,
+          false, partition, forceRadix2, build_cache, context.getDummy());
+    }
+  }
 }
 
 // Extract digits from thinly packed slots
 
 long fhe_force_chen_han = 0;
 
-void extractDigitsThin(Ctxt& ctxt, long botHigh, long r, long ePrime)
+// botHigh = e - e' is the number of digits to discard
+// r is the number of digits to keep
+void extractDigitsThin(Ctxt& ctxt, long botHigh, long r, long ePrime, bool thinRefine)
 {
   HELIB_TIMER_START;
 
@@ -801,42 +2155,101 @@ void extractDigitsThin(Ctxt& ctxt, long botHigh, long r, long ePrime)
 
   long p = ctxt.getContext().getP();
   long p2r = NTL::power_long(p, r);
-  long topHigh = botHigh + r - 1;
+  long topHigh =
+      botHigh + r - 1; // topHigh is the index of the highest digit to keep
+
+  bool newBtsFlag = ctxt.getContext().getNewBTSFlag();
 
   // degree Chen/Han technique is p^{bot-1}(p-1)r
   // degree of basic technique is p^{bot-1}p^r,
   //     or p^{bot-1}p^{r-1} if p==2, r > 1, and bot+r > 2
 
-  bool use_chen_han = false;
-  if (r > 1) {
-    double chen_han_cost = log(p - 1) + log(r);
-    double basic_cost;
-    if (p == 2 && r > 2 && botHigh + r > 2)
-      basic_cost = (r - 1) * log(p);
-    else
-      basic_cost = r * log(p);
-
-    // std::cerr << "*** basic: " << basic_cost << "\n";
-    // std::cerr << "*** chen/han: " << chen_han_cost << "\n";
-
-    double thresh = 1.5;
-    if (p == 2)
-      thresh = 1.75;
-    // increasing thresh makes chen_han less likely to be chosen.
-    // For p == 2, the basic algorithm is just squaring,
-    // and so is a bit cheaper, so we raise thresh a bit.
-    // This is all a bit heuristic.
-
-    if (basic_cost > thresh * chen_han_cost)
-      use_chen_han = true;
+  if (newBtsFlag) {
+    newExtractDigits(scratch, unpacked);
+    long scratch_len = scratch.size();
+    if(thinRefine) {
+      // just remove the lower digits
+      for (long i = 0; i < scratch_len; i++) {
+        unpacked -= scratch[i];
+        unpacked.divideByP();
+      }
+      ctxt = unpacked;
+    } else {
+      // > get the lower digits modulo p^eNew
+      // sum up the extracted digits from high to low
+      unpacked = scratch[scratch_len - 1];
+      for (long i = scratch_len - 2; i >= 0; i--) {
+        unpacked.multByP();
+        unpacked += scratch[i];
+      }
+      ctxt = unpacked;
+    }
+#ifdef HELIB_DEBUG
+    // XXX: debug
+    // long p2eNew = NTL::power_long(p, ctxt.getContext().getENew());
+    // std::vector<NTL::ZZX> in_slots, after_slots0;
+    // ctxt.getContext().getRcData().ea->decrypt(ctxt, *dbgKey, in_slots);
+
+    // ctxt.getContext().getRcData().ea->decrypt(scratch[0],
+    //                                           *dbgKey,
+    //                                           after_slots0);
+
+    // long nslots = in_slots.size();
+    // for (long i = 0; i < nslots; i++) {
+    //   long in_deg = NTL::deg(in_slots[i]);
+    //   long out_deg = NTL::deg(after_slots0[i]);
+    //   assertTrue((in_deg <= 0) && (out_deg <= 0),
+    //              "slot values should be integers");
+    //   if ((in_deg == -1 && out_deg != -1) || (in_deg != -1 && out_deg == -1))
+    //     assertTrue(false, "nope");
+    //   if (in_deg == -1 && out_deg == -1)
+    //     continue;
+    //   NTL::ZZ tmp = in_slots[i][0];
+    //   // long tmp_bal = NTL::rem(tmp, p2eNew);
+    //   // if(tmp_bal > p2eNew / 2)
+    //   //   tmp_bal -= p2eNew;
+    //   long expected = NTL::rem(tmp, p);
+    //   expected = helib::balRem(expected, p);
+    //   long got = NTL::to_long(after_slots0[i][0]);
+    //   got = helib::balRem(got, p2eNew);
+    //   assertEq(expected, got, "???");
+    // }
+    // XXX: end debug
+#endif
+    return;
   }
 
-  if (fhe_force_chen_han > 0)
-    use_chen_han = true;
-  else if (fhe_force_chen_han < 0)
-    use_chen_han = false;
-
-  if (use_chen_han) {
+  // XXX: pre-computed in Context
+  // bool use_chen_han = false;
+  // if (r > 1) {
+  //   double chen_han_cost = log(p - 1) + log(r);
+  //   double basic_cost;
+  //   if (p == 2 && r > 2 && botHigh + r > 2)
+  //     basic_cost = (r - 1) * log(p);
+  //   else
+  //     basic_cost = r * log(p);
+
+  //   // std::cerr << "*** basic: " << basic_cost << "\n";
+  //   // std::cerr << "*** chen/han: " << chen_han_cost << "\n";
+
+  //   double thresh = 1.5;
+  //   if (p == 2)
+  //     thresh = 1.75;
+  //   // increasing thresh makes chen_han less likely to be chosen.
+  //   // For p == 2, the basic algorithm is just squaring,
+  //   // and so is a bit cheaper, so we raise thresh a bit.
+  //   // This is all a bit heuristic.
+
+  //   if (basic_cost > thresh * chen_han_cost)
+  //     use_chen_han = true;
+  // }
+
+  // if (fhe_force_chen_han > 0)
+  //   use_chen_han = true;
+  // else if (fhe_force_chen_han < 0)
+  //   use_chen_han = false;
+
+  if (ctxt.getContext().getCH18Flag()) {
     // use Chen and Han technique
 
     extendExtractDigits(scratch, unpacked, botHigh, r);
@@ -936,15 +2349,84 @@ struct PubKeyHack
   Ctxt recryptEkey;  // the key itself, encrypted under key #0
 };
 
+#ifdef HELIB_DEBUG
+static NTL::vec_ZZ balrem_vec_ZZX(const std::vector<NTL::ZZX>& vec, long q)
+{
+  NTL::vec_ZZ ret_vec;
+  ret_vec.SetLength(vec.size());
+  for (size_t i = 0; i < vec.size(); i++) {
+    if (NTL::deg(vec[i]) == -1)
+      ret_vec[i] = 0;
+    else
+      ret_vec[i] = balRem(NTL::rem(vec[i][0], q), q);
+  }
+  return ret_vec;
+}
+#endif
+
+
 // bootstrap a ciphertext to reduce noise
-void PubKey::thinReCrypt(Ctxt& ctxt) const
+BootBench PubKey::thinReCrypt(Ctxt& ctxt) const
 {
+#ifdef HELIB_DEBUG
+  // XXX: debug, check the bound (5) in HS21
+  if(context.getNewKSFlag())
+  {
+    long phim = context.getPhiM();
+    long q = 1 << 20;
+    NTL::zz_p::init(q);
+    NTL::ZZX dbg_b, dbg_a, dbg_m;
+    NTL::vec_ZZ pwfl_b, pwfl_a, pwfl_m;
+    NTL::zz_p tmp;
+    pwfl_b.SetLength(phim);
+    pwfl_a.SetLength(phim);
+    long n_trials = 20;
+    auto p2d_conv = context.getRcData().p2dConv;
+    NTL::ZZ sum_var(0);
+    for (long i = 0; i < n_trials; i++) {
+      // random in [-q/2,q/2]
+      for (long j = 0; j < phim; j++) {
+        NTL::random(tmp);
+        pwfl_a[j] = NTL::conv<NTL::ZZ>(tmp);
+        NTL::random(tmp);
+        pwfl_b[j] = NTL::conv<NTL::ZZ>(tmp);
+      }
+      vecRed(pwfl_a, pwfl_a, q, false);
+      vecRed(pwfl_b, pwfl_b, q, false);
+      // check bound
+      p2d_conv->powerfulToZZX(dbg_b, pwfl_b);
+      p2d_conv->powerfulToZZX(dbg_a, pwfl_a);
+      rawDecrypt(dbg_m, {dbg_b, dbg_a}, dbgKey->getRecryptKey());
+      p2d_conv->ZZXtoPowerful(pwfl_m, dbg_m);
+      NTL::ZZ pwfl_bound = largestCoeff(pwfl_m);
+      std::cout << "pwfl bound on I " << 
+                NTL::conv<NTL::xdouble>(pwfl_bound) / NTL::conv<NTL::xdouble>(q)
+                << "\n";
+      NTL::ZZ local_var(0), local_mean(0);
+      for (long j = 0; j < phim; j++) {
+        local_var += pwfl_m[j] * pwfl_m[j];
+        local_mean += pwfl_m[j];
+      }
+      // += phim^2*Var(Iq)
+      sum_var += phim * local_var - local_mean * local_mean;
+    }
+    // now sum_var = n_trials * phim^2 * Var(Iq)
+    // std(I) = sqrt(Var(I)) = sqrt(sum_var / (n_trials * phim^2 * q^2))
+    std::cout << "standard deviation "
+              << NTL::sqrt(NTL::conv<NTL::xdouble>(sum_var) / n_trials) /
+                     (q * phim)
+              << "\n";
+  }
+#endif
+
+  BootBench benchmarker;
+  auto time_boot_start = steady_clock::now();
   HELIB_TIMER_START;
 
   // Some sanity checks for dummy ciphertext
   long ptxtSpace = ctxt.getPtxtSpace();
   if (ctxt.isEmpty())
-    return;
+    return benchmarker;
 
   if (ctxt.parts.size() == 1 && ctxt.parts[0].skHandle.isOne()) {
     // Dummy encryption, just ensure that it is reduced mod p
@@ -953,7 +2435,7 @@ void PubKey::thinReCrypt(Ctxt& ctxt) const
       poly[i] = NTL::to_ZZ(rem(poly[i], ptxtSpace));
     poly.normalize();
     ctxt.DummyEncrypt(poly);
-    return;
+    return benchmarker;
   }
 
   // check that we have bootstrapping data
@@ -966,13 +2448,29 @@ void PubKey::thinReCrypt(Ctxt& ctxt) const
   long intFactor = ctxt.intFactor;
 
   const ThinRecryptData& trcData = ctxt.getContext().getRcData();
+  auto p2d_conv = *trcData.p2dConv;
 
   // the bootstrapping key is encrypted relative to plaintext space p^{e-e'+r}.
   long e = trcData.e;
   long ePrime = trcData.ePrime;
   long p2ePrime = NTL::power_long(p, ePrime);
   long q = NTL::power_long(p, e) + 1;
-  assertTrue(e >= r, "trcData.e must be at least alMod.r");
+  // new bts
+  long phim = context.getZMStar().getPhiM();
+#ifdef HELIB_DEBUG
+  long d = context.getOrdP();
+  long n_slots = phim / d;
+#endif
+  long eNew = trcData.eNew;
+  long t = trcData.t;
+  long aux = context.getAux();
+  long p2eNew = NTL::power_long(p, eNew);
+  bool newBtsFlag = context.getNewBTSFlag();
+  bool newKSFlag = context.getNewKSFlag();
+  if (!newBtsFlag)
+    assertTrue(e >= r, "trcData.e must be at least alMod.r");
+  if (newBtsFlag)
+    q = context.ithPrime(context.getIndexQks());
 
   // can only bootstrap ciphertext with plaintext-space dividing p^r
   assertEq(p2r % ptxtSpace,
@@ -980,6 +2478,10 @@ void PubKey::thinReCrypt(Ctxt& ctxt) const
            "ptxtSpace must divide p^r when thin bootstrapping");
 
 #ifdef HELIB_DEBUG
+  auto ea_ctxt = context.shareEA();
+  auto ea_boot = context.getRcData().ea;
+  std::vector<NTL::ZZX> slots_in;
+  ea_ctxt->decrypt(ctxt, *dbgKey, slots_in);
   CheckCtxt(ctxt, "init");
 #endif
 
@@ -1002,8 +2504,17 @@ void PubKey::thinReCrypt(Ctxt& ctxt) const
 
   // Move the slots to powerful-basis coefficients
   HELIB_NTIMER_START(AAA_slotToCoeff);
-  trcData.slotToCoeff->apply(ctxt);
+  auto bits_down_linear1 = ctxt.capacity();
+  auto time_linear1_start = steady_clock::now();
+  if(!trcData.isPo2)
+    trcData.slotToCoeff->apply(ctxt);
+  else
+    trcData.slotToCoeffPo2->apply(ctxt);
+  auto time_linear1_end = steady_clock::now();
+  bits_down_linear1 -= ctxt.capacity();
   HELIB_NTIMER_STOP(AAA_slotToCoeff);
+  // std::cout << "time for linear1 is " << 
+  //   duration_cast<duration<double>>(time_linear1_end - time_linear1_start).count() << "\n";
 
 #ifdef HELIB_DEBUG
   CheckCtxt(ctxt, "after slotToCoeff");
@@ -1014,33 +2525,115 @@ void PubKey::thinReCrypt(Ctxt& ctxt) const
   // Make sure that this ciphertext is in canonical form
   if (!ctxt.inCanonicalForm())
     ctxt.reLinearize();
+  
+#ifdef HELIB_DEBUG
+  // XXX: debug
+  NTL::ZZX poly_s2c;
+  NTL::vec_ZZ pwfl_s2c;
+  dbgKey->Decrypt(poly_s2c, ctxt);
+  p2d_conv.ZZXtoPowerful(pwfl_s2c, poly_s2c);
+  // NOTE: the pwfl basis coeffs stores
+  // slots[0][0], ..., slots[0][d-1]; slots[1][0], ...
+  vecRed(pwfl_s2c, pwfl_s2c, p2r, true);
+  // check the validity of s2c
+  for(long i = 0; i < n_slots; i++) {
+    NTL::ZZ val_in;
+    if(NTL::deg(slots_in[i]) == -1)
+      val_in = 0;
+    else
+      val_in = NTL::rem(slots_in[i][0], p2r);
+    if (!trcData.isPo2)
+      assertEq(val_in, pwfl_s2c[i * d], "something wrong with s2c?");
+  }
+  // try
+  // for(long i = 0; i < n_slots; i++) {
+  //   auto it = std::find(pwfl_s2c.begin(), pwfl_s2c.end(), NTL::ZZ(i+1));
+  //   if(it != pwfl_s2c.end())
+  //     printf("%ld found at %ld\n", i+1, it - pwfl_s2c.begin());
+  // }
+  // XXX: end debug
+#endif
 
   // Mod-switch down if needed
   IndexSet s = ctxt.getPrimeSet() / context.getSpecialPrimes();
   assertTrue(s <= context.getCtxtPrimes(), "prime set is messed up");
-  if (s.card() > 3) { // leave only first three ciphertext primes
-    long first = s.first();
-    IndexSet s3(first, first + 2);
-    s.retain(s3);
+  if (newKSFlag) {
+    s.clear();
+    s.insert(context.getIndexQks());
+    ctxt.bringToSet(s);
+  } else {
+    if (s.card() > 3) { // leave only first three ciphertext primes
+      long first = s.first();
+      IndexSet s3(first, first + 2);
+      s.retain(s3);
+    }
+    ctxt.modDownToSet(s);
   }
-  ctxt.modDownToSet(s);
+
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after mod down to qKS");
+  // XXX: debug
+  NTL::ZZX poly_beforeKS;
+  NTL::vec_ZZ pwfl_beforeKS;
+  dbgKey->Decrypt(poly_beforeKS, ctxt);
+  p2d_conv.ZZXtoPowerful(pwfl_beforeKS, poly_beforeKS);
+  vecRed(pwfl_beforeKS, pwfl_beforeKS, p2r, true);
+  for(long i = 0; i < n_slots; i++) {
+    assertEq(pwfl_s2c[i * d], pwfl_beforeKS[i * d], "something wrong with mod down to qKS");
+  }
+  // XXX: end debug
+#endif
+
 
   // key-switch to the bootstrapping key
-  ctxt.reLinearize(recryptKeyID);
+  ctxt.reLinearize(recryptKeyID, newKSFlag);
 
 #ifdef HELIB_DEBUG
   CheckCtxt(ctxt, "after key switching");
+  // XXX: debug
+  NTL::ZZX poly_beforeRaw;
+  NTL::vec_ZZ pwfl_beforeRaw;
+  dbgKey->Decrypt(poly_beforeRaw, ctxt);
+  p2d_conv.ZZXtoPowerful(pwfl_beforeRaw, poly_beforeRaw);
+  vecRed(pwfl_beforeRaw, pwfl_beforeRaw, p2r, true);
+  for(long i = 0; i < n_slots; i++) {
+    assertEq(pwfl_beforeKS[i * d], pwfl_beforeRaw[i * d], "something wrong with ks to btk");
+  }
+  // XXX: end debug
 #endif
 
+
   // "raw mod-switch" to the bootstrapping mosulus q=p^e+1.
   std::vector<NTL::ZZX> zzParts; // the mod-switched parts, in ZZX format
 
   double mfac = ctxt.getContext().getZMStar().getNormBnd();
-  double noise_est = ctxt.rawModSwitch(zzParts, q) * mfac;
+  double noise_est;
+  if (newBtsFlag)
+    noise_est = ctxt.rawModSwitchNew(zzParts, q) * mfac;
+  else
+    noise_est = ctxt.rawModSwitch(zzParts, q) * mfac;
+#ifdef HELIB_DEBUG
+  // XXX: debug, check the bound on I after native bts
+  NTL::ZZX native_poly;
+  NTL::vec_ZZ native_pwfl;
+  rawDecrypt(native_poly, zzParts, dbgKey->getRecryptKey());
+  p2d_conv.ZZXtoPowerful(native_pwfl, native_poly);
+  auto native_pwfl_bound = NTL::conv<NTL::xdouble>(largestCoeff(native_pwfl)) /
+                           NTL::conv<NTL::xdouble>(q);
+  std::cout << "native pwfl bound is " << native_pwfl_bound << "\n";
+  // XXX: end debug native
+#endif
+
   // noise_est is an upper bound on the L-infty norm of the scaled noise
   // in the pwrfl basis
-  double noise_bnd =
-      HELIB_MIN_CAP_FRAC * p2r * ctxt.getContext().boundForRecryption();
+  double beta =
+      p2r * (context.getScale() * sqrt(double(phim) / 12.0) *
+                 (sqrt(double(context.getHwt()) * log(double(phim))) + 1) +
+             0.5);
+  double noise_bnd = newBtsFlag ? 2 * beta * mfac
+                                : HELIB_MIN_CAP_FRAC * p2r *
+                                      ctxt.getContext().boundForRecryption();
   // noise_bnd is the bound assumed in selecting the parameters
   double noise_rat = noise_est / noise_bnd;
 
@@ -1063,41 +2656,237 @@ void PubKey::thinReCrypt(Ctxt& ctxt) const
 
 #ifdef HELIB_DEBUG
   if (dbgKey) {
-    checkRecryptBounds(zzParts, dbgKey->getRecryptKey(), ctxt.getContext(), q);
+    if (!newBtsFlag)
+      checkRecryptBounds(zzParts,
+                         dbgKey->getRecryptKey(),
+                         ctxt.getContext(),
+                         q);
   }
 #endif
 
   std::vector<NTL::ZZX> v;
   v.resize(2);
 
-  // Add multiples of q to make the zzParts divisible by p^{e'}
-  for (long i : range(2)) {
-    // make divisible by p^{e'}
+  Ctxt modUpCtxt(ctxt.getPubKey(), p2eNew);
+  std::vector<NTL::ZZX> I_part;
+
+  // debug variables
+
+  NTL::ZZX poly_before_mod;
+  NTL::vec_ZZ pwfl_before_mod;
+  NTL::ZZX poly_after_mod, I_poly, modUpPoly;
+  NTL::vec_ZZ I_part_pwfl, pwfl_diff, pwfl_after_mod, modUpPwfl;
+  std::vector<NTL::ZZX> slots_scaleUp;
+
+  steady_clock::time_point time_linear2_start_second, time_linear2_end_second;
+  if (!newBtsFlag) {
+    // Add multiples of q to make the zzParts divisible by p^{e'}
+    for (long i : range(2)) {
+      // make divisible by p^{e'}
+
+      newMakeDivisible(zzParts[i], p2ePrime, q, ctxt.getContext(), v[i]);
+    }
+  } else {
+#ifdef HELIB_DEBUG
+    // check the capacity of zzParts
+    rawDecrypt(poly_before_mod, zzParts, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(pwfl_before_mod, poly_before_mod);
+    vecRed(pwfl_before_mod, pwfl_before_mod, q, false);
+    NTL::ZZ maxPwfl = largestCoeff(pwfl_before_mod);
+    double capacity =
+        log(double(q) / NTL::to_long(maxPwfl) / 2.0 / aux) / log(2.0);
+    printf("pwfl capacity of zzParts is %f\n", capacity);
+    assertTrue(capacity > 0, "not enough capacity before scale");
+    // check the correctness of raw MS
+    long divFac = NTL::MulMod(q % p2r, intFactor, p2r);
+    divFac = NTL::InvMod(divFac, p2r);
+    for(long i = 0; i < n_slots; i++) {
+      long before = NTL::to_long(pwfl_beforeRaw[i * d]);
+      long after = NTL::rem(pwfl_before_mod[i * d], p2r);
+      after = NTL::MulMod(after, divFac, p2r);
+      assertEq(after, before, "something wrong with raw ms");
+    }
+#endif
+    // NOTE: in thin bootstrapping, the Zpr values in slots are first
+    //  move to the coeff domain by slotToCoeff
+    //  then the multAndGetOverflowPart adds noise to the lower digits
+    //  and the unoccupied coeffs
+    //  a coeffToSlot map moves the noisy coeffs into the slots,
+    //  then a trace-like map removes the values out of Z_p2eNew
+    //  In other words, we have apply the second map to
+    //  both modUpCtxt and Enc(I+aux*I', p2eNew)
+    multAndGetOverflowPart(zzParts, I_part, ctxt.getContext());
+
+#ifdef HELIB_DEBUG
+    // XXX: debug
+    rawDecrypt(poly_after_mod, zzParts, dbgKey->getRecryptKey());
+    // check the overflow part
+    rawDecrypt(I_poly, I_part, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(I_part_pwfl, I_poly);
+    vecRed(I_part_pwfl, I_part_pwfl, aux, false);
+    p2d_conv.powerfulToZZX(I_poly, I_part_pwfl);
+
+    p2d_conv.ZZXtoPowerful(pwfl_diff, poly_after_mod - I_poly * q);
+    // vecRed(pwfl_diff, pwfl_diff, NTL::ZZ(aux) * NTL::ZZ(q), false);
+    for (long i = 0; i < phim; i++) {
+      assertTrue(bool(NTL::abs(pwfl_diff[i]) <= (q / 2)),
+                 "overflow part wrong?");
+    }
+    // assertTrue(NTL::to_long(largestCoeff(pwfl_diff)) <= (q / 2),
+    //            "overflow part wrong?");
+    // check the relationship between pwfl_before_mod and pwfl_after_mod
+    // now check if the bound on I is valid
+    p2d_conv.ZZXtoPowerful(pwfl_after_mod, poly_after_mod);
+    NTL::xdouble actualBoundI =
+        NTL::conv<NTL::xdouble>(largestCoeff(pwfl_after_mod)) / NTL::xdouble(q);
+    std::cerr << "actual bound on I is " << actualBoundI << "\n";
+    assertTrue(
+        bool(NTL::floor(actualBoundI) <= ceil(context.boundForRecryption())),
+        "bound on I exceeded");
+    vecRed(pwfl_after_mod, pwfl_after_mod, q, false);
+    if (t < 0) {
+      for (long i = 0; i < phim; i++) {
+        long before = NTL::rem(pwfl_before_mod[i], p2r);
+        before = NTL::MulMod(before, aux % p2r, p2r);
+        long after = NTL::rem(pwfl_after_mod[i], p2r);
+        assertEq(before,
+                 after,
+                 "something wrong with upscaling, non-power-of-p aux");
+      }
+    } else {
+      for (long i = 0; i < phim; i++) {
+        long before = NTL::rem(pwfl_before_mod[i], p2r);
+        long after = NTL::rem(pwfl_after_mod[i], p2eNew);
+        assertEq(before * aux,
+                 after,
+                 "something wrong with upscaling, power-of-p aux");
+      }
+    }
+// XXX: end debug
+#endif
+
+    // now handle the mod-up ctxt
+    modUpCtxt.ptxtSpace = p2eNew;
+    modUpCtxt.primeSet = context.getCtxtPrimes() | context.getModUpPrimes();
+    long QmodP = 1;
+    // be careful with single-precision modular arithmetic...
+    for (auto i : modUpCtxt.primeSet)
+      QmodP = NTL::MulMod(QmodP, context.ithPrime(i) % p2eNew, p2eNew);
+    // we pretend the IMPLIED INTFACTOR of m* mod P is 1
+    // (i.e., zzParts after raw-ms decrypts to m*)
+    // which is actually intFactor * [q]_{p^r}
+    // we want the mult-by-aux and modded-up ctxt to have
+    // an implied intfactor of aux (decrypts to m*+...)
+    if (t < 0) // gcd(aux, p) = 1, stored intFactor = aux * [Q^-1]_P
+      modUpCtxt.intFactor =
+          NTL::MulMod(aux, NTL::InvMod(QmodP, p2eNew), p2eNew);
+    else // aux = p^t, stored intFactor = [Q^-1]_P
+      modUpCtxt.intFactor = NTL::InvMod(QmodP, p2eNew);
+    modUpCtxt.noiseBound = context.boundForRecryption() * q;
+    for (int i = 0; i < 2; i++)
+      modUpCtxt.addPart(DoubleCRT(zzParts[i], context, modUpCtxt.primeSet),
+                        ctxt.parts[i].skHandle);
+    // discard the mod-up primes
+    modUpCtxt.modDownToSet(context.getCtxtPrimes());
+
+    // switch to the normal sk (keyID = 0)
+    modUpCtxt.reLinearize();
 
-    newMakeDivisible(zzParts[i], p2ePrime, q, ctxt.getContext(), v[i]);
+#ifdef HELIB_DEBUG
+    dbgKey->Decrypt(modUpPoly, modUpCtxt);
+    p2d_conv.ZZXtoPowerful(modUpPwfl, modUpPoly);
+    vecRed(modUpPwfl, modUpPwfl, p2eNew, false);
+    p2d_conv.ZZXtoPowerful(I_part_pwfl, I_poly);
+    vecRed(I_part_pwfl, I_part_pwfl, aux, false);
+
+    p2d_conv.ZZXtoPowerful(pwfl_after_mod, poly_after_mod);
+    vecRed(pwfl_after_mod, pwfl_after_mod, q, false);
+
+    // for aux = p^t
+    // the message in zzParts befure "multAndGetOverflowPart" is m' mod p2r
+    // after that, the scaled message becomes p^t*m' mod p2eNew
+    // by modding up, the message becomes p^t*m' + [q]_p2eNew*I
+    // setting the modUpCtxt.intFactor = [Q^-1]_p2eNew ensures
+    // modUpCtxt decrypts to p^t*m' + [q]_p2eNew*I
+    for (long i = 0; i < phim; i++) {
+      if (t > 0) {
+        assertEq(NTL::rem(modUpPwfl[i] - I_part_pwfl[i] * (q % p2eNew) -
+                              pwfl_after_mod[i],
+                          p2eNew),
+                 0L,
+                 "something wrong with assembly...? power-of-p aux");
+      } else {
+        // aux is not a power of p
+        // old message: m' mod p2r
+        // scaled message: aux*m' mod p2r (= pwfl_after_mod)
+        // modding up: aux*m' + [q]_p2r*I
+        // by setting stored intFactor to aux*[Q]_p2r:
+        //  m' + [q*aux^-1]_p2r*I
+        assertEq(NTL::rem(aux * modUpPwfl[i] - I_part_pwfl[i] * (q % p2r) -
+                              pwfl_after_mod[i],
+                          p2r),
+                 0L,
+                 "something wrong with assembly...? non-power-of-p aux");
+      }
+    }
+#endif
+    // NOTE: this map is exclusive to thin-bts
+    time_linear2_start_second = steady_clock::now();
+    if (!trcData.isPo2)
+      trcData.coeffToSlot->apply(modUpCtxt);
+    else
+      trcData.coeffToSlotPo2->apply(modUpCtxt);
+    time_linear2_end_second = steady_clock::now();
+    // std::cout << "time for 2nd linear2 is " << 
+    //   duration_cast<duration<double>>(time_linear2_end_second - time_linear2_start_second).count()
+    //   << "\n";
+#ifdef HELIB_DEBUG
+    ea_boot->decrypt(modUpCtxt, *dbgKey, slots_scaleUp);
+#endif
   }
 
 #ifdef HELIB_DEBUG
   if (dbgKey) {
-    checkRecryptBounds_v(v, dbgKey->getRecryptKey(), ctxt.getContext(), q);
-    checkCriticalValue(zzParts,
-                       dbgKey->getRecryptKey(),
-                       ctxt.getContext().getRcData(),
-                       q);
+    if (!newBtsFlag) {
+      checkRecryptBounds_v(v, dbgKey->getRecryptKey(), ctxt.getContext(), q);
+      checkCriticalValue(zzParts,
+                         dbgKey->getRecryptKey(),
+                         ctxt.getContext().getRcData(),
+                         q);
+    }
   }
 #endif
 
-  for (long i : range(zzParts.size())) {
-    zzParts[i] /= p2ePrime; // divide by p^{e'}
-  }
+  if (!newBtsFlag)
+    for (long i : range(zzParts.size())) {
+      zzParts[i] /= p2ePrime; // divide by p^{e'}
+    }
 
   // NOTE: here we lose the intFactor associated with ctxt.
   // We will restore it below.
   ctxt = recryptEkey;
 
-  ctxt.multByConstant(zzParts[1]);
-  ctxt.addConstant(zzParts[0]);
-
+  NTL::ZZX I_poly_new;
+  NTL::vec_ZZ I_poly_new_pwfl;
+  if (!newBtsFlag) {
+    ctxt.multByConstant(zzParts[1]);
+    ctxt.addConstant(zzParts[0]);
+    benchmarker.bits_after_inner_prod = ctxt.capacity();
+  } else {
+    ctxt.multByConstant(I_part[1]);
+    ctxt.addConstant(I_part[0]);
+    benchmarker.bits_after_inner_prod = ctxt.capacity();
+#ifdef HELIB_DEBUG
+    // NOTE-debug: check ctxt here, see if it matches I_part
+    dbgKey->Decrypt(I_poly_new, ctxt);
+    p2d_conv.ZZXtoPowerful(I_poly_new_pwfl, I_poly_new);
+    vecRed(I_poly_new_pwfl, I_poly_new_pwfl, p2eNew, false);
+    for (long i = 0; i < phim; i++) {
+      assertTrue(bool(NTL::rem(I_poly_new_pwfl[i] - I_part_pwfl[i], aux) == 0),
+                 "something wrong with linear dec");
+    }
+#endif
+  }
 #ifdef HELIB_DEBUG
   CheckCtxt(ctxt, "after bootKeySwitch");
 #endif
@@ -1106,8 +2895,42 @@ void PubKey::thinReCrypt(Ctxt& ctxt) const
 
   // Move the powerful-basis coefficients to the plaintext slots
   HELIB_NTIMER_START(AAA_coeffToSlot);
-  trcData.coeffToSlot->apply(ctxt);
+  auto bits_down_linear2 = ctxt.capacity();
+  auto time_linear2_start = steady_clock::now();
+  if (!trcData.isPo2)
+    trcData.coeffToSlot->apply(ctxt);
+  else
+    trcData.coeffToSlotPo2->apply(ctxt);
+  auto time_linear2_end = steady_clock::now();
+  bits_down_linear2 -= ctxt.capacity();
   HELIB_NTIMER_STOP(AAA_coeffToSlot);
+  // std::cout << "time for linear2 is " << 
+
+#ifdef HELIB_DEBUG
+  std::vector<NTL::ZZX> slots_I;
+  ea_boot->decrypt(ctxt, *dbgKey, slots_I);
+  // XXX: debug, check if the slots match
+  auto vals_in = balrem_vec_ZZX(slots_in, p2r);
+  auto vals_scaleUp = balrem_vec_ZZX(slots_scaleUp, p2eNew);
+  auto val_I = balrem_vec_ZZX(slots_I, p2eNew);
+  if (t > 0)
+    for (long i = 0; i < n_slots; i++) {
+      long tmp = balRem(NTL::rem(val_I[i], aux), aux); // I without I*
+      tmp = (tmp + p2eNew) % p2eNew;
+      tmp = NTL::MulMod(q % p2eNew, tmp, p2eNew);
+      tmp = NTL::SubMod(NTL::rem(vals_scaleUp[i], p2eNew), tmp, p2eNew);
+      assertEq(tmp % aux, 0L, "not divisible by aux?");
+      tmp /= aux;
+      tmp %= p2r;
+      long factorDiv = intFactor;
+      factorDiv = NTL::MulMod(factorDiv % p2r, q % p2r, p2r);
+      assertEq(tmp,
+               NTL::MulMod(NTL::rem(vals_in[i], p2r), factorDiv, p2r),
+               "not matching, p^t");
+    }
+    // TODO: t < 0
+    // XXX: end debug
+#endif
 
 #ifdef HELIB_DEBUG
   CheckCtxt(ctxt, "after coeffToSlot");
@@ -1115,18 +2938,694 @@ void PubKey::thinReCrypt(Ctxt& ctxt) const
 
   // Extract the digits e-e'+r-1,...,e-e' (from fully packed slots)
   HELIB_NTIMER_START(AAA_extractDigitsThin);
+  auto bits_down_extract = ctxt.capacity();
+  auto time_extract_start = steady_clock::now();
   extractDigitsThin(ctxt, e - ePrime, r, ePrime);
+  auto time_extract_end = steady_clock::now();
+  bits_down_extract -= ctxt.capacity();
+  HELIB_NTIMER_STOP(AAA_extractDigitsThin);
+
+#ifdef HELIB_DEBUG
+  if (newBtsFlag) {
+    std::vector<NTL::ZZX> slots_I_out;
+    ea_boot->decrypt(ctxt, *dbgKey, slots_I_out);
+    auto vals_I_out = balrem_vec_ZZX(slots_I_out, p2eNew);
+    for (long i = 0; i < n_slots; i++) {
+      assertEq(balRem(NTL::rem(val_I[i], aux), aux),
+               NTL::to_long(vals_I_out[i]),
+               "something wrong with digit extraction");
+    }
+  }
+#endif
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after extractDigitsThin");
+#endif
+
+  // restore intFactor
+  if (newBtsFlag) {
+    // > assemble the ctxts and adjust the intFactors
+    // after modding-up, the message encrypted becomes
+    //  m + [q]_P*I, P = p^eNew, for power-of-p aux
+    //  m + [q*aux^-1]_P*I, P = p^r, for non-power-of-p aux
+    long adjust_factor = q % p2eNew;
+    if (t < 0)
+      adjust_factor = NTL::MulMod(q % p2r, NTL::InvMod(aux % p2r, p2r), p2r);
+    ctxt *= adjust_factor;
+    ctxt -= modUpCtxt;
+    ctxt.negate();               // modUpCtxt - ctxt = Enc(m)
+    for (long i = 0; i < t; i++) // remove the extra p^t, if any
+      ctxt.divideByP();
+    // now correct the intFactor
+    // NOTE: for old bts, since q=p^e+1, [q]_p^r==1
+    ctxt.intFactor =
+        NTL::MulMod(ctxt.intFactor,
+                    NTL::MulMod(intFactor, q % ptxtSpace, ptxtSpace),
+                    ptxtSpace);
+  } else if (intFactor != 1)
+    ctxt.intFactor = NTL::MulMod(ctxt.intFactor, intFactor, ptxtSpace);
+  auto time_boot_end = steady_clock::now();
+  benchmarker.bits_down_extract = bits_down_extract;
+  benchmarker.bits_down_linear_1 = bits_down_linear1;
+  benchmarker.bits_down_linear_2 = bits_down_linear2;
+  benchmarker.bits_final = ctxt.capacity();
+  benchmarker.time_linear_1 =
+      duration_cast<duration<double>>(time_linear1_end - time_linear1_start)
+          .count();
+  benchmarker.time_linear_2 =
+      duration_cast<duration<double>>(time_linear2_end - time_linear2_start)
+          .count();
+  if (newBtsFlag)
+    benchmarker.time_linear_2 += 
+      duration_cast<duration<double>>(time_linear2_end_second - time_linear2_start_second).count();
+  benchmarker.time_extract =
+      duration_cast<duration<double>>(time_extract_end - time_extract_start)
+          .count();
+  benchmarker.time_total =
+      duration_cast<duration<double>>(time_boot_end - time_boot_start).count();
+  return benchmarker;
+}
+
+
+// bootstrap a ciphertext to reduce noise
+BootBench PubKey::thinReCryptRefine(Ctxt& ctxt) const
+{
+#ifdef HELIB_DEBUG
+  // XXX: debug, check the bound (5) in HS21
+  if(context.getNewKSFlag())
+  {
+    long phim = context.getPhiM();
+    long q = 1 << 20;
+    NTL::zz_p::init(q);
+    NTL::ZZX dbg_b, dbg_a, dbg_m;
+    NTL::vec_ZZ pwfl_b, pwfl_a, pwfl_m;
+    NTL::zz_p tmp;
+    pwfl_b.SetLength(phim);
+    pwfl_a.SetLength(phim);
+    long n_trials = 20;
+    auto p2d_conv = context.getRcData().p2dConv;
+    NTL::ZZ sum_var(0);
+    for (long i = 0; i < n_trials; i++) {
+      // random in [-q/2,q/2]
+      for (long j = 0; j < phim; j++) {
+        NTL::random(tmp);
+        pwfl_a[j] = NTL::conv<NTL::ZZ>(tmp);
+        NTL::random(tmp);
+        pwfl_b[j] = NTL::conv<NTL::ZZ>(tmp);
+      }
+      vecRed(pwfl_a, pwfl_a, q, false);
+      vecRed(pwfl_b, pwfl_b, q, false);
+      // check bound
+      p2d_conv->powerfulToZZX(dbg_b, pwfl_b);
+      p2d_conv->powerfulToZZX(dbg_a, pwfl_a);
+      rawDecrypt(dbg_m, {dbg_b, dbg_a}, dbgKey->getRecryptKey());
+      p2d_conv->ZZXtoPowerful(pwfl_m, dbg_m);
+      NTL::ZZ pwfl_bound = largestCoeff(pwfl_m);
+      std::cout << "pwfl bound on I " << 
+                NTL::conv<NTL::xdouble>(pwfl_bound) / NTL::conv<NTL::xdouble>(q)
+                << "\n";
+      NTL::ZZ local_var(0), local_mean(0);
+      for (long j = 0; j < phim; j++) {
+        local_var += pwfl_m[j] * pwfl_m[j];
+        local_mean += pwfl_m[j];
+      }
+      // += phim^2*Var(Iq)
+      sum_var += phim * local_var - local_mean * local_mean;
+    }
+    // now sum_var = n_trials * phim^2 * Var(Iq)
+    // std(I) = sqrt(Var(I)) = sqrt(sum_var / (n_trials * phim^2 * q^2))
+    std::cout << "standard deviation "
+              << NTL::sqrt(NTL::conv<NTL::xdouble>(sum_var) / n_trials) /
+                     (q * phim)
+              << "\n";
+  }
+#endif
+
+  BootBench benchmarker;
+  auto time_boot_start = steady_clock::now();
+  HELIB_TIMER_START;
+
+  // Some sanity checks for dummy ciphertext
+  long ptxtSpace = ctxt.getPtxtSpace();
+  if (ctxt.isEmpty())
+    return benchmarker;
+
+  if (ctxt.parts.size() == 1 && ctxt.parts[0].skHandle.isOne()) {
+    // Dummy encryption, just ensure that it is reduced mod p
+    NTL::ZZX poly = to_ZZX(ctxt.parts[0]);
+    for (long i = 0; i < poly.rep.length(); i++)
+      poly[i] = NTL::to_ZZ(rem(poly[i], ptxtSpace));
+    poly.normalize();
+    ctxt.DummyEncrypt(poly);
+    return benchmarker;
+  }
+
+  // check that we have bootstrapping data
+  assertTrue(recryptKeyID >= 0l, "Bootstrapping data not present");
+
+  long p = ctxt.getContext().getP();
+  long r = ctxt.getContext().getAlMod().getR();
+  long p2r = ctxt.getContext().getAlMod().getPPowR();
+
+  long intFactor = ctxt.intFactor;
+
+  const ThinRecryptData& trcData = ctxt.getContext().getRcData();
+  auto p2d_conv = *trcData.p2dConv;
+
+  // the bootstrapping key is encrypted relative to plaintext space p^{e-e'+r}.
+  long e = trcData.e;
+  long ePrime = trcData.ePrime;
+  long p2ePrime = NTL::power_long(p, ePrime);
+  long q = NTL::power_long(p, e) + 1;
+  // new bts
+  long phim = context.getZMStar().getPhiM();
+#ifdef HELIB_DEBUG
+  long d = context.getOrdP();
+  long n_slots = phim / d;
+  long aux = context.getAux();
+#endif
+  long eNew = trcData.eNew;
+  long t = trcData.t;
+  assertTrue(t > 0, "thin bts without I applies only to Delta=p^t");
+  long p2eNew = NTL::power_long(p, eNew);
+  bool newBtsFlag = context.getNewBTSFlag();
+  assertTrue(newBtsFlag, "thinRecryptRefine expects new bts flag");
+  bool newKSFlag = context.getNewKSFlag();
+  if (!newBtsFlag)
+    assertTrue(e >= r, "trcData.e must be at least alMod.r");
+  if (newBtsFlag)
+    q = context.ithPrime(context.getIndexQks());
+
+  // can only bootstrap ciphertext with plaintext-space dividing p^r
+  assertEq(p2r % ptxtSpace,
+           0l,
+           "ptxtSpace must divide p^r when thin bootstrapping");
+
+#ifdef HELIB_DEBUG
+  auto ea_ctxt = context.shareEA();
+  auto ea_boot = context.getRcData().ea;
+  std::vector<NTL::ZZX> slots_in;
+  ea_ctxt->decrypt(ctxt, *dbgKey, slots_in);
+  CheckCtxt(ctxt, "init");
+#endif
+
+  ctxt.dropSmallAndSpecialPrimes();
+
+#define DROP_BEFORE_THIN_RECRYPT
+#define THIN_RECRYPT_NLEVELS (3)
+#ifdef DROP_BEFORE_THIN_RECRYPT
+  // experimental code...we should drop down to a reasonably low level
+  // before doing the first linear map.
+  long first = context.getCtxtPrimes().first();
+  long last = std::min(context.getCtxtPrimes().last(),
+                       first + THIN_RECRYPT_NLEVELS - 1);
+  ctxt.bringToSet(IndexSet(first, last));
+#endif
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after mod down");
+#endif
+
+  // Move the slots to powerful-basis coefficients
+  HELIB_NTIMER_START(AAA_slotToCoeff);
+  auto bits_down_linear1 = ctxt.capacity();
+  auto time_linear1_start = steady_clock::now();
+  if (!trcData.isPo2)
+    trcData.slotToCoeff->apply(ctxt);
+  else
+    trcData.slotToCoeffPo2->apply(ctxt);
+  auto time_linear1_end = steady_clock::now();
+  bits_down_linear1 -= ctxt.capacity();
+  HELIB_NTIMER_STOP(AAA_slotToCoeff);
+  // std::cout << "time for linear1 is " << 
+  //   duration_cast<duration<double>>(time_linear1_end - time_linear1_start).count() << "\n";
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after slotToCoeff");
+#endif
+
+  HELIB_NTIMER_START(AAA_bootKeySwitch);
+
+  // Make sure that this ciphertext is in canonical form
+  if (!ctxt.inCanonicalForm())
+    ctxt.reLinearize();
+  
+#ifdef HELIB_DEBUG
+  // XXX: debug
+  NTL::ZZX poly_s2c;
+  NTL::vec_ZZ pwfl_s2c;
+  dbgKey->Decrypt(poly_s2c, ctxt);
+  p2d_conv.ZZXtoPowerful(pwfl_s2c, poly_s2c);
+  // NOTE: the pwfl basis coeffs stores
+  // slots[0][0], ..., slots[0][d-1]; slots[1][0], ...
+  vecRed(pwfl_s2c, pwfl_s2c, p2r, true);
+  // check the validity of s2c
+  for(long i = 0; i < n_slots; i++) {
+    NTL::ZZ val_in;
+    if(NTL::deg(slots_in[i]) == -1)
+      val_in = 0;
+    else
+      val_in = NTL::rem(slots_in[i][0], p2r);
+    if (!trcData.isPo2)
+      assertEq(val_in, pwfl_s2c[i * d], "something wrong with s2c?");
+  }
+  // try
+  // for(long i = 0; i < n_slots; i++) {
+  //   auto it = std::find(pwfl_s2c.begin(), pwfl_s2c.end(), NTL::ZZ(i+1));
+  //   if(it != pwfl_s2c.end())
+  //     printf("%ld found at %ld\n", i+1, it - pwfl_s2c.begin());
+  // }
+  // XXX: end debug
+#endif
+
+  // Mod-switch down if needed
+  IndexSet s = ctxt.getPrimeSet() / context.getSpecialPrimes();
+  assertTrue(s <= context.getCtxtPrimes(), "prime set is messed up");
+  if (newKSFlag) {
+    s.clear();
+    s.insert(context.getIndexQks());
+    ctxt.bringToSet(s);
+  } else {
+    if (s.card() > 3) { // leave only first three ciphertext primes
+      long first = s.first();
+      IndexSet s3(first, first + 2);
+      s.retain(s3);
+    }
+    ctxt.modDownToSet(s);
+  }
+
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after mod down to qKS");
+  // XXX: debug
+  NTL::ZZX poly_beforeKS;
+  NTL::vec_ZZ pwfl_beforeKS;
+  dbgKey->Decrypt(poly_beforeKS, ctxt);
+  p2d_conv.ZZXtoPowerful(pwfl_beforeKS, poly_beforeKS);
+  vecRed(pwfl_beforeKS, pwfl_beforeKS, p2r, true);
+  for(long i = 0; i < n_slots; i++) {
+    assertEq(pwfl_s2c[i * d], pwfl_beforeKS[i * d], "something wrong with mod down to qKS");
+  }
+  // XXX: end debug
+#endif
+
+
+  // key-switch to the bootstrapping key
+  ctxt.reLinearize(recryptKeyID, newKSFlag);
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after key switching");
+  // XXX: debug
+  NTL::ZZX poly_beforeRaw;
+  NTL::vec_ZZ pwfl_beforeRaw;
+  dbgKey->Decrypt(poly_beforeRaw, ctxt);
+  p2d_conv.ZZXtoPowerful(pwfl_beforeRaw, poly_beforeRaw);
+  vecRed(pwfl_beforeRaw, pwfl_beforeRaw, p2r, true);
+  for(long i = 0; i < n_slots; i++) {
+    assertEq(pwfl_beforeKS[i * d], pwfl_beforeRaw[i * d], "something wrong with ks to btk");
+  }
+  // XXX: end debug
+#endif
+
+
+  // "raw mod-switch" to the bootstrapping mosulus q=p^e+1.
+  std::vector<NTL::ZZX> zzParts; // the mod-switched parts, in ZZX format
+
+  double mfac = ctxt.getContext().getZMStar().getNormBnd();
+  double noise_est;
+  if (newBtsFlag)
+    noise_est = ctxt.rawModSwitchNew(zzParts, q) * mfac;
+  else
+    noise_est = ctxt.rawModSwitch(zzParts, q) * mfac;
+#ifdef HELIB_DEBUG
+  // XXX: debug, check the bound on I after native bts
+  NTL::ZZX native_poly;
+  NTL::vec_ZZ native_pwfl;
+  rawDecrypt(native_poly, zzParts, dbgKey->getRecryptKey());
+  p2d_conv.ZZXtoPowerful(native_pwfl, native_poly);
+  auto native_pwfl_bound = NTL::conv<NTL::xdouble>(largestCoeff(native_pwfl)) /
+                           NTL::conv<NTL::xdouble>(q);
+  std::cout << "native pwfl bound is " << native_pwfl_bound << "\n";
+  // XXX: end debug native
+#endif
+
+  // noise_est is an upper bound on the L-infty norm of the scaled noise
+  // in the pwrfl basis
+  double beta =
+      p2r * (context.getScale() * sqrt(double(phim) / 12.0) *
+                 (sqrt(double(context.getHwt()) * log(double(phim))) + 1) +
+             0.5);
+  double noise_bnd = newBtsFlag ? 2 * beta * mfac
+                                : HELIB_MIN_CAP_FRAC * p2r *
+                                      ctxt.getContext().boundForRecryption();
+  // noise_bnd is the bound assumed in selecting the parameters
+  double noise_rat = noise_est / noise_bnd;
+
+  HELIB_STATS_UPDATE("raw-mod-switch-noise", noise_rat);
+
+  if (noise_rat > 1) {
+    // TODO: Turn the following preprocessor logics into a warnOrThrow function
+    std::string message =
+        "rawModSwitch scaled noise exceeds bound: " + std::to_string(noise_rat);
+#ifdef HELIB_DEBUG
+    Warning(message);
+#else
+    throw LogicError(message);
+#endif
+  }
+
+  assertEq(zzParts.size(),
+           (std::size_t)2,
+           "Exactly 2 parts required for mod-switching in thin bootstrapping");
+
+#ifdef HELIB_DEBUG
+  if (dbgKey) {
+    if (!newBtsFlag)
+      checkRecryptBounds(zzParts,
+                         dbgKey->getRecryptKey(),
+                         ctxt.getContext(),
+                         q);
+  }
+#endif
+
+  std::vector<NTL::ZZX> v;
+  v.resize(2);
+
+  Ctxt modUpCtxt(ctxt.getPubKey(), p2eNew);
+  std::vector<NTL::ZZX> I_part;
+
+  // debug variables
+
+  NTL::ZZX poly_before_mod;
+  NTL::vec_ZZ pwfl_before_mod;
+  NTL::ZZX poly_after_mod, I_poly, modUpPoly;
+  NTL::vec_ZZ I_part_pwfl, pwfl_diff, pwfl_after_mod, modUpPwfl;
+  std::vector<NTL::ZZX> slots_scaleUp;
+
+  if (!newBtsFlag) {
+    // Add multiples of q to make the zzParts divisible by p^{e'}
+    for (long i : range(2)) {
+      // make divisible by p^{e'}
+
+      newMakeDivisible(zzParts[i], p2ePrime, q, ctxt.getContext(), v[i]);
+    }
+  } else {
+#ifdef HELIB_DEBUG
+    // check the capacity of zzParts
+    rawDecrypt(poly_before_mod, zzParts, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(pwfl_before_mod, poly_before_mod);
+    vecRed(pwfl_before_mod, pwfl_before_mod, q, false);
+    NTL::ZZ maxPwfl = largestCoeff(pwfl_before_mod);
+    double capacity =
+        log(double(q) / NTL::to_long(maxPwfl) / 2.0 / aux) / log(2.0);
+    printf("pwfl capacity of zzParts is %f\n", capacity);
+    assertTrue(capacity > 0, "not enough capacity before scale");
+    // check the correctness of raw MS
+    long divFac = NTL::MulMod(q % p2r, intFactor, p2r);
+    divFac = NTL::InvMod(divFac, p2r);
+    for(long i = 0; i < n_slots; i++) {
+      long before = NTL::to_long(pwfl_beforeRaw[i * d]);
+      long after = NTL::rem(pwfl_before_mod[i * d], p2r);
+      after = NTL::MulMod(after, divFac, p2r);
+      assertEq(after, before, "something wrong with raw ms");
+    }
+#endif
+    // NOTE: in thin bootstrapping, the Zpr values in slots are first
+    //  move to the coeff domain by slotToCoeff
+    //  then the multAndGetOverflowPart adds noise to the lower digits
+    //  and the unoccupied coeffs
+    //  a coeffToSlot map moves the noisy coeffs into the slots,
+    //  then a trace-like map removes the values out of Z_p2eNew
+    //  In other words, we have apply the second map to
+    //  both modUpCtxt and Enc(I+aux*I', p2eNew)
+    multAndGetOverflowPart(zzParts, I_part, ctxt.getContext());
+    // NOTE: I_part is discarded
+
+#ifdef HELIB_DEBUG
+    // XXX: debug
+    rawDecrypt(poly_after_mod, zzParts, dbgKey->getRecryptKey());
+    // check the overflow part
+    rawDecrypt(I_poly, I_part, dbgKey->getRecryptKey());
+    p2d_conv.ZZXtoPowerful(I_part_pwfl, I_poly);
+    vecRed(I_part_pwfl, I_part_pwfl, aux, false);
+    p2d_conv.powerfulToZZX(I_poly, I_part_pwfl);
+
+    p2d_conv.ZZXtoPowerful(pwfl_diff, poly_after_mod - I_poly * q);
+    // vecRed(pwfl_diff, pwfl_diff, NTL::ZZ(aux) * NTL::ZZ(q), false);
+    for (long i = 0; i < phim; i++) {
+      assertTrue(bool(NTL::abs(pwfl_diff[i]) <= (q / 2)),
+                 "overflow part wrong?");
+    }
+    // assertTrue(NTL::to_long(largestCoeff(pwfl_diff)) <= (q / 2),
+    //            "overflow part wrong?");
+    // check the relationship between pwfl_before_mod and pwfl_after_mod
+    // now check if the bound on I is valid
+    p2d_conv.ZZXtoPowerful(pwfl_after_mod, poly_after_mod);
+    NTL::xdouble actualBoundI =
+        NTL::conv<NTL::xdouble>(largestCoeff(pwfl_after_mod)) / NTL::xdouble(q);
+    std::cerr << "actual bound on I is " << actualBoundI << "\n";
+    assertTrue(
+        bool(NTL::floor(actualBoundI) <= ceil(context.boundForRecryption())),
+        "bound on I exceeded");
+    vecRed(pwfl_after_mod, pwfl_after_mod, q, false);
+    if (t < 0) {
+      for (long i = 0; i < phim; i++) {
+        long before = NTL::rem(pwfl_before_mod[i], p2r);
+        before = NTL::MulMod(before, aux % p2r, p2r);
+        long after = NTL::rem(pwfl_after_mod[i], p2r);
+        assertEq(before,
+                 after,
+                 "something wrong with upscaling, non-power-of-p aux");
+      }
+    } else {
+      for (long i = 0; i < phim; i++) {
+        long before = NTL::rem(pwfl_before_mod[i], p2r);
+        long after = NTL::rem(pwfl_after_mod[i], p2eNew);
+        assertEq(before * aux,
+                 after,
+                 "something wrong with upscaling, power-of-p aux");
+      }
+    }
+// XXX: end debug
+#endif
+
+    // now handle the mod-up ctxt
+    modUpCtxt.ptxtSpace = p2eNew;
+    modUpCtxt.primeSet = context.getCtxtPrimes() | context.getModUpPrimes();
+    long QmodP = 1;
+    // be careful with single-precision modular arithmetic...
+    for (auto i : modUpCtxt.primeSet)
+      QmodP = NTL::MulMod(QmodP, context.ithPrime(i) % p2eNew, p2eNew);
+    // we pretend the IMPLIED INTFACTOR of m' mod P is 1
+    // (i.e., zzParts after raw-ms decrypts to m')
+    // which is actually intFactor * [q]_{p^r}
+    // we want the mult-by-aux and modded-up ctxt 
+    // to decrypt to p^t*m'+[q]_{p^eNew}*I...
+    // aux = p^t, stored intFactor = [Q^-1]_P
+    modUpCtxt.intFactor = NTL::InvMod(QmodP, p2eNew);
+    // divide by [q]_p2eNew, so that the encrypted value is I+[q]^-1_{p2eNew}*p^t*m'
+    modUpCtxt.intFactor = NTL::MulMod(modUpCtxt.intFactor, q % p2eNew, p2eNew);
+    modUpCtxt.noiseBound = context.boundForRecryption() * q;
+    for (int i = 0; i < 2; i++)
+      modUpCtxt.addPart(DoubleCRT(zzParts[i], context, modUpCtxt.primeSet),
+                        ctxt.parts[i].skHandle);
+    // discard the mod-up primes
+    modUpCtxt.modDownToSet(context.getCtxtPrimes());
+
+    // switch to the normal sk (keyID = 0)
+    modUpCtxt.reLinearize();
+
+#ifdef HELIB_DEBUG
+    dbgKey->Decrypt(modUpPoly, modUpCtxt);
+    p2d_conv.ZZXtoPowerful(modUpPwfl, modUpPoly);
+    vecRed(modUpPwfl, modUpPwfl, p2eNew, false);
+    p2d_conv.ZZXtoPowerful(I_part_pwfl, I_poly);
+    vecRed(I_part_pwfl, I_part_pwfl, aux, false);
+
+    p2d_conv.ZZXtoPowerful(pwfl_after_mod, poly_after_mod);
+    vecRed(pwfl_after_mod, pwfl_after_mod, q, false);
+
+    // for aux = p^t
+    // the message in zzParts befure "multAndGetOverflowPart" is m' mod p2r
+    // after that, the scaled message becomes p^t*m' mod p2eNew
+    // by modding up, the message becomes p^t*m' + [q]_p2eNew*I
+    // setting the modUpCtxt.intFactor = [Q^-1]_p2eNew ensures
+    // modUpCtxt decrypts to p^t*m' + [q]_p2eNew*I
+    // XXX: note at 20240104, I'm not sure why this check fails, 
+    //  but the final result is correct...?
+    // NOTE: maybe it is caused by the second modification to modUpCtxt.intFactor?
+    for (long i = 0; i < phim; i++) {
+      if (t > 0) {
+        assertEq(NTL::rem(modUpPwfl[i] - I_part_pwfl[i] * (q % p2eNew) -
+                              pwfl_after_mod[i],
+                          p2eNew),
+                 0L,
+                 "something wrong with assembly...? power-of-p aux");
+      } else {
+        // aux is not a power of p
+        // old message: m' mod p2r
+        // scaled message: aux*m' mod p2r (= pwfl_after_mod)
+        // modding up: aux*m' + [q]_p2r*I
+        // by setting stored intFactor to aux*[Q]_p2r:
+        //  m' + [q*aux^-1]_p2r*I
+        assertEq(NTL::rem(aux * modUpPwfl[i] - I_part_pwfl[i] * (q % p2r) -
+                              pwfl_after_mod[i],
+                          p2r),
+                 0L,
+                 "something wrong with assembly...? non-power-of-p aux");
+      }
+    }
+#endif
+//     // NOTE: this map is exclusive to thin-bts
+//     time_linear2_start_second = steady_clock::now();
+//     trcData.coeffToSlot->apply(modUpCtxt);
+//     time_linear2_end_second = steady_clock::now();
+//     // std::cout << "time for 2nd linear2 is " << 
+//     //   duration_cast<duration<double>>(time_linear2_end_second - time_linear2_start_second).count()
+//     //   << "\n";
+// #ifdef HELIB_DEBUG
+//     ea_boot->decrypt(modUpCtxt, *dbgKey, slots_scaleUp);
+// #endif
+  }
+
+#ifdef HELIB_DEBUG
+  if (dbgKey) {
+    if (!newBtsFlag) {
+      checkRecryptBounds_v(v, dbgKey->getRecryptKey(), ctxt.getContext(), q);
+      checkCriticalValue(zzParts,
+                         dbgKey->getRecryptKey(),
+                         ctxt.getContext().getRcData(),
+                         q);
+    }
+  }
+#endif
+
+  if (!newBtsFlag)
+    for (long i : range(zzParts.size())) {
+      zzParts[i] /= p2ePrime; // divide by p^{e'}
+    }
+
+  // NOTE: here we lose the intFactor associated with ctxt.
+  // We will restore it below.
+  ctxt = recryptEkey;
+
+  NTL::ZZX I_poly_new;
+  NTL::vec_ZZ I_poly_new_pwfl;
+  if (!newBtsFlag) {
+    ctxt.multByConstant(zzParts[1]);
+    ctxt.addConstant(zzParts[0]);
+    benchmarker.bits_after_inner_prod = ctxt.capacity();
+  } else {
+    ctxt = modUpCtxt;
+    benchmarker.bits_after_inner_prod = ctxt.capacity();
+  }
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after bootKeySwitch");
+#endif
+
+  HELIB_NTIMER_STOP(AAA_bootKeySwitch);
+
+  // Move the powerful-basis coefficients to the plaintext slots
+  HELIB_NTIMER_START(AAA_coeffToSlot);
+  auto bits_down_linear2 = ctxt.capacity();
+  auto time_linear2_start = steady_clock::now();
+  if (!trcData.isPo2)
+    trcData.coeffToSlot->apply(ctxt);
+  else
+    trcData.coeffToSlotPo2->apply(ctxt);
+  auto time_linear2_end = steady_clock::now();
+  bits_down_linear2 -= ctxt.capacity();
+  HELIB_NTIMER_STOP(AAA_coeffToSlot);
+  // std::cout << "time for linear2 is " << 
+
+#ifdef HELIB_DEBUG
+  std::vector<NTL::ZZX> slots_I;
+  ea_boot->decrypt(ctxt, *dbgKey, slots_I);
+  // XXX: debug, check if the slots match
+  auto vals_in = balrem_vec_ZZX(slots_in, p2r);
+  auto vals_scaleUp = balrem_vec_ZZX(slots_scaleUp, p2eNew);
+  auto val_I = balrem_vec_ZZX(slots_I, p2eNew);
+  if (t > 0)
+    for (long i = 0; i < n_slots; i++) {
+      long tmp = balRem(NTL::rem(val_I[i], aux), aux); // I without I*
+      tmp = (tmp + p2eNew) % p2eNew;
+      tmp = NTL::MulMod(q % p2eNew, tmp, p2eNew);
+      tmp = NTL::SubMod(NTL::rem(vals_scaleUp[i], p2eNew), tmp, p2eNew);
+      assertEq(tmp % aux, 0L, "not divisible by aux?");
+      tmp /= aux;
+      tmp %= p2r;
+      long factorDiv = intFactor;
+      factorDiv = NTL::MulMod(factorDiv % p2r, q % p2r, p2r);
+      assertEq(tmp,
+               NTL::MulMod(NTL::rem(vals_in[i], p2r), factorDiv, p2r),
+               "not matching, p^t");
+    }
+    // TODO: t < 0
+    // XXX: end debug
+#endif
+
+#ifdef HELIB_DEBUG
+  CheckCtxt(ctxt, "after coeffToSlot");
+#endif
+
+  // Extract the digits e-e'+r-1,...,e-e' (from fully packed slots)
+  HELIB_NTIMER_START(AAA_extractDigitsThin);
+  auto bits_down_extract = ctxt.capacity();
+  auto time_extract_start = steady_clock::now();
+  extractDigitsThin(ctxt, e - ePrime, r, ePrime, true);
+  auto time_extract_end = steady_clock::now();
+  bits_down_extract -= ctxt.capacity();
   HELIB_NTIMER_STOP(AAA_extractDigitsThin);
 
+#ifdef HELIB_DEBUG
+  if (newBtsFlag) {
+    std::vector<NTL::ZZX> slots_I_out;
+    ea_boot->decrypt(ctxt, *dbgKey, slots_I_out);
+    auto vals_I_out = balrem_vec_ZZX(slots_I_out, p2eNew);
+    for (long i = 0; i < n_slots; i++) {
+      assertEq(balRem(NTL::rem(val_I[i], aux), aux),
+               NTL::to_long(vals_I_out[i]),
+               "something wrong with digit extraction");
+    }
+  }
+#endif
+
 #ifdef HELIB_DEBUG
   CheckCtxt(ctxt, "after extractDigitsThin");
 #endif
 
   // restore intFactor
-  if (intFactor != 1)
+  if (newBtsFlag) {
+    // the ctxt encrypts [q]^-1_p2r*m' mod p2r
+    ctxt *= q % p2r;
+    // now correct the intFactor of m'
+    // NOTE: for old bts, since q=p^e+1, [q]_p^r==1
+    ctxt.intFactor =
+        NTL::MulMod(ctxt.intFactor,
+                    NTL::MulMod(intFactor, q % ptxtSpace, ptxtSpace),
+                    ptxtSpace);
+  } else if (intFactor != 1)
     ctxt.intFactor = NTL::MulMod(ctxt.intFactor, intFactor, ptxtSpace);
+  auto time_boot_end = steady_clock::now();
+  benchmarker.bits_down_extract = bits_down_extract;
+  benchmarker.bits_down_linear_1 = bits_down_linear1;
+  benchmarker.bits_down_linear_2 = bits_down_linear2;
+  benchmarker.bits_final = ctxt.capacity();
+  benchmarker.time_linear_1 =
+      duration_cast<duration<double>>(time_linear1_end - time_linear1_start)
+          .count();
+  benchmarker.time_linear_2 =
+      duration_cast<duration<double>>(time_linear2_end - time_linear2_start)
+          .count();
+  benchmarker.time_extract =
+      duration_cast<duration<double>>(time_extract_end - time_extract_start)
+          .count();
+  benchmarker.time_total =
+      duration_cast<duration<double>>(time_boot_end - time_boot_start).count();
+  return benchmarker;
 }
 
+
 #ifdef HELIB_DEBUG
 
 static void checkCriticalValue(const std::vector<NTL::ZZX>& zzParts,
diff --git a/tests/GTestBootstrapping.cpp b/tests/GTestBootstrapping.cpp
index 89360d9..fb5790c 100644
--- a/tests/GTestBootstrapping.cpp
+++ b/tests/GTestBootstrapping.cpp
@@ -133,7 +133,7 @@ protected:
       { 17,   576,  1365, 12,  7,   3, 65,   976,   911,  463,    6,   2,   4, 100}, // m=3*(5)*7*{13} m/phim(m)=2.36  C=22  D=3
       { 17, 18000, 21917, 30, 101, 217, 0,  5860,  5455,    0,  100,   6,   0, 100}, // m=(7)*{31}*101 m/phim(m)=1.21  C=134 D=2
       { 17, 30000, 34441, 30, 101, 341, 0,  2729, 31715,    0,  100,  10,   0, 100}, // m=(11)*{31}*101 m/phim(m)=1.14 C=138 D=2
-      { 17, 40000, 45551, 40, 101, 451, 0, 19394,  7677,    0,  100,  10,   0, 200}, // m=(11)*{41}*101 m/phim(m)=1.13 C=148 D=2
+      { 17, 40000, 45551, 40, 101, 451, 0, 19394,  7677,    0,  100,  10,   0, 200}, // m=(11)*{41}*101 m/phim(m)=1.13 C=148 D=2 <<<
       { 17, 46656, 52429, 36, 109, 481, 0, 46658,  5778,    0,  108,  12,   0, 100}, // m=(13)*{37}*109 m/phim(m)=1.12 C=154 D=2
       { 17, 54208, 59363, 44, 23, 2581, 0, 25811,  5199,    0,   22,  56,   0, 100}, // m=23*(29)*{89} m/phim(m)=1.09  C=120 D=2
       { 17, 70000, 78881, 10, 101, 781, 0, 67167, 58581,    0,  100,  70,   0, 100}, // m=(11)*{71}*101 m/phim(m)=1.12 C=178 D=2
@@ -143,7 +143,7 @@ protected:
       {127,  2160,  2821, 30,  13, 217, 0,   652,   222,    0,   12,   6,   0, 100}, // m=(7)*13*{31} m/phim(m)=1.3     C=46 D=2
       {127, 18816, 24295, 28, 43, 565,  0, 16386, 16427,    0,   42,  16,   0, 100}, // m=(5)*43*{113} m/phim(m)=1.29   C=84  D=2
       {127, 26112, 30277, 24, 17, 1781, 0, 14249, 10694,    0,   16,  68,   0, 100}, // m=(13)*17*{137} m/phim(m)=1.15  C=106 D=2
-      {127, 31752, 32551, 14, 43,  757, 0,  7571, 28768,    0,   42,  54,   0, 100}, // m=43*(757) :-( m/phim(m)=1.02   C=161 D=3
+      {127, 31752, 32551, 14, 43,  757, 0,  7571, 28768,    0,   42,  54,   0, 100}, // m=43*(757) :-( m/phim(m)=1.02   C=161 D=3 <<<
       {127, 46656, 51319, 36, 37, 1387, 0, 48546, 24976,    0,   36, -36,   0, 200}, //m=(19)*37*{73}:-( m/phim(m)=1.09 C=141 D=3
       {127, 49392, 61103, 28, 43, 1421, 0,  1422, 14234,    0,   42,  42,   0, 200}, // m=(7^2)*{29}*43 m/phim(m)=1.23  C=110 D=2
       {127, 54400, 61787, 40, 41, 1507, 0, 30141, 46782,    0,   40,  34,   0, 100}, // m=(11)*41*{137} m/phim(m)=1.13  C=112 D=2
@@ -256,13 +256,18 @@ TEST_P(GTestBootstrapping, bootstrappingWorksCorrectly)
   double t = -NTL::GetTime();
   helib::ContextBuilder<helib::BGV> cb;
   cb.m(m).p(p).r(r).gens(gens).ords(ords);
+  // NOTE: scale is the `k` in HElib paper, i.e., failure probability = phi(m)*erfc(k/sqrt(2))
+  // > a seperate `k` is used for bootstrap: Context::btsScale
   if (scale) {
     cb.scale(scale);
   }
   helib::Context context = cb.buildModChain(false).build();
 
-  context.buildModChain(L,
-                        c,
+  // NOTE: skHwt, e_param, ePrime_param, specialPrimes is set here
+  // > added eNew_param and ecapSkHwt, and tell recrypt to use ecapSkHwt
+  // > added KS params (a new ks modulus, a new set of specialPrimes) for encapsulated sk only
+  context.buildModChain(L, // modulus bits of fresh ctxt
+                        c, // number of decomposition digits for key switching
                         /*willBeBootstrappable=*/true,
                         /*t=*/skHwt);
 
@@ -288,6 +293,8 @@ TEST_P(GTestBootstrapping, bootstrappingWorksCorrectly)
   //   issue that buildModChain must be called BEFORE the context is made
   //   bootstrappable (else the "powerful" basis is not initialized correctly.)
 
+  // NOTE: RcData is initialized here, the main work in RcData is building the linear transformations
+  // > updated RcData to use p^eNew_param
   context.enableBootStrapping(mvec, /*build_cache=*/0);
   t += NTL::GetTime();
 
@@ -299,6 +306,7 @@ TEST_P(GTestBootstrapping, bootstrappingWorksCorrectly)
               << ", t=" << context.getRcData().skHwt << "\n";
     context.printout();
   }
+  // TODO: remove this for real computation
   helib::setDryRun(
       helib_test::dry); // Now we can set the dry-run flag if desired
 
@@ -312,11 +320,13 @@ TEST_P(GTestBootstrapping, bootstrappingWorksCorrectly)
     helib::SecKey secretKey(context);
     helib::PubKey& publicKey = secretKey;
     secretKey.GenSecKey(); // A +-1/0 secret key
-    helib::addSome1DMatrices(
+    helib::addSome1DMatrices( // TODO: add KS matrices for the collapsed FFT?
         secretKey); // compute key-switching matrices that we need
     helib::addFrbMatrices(secretKey);
     if (!helib_test::noPrint)
       std::cout << "computing key-dependent tables..." << std::flush;
+    // NOTE: the bootstrapping keys are generated here
+    // > modified the ksk generation to use the newly added params
     secretKey.genRecryptData();
     t += NTL::GetTime();
     if (!helib_test::noPrint)
@@ -343,6 +353,7 @@ TEST_P(GTestBootstrapping, bootstrappingWorksCorrectly)
 
     secretKey.Encrypt(c1, ptxt_poly, p2r);
 
+    // XXX: why multiplying with Enc(1) here?
     helib::Ctxt c_const1(publicKey);
     secretKey.Encrypt(c_const1, NTL::ZZX(1), p2r);
 
@@ -350,6 +361,8 @@ TEST_P(GTestBootstrapping, bootstrappingWorksCorrectly)
 
     for (long num = 0; num < INNER_REP; num++) {
       // multiple tests with the same key
+      // TODO: modify decomposition for ks
+      // modify bts routine
       publicKey.reCrypt(c1);
       secretKey.Decrypt(poly2, c1);
 
diff --git a/tests/GTestThinboot.cpp b/tests/GTestThinboot.cpp
index d8f3554..b2d8703 100644
--- a/tests/GTestThinboot.cpp
+++ b/tests/GTestThinboot.cpp
@@ -438,6 +438,7 @@ TEST_P(GTestThinboot, correctlyPerformsThinboot)
     long nslots = phim / d;
 
     // GG defines the plaintext space Z_p[X]/GG(X)
+    // NOTE: this GG and ea are identical to the normally constructed ones
     NTL::ZZX GG;
     GG = context.getAlMod().getFactorsOverZZ()[0];
     std::shared_ptr<helib::EncryptedArray> ea(
